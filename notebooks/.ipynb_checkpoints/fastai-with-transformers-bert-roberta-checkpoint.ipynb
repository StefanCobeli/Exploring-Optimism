{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "\n",
    "https://www.kaggle.com/maroberti/fastai-with-transformers-bert-roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastai with HuggingFace 🤗Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)\n",
    "\n",
    "![fastai + Transformers](https://i.ibb.co/qspmrcm/fastai-transformers-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. This implementation is a supplement of the Medium article [\"Fastai with 🤗Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)\"](https://medium.com/p/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2?source=email-29c8f5cf1dc4--writer.postDistributed&sk=119c3e5d748b2827af3ea863faae6376).\n",
    "\n",
    "**Also, remember the upvote button is next to the fork button, and it's free too!** 😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction : Story of transfer learning in NLP\n",
    "In early 2018, Jeremy Howard (co-founder of fast.ai) and Sebastian Ruder introduced the  [Universal Language Model Fine-tuning for Text Classification](https://medium.com/r/?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1801.06146.pdf) (ULMFiT) method. ULMFiT was the first **Transfer Learning** method applied to NLP. As a result, besides significantly outperforming many state-of-the-art tasks, it allowed, with only 100 labeled examples, to match performances equivalent to models trained on 100×  more data.\n",
    "\n",
    "The first time I heard about ULMFiT was during a [fast.ai course](https://course.fast.ai/videos/?lesson=4) given by Jeremy Howard. He demonstrated how it was easy  -  thanks to the ``fastai`` library  -  to implement the complete ULMFit method with only a few lines of codes. In his demo, he used an AWD-LSTM neural network pre-trained on Wikitext-103 and get rapidly state-of-the-art results. He also explained key techniques - also demonstrated in ULMFiT - to fine-tune the models like **Discriminate Learning Rate**, **Gradual Unfreezing** or **Slanted Triangular Learning Rates**.\n",
    "\n",
    "Since the introduction of ULMFiT, **Transfer Learning** became very popular in NLP and yet Google (BERT, Transformer-XL, XLNet), Facebook (RoBERTa, XLM) or even OpenAI (GPT, GPT-2) begin to pre-train their own model on very large corpora. This time, instead of using the AWD-LSTM neural network, they all used a more powerful architecture based on the Transformer (cf. [Attention is all you need](https://arxiv.org/abs/1706.03762)).\n",
    "\n",
    "Although these models are powerful, ``fastai`` do not integrate all of them. Fortunately, [HuggingFace](https://huggingface.co/) 🤗 created the well know [transformers library](https://github.com/huggingface/transformers). Formerly knew as ``pytorch-transformers`` or ``pytorch-pretrained-bert``, this library brings together over 40 state-of-the-art pre-trained NLP models (BERT, GPT-2, RoBERTa, CTRL…). The implementation gives interesting additional utilities like tokenizer, optimizer or scheduler.\n",
    "\n",
    "The ``transformers`` library can be self-sufficient but incorporating it within the ``fastai`` library provides simpler implementation compatible with powerful fastai tools like  **Discriminate Learning Rate**, **Gradual Unfreezing** or **Slanted Triangular Learning Rates**. The point here is to allow anyone — expert or non-expert — to get easily state-of-the-art results and to “make NLP uncool again”.\n",
    "\n",
    "It worth noting that the integration of the HuggingFace ``transformers`` library in ``fastai`` has already been demonstrated in:\n",
    "* Keita Kurita's article [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) which makes ``pytorch_pretrained_bert`` library compatible with ``fastai``.\n",
    "* Dev Sharma's article [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) which makes ``pytorch_transformers`` library compatible with ``fastai``.\n",
    "\n",
    "Although these articles are of high quality, some part of their demonstration is not anymore compatible with the last version of ``transformers``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🛠 Integrating transformers with fastai for multiclass classification\n",
    "Before beginning the implementation, note that integrating ``transformers`` within ``fastai`` can be done in multiple different ways. For that reason, I decided to bring simple solutions, that are the most generic and flexible. More precisely, I try to make the minimum of modification in both libraries while making them compatible with the maximum amount of transformer architectures.\n",
    "\n",
    "Note that in addition to this NoteBook and the [Medium article](https://medium.com/p/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2?source=email-29c8f5cf1dc4--writer.postDistributed&sk=119c3e5d748b2827af3ea863faae6376), I made another version available on my GitHub(TODO add link)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Installation\n",
    "Before starting the implementation, you will need to install the ``fastai`` and ``transformers`` libraries. To do so, just follow the instructions [here](https://github.com/fastai/fastai/blob/master/README.md#installation) and [here](https://github.com/huggingface/transformers#installation).\n",
    "\n",
    "In Kaggle, the ``fastai`` library is already installed. So you just have to instal ``transformers`` with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (2.8.0)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: sacremoses in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (0.0.41)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (2017.11.9)\n",
      "Requirement already satisfied: sentencepiece in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (0.1.86)\n",
      "Requirement already satisfied: numpy in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: requests in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (4.45.0)\n",
      "Requirement already satisfied: filelock in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: boto3 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from transformers) (1.12.17)\n",
      "Requirement already satisfied: six in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: joblib in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from boto3->transformers) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.17 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from boto3->transformers) (1.15.17)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.17->boto3->transformers) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.17->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: fastprogress in /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# pip install -q transformers\n",
    "!pip install transformers\n",
    "!pip install fastprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current versions of the fastai and transformers libraries are respectively 1.0.58 and 2.5.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 1.0.60\n",
      "transformers version : 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎬 The example task\n",
    "The chosen task is a multi-class text classification on [Movie Reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/overview).\n",
    "\n",
    "For each text movie review, the model has to predict a label for the sentiment. We evaluate the outputs of the model on classification accuracy. The sentiment labels are:\n",
    "* 0 → Negative\n",
    "* 1 → Somewhat negative\n",
    "* 2 → Neutral\n",
    "* 3 → Somewhat positive\n",
    "* 4 → Positive\n",
    "\n",
    "The data is loaded into a ``DataFrame`` using ``pandas``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/sentiment-analysis-on-movie-reviews/sampleSubmission.csv\n",
      "../../data/sentiment-analysis-on-movie-reviews/test.tsv.zip\n",
      "../../data/sentiment-analysis-on-movie-reviews/train.tsv.zip\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/sentiment-analysis-on-movie-reviews\"\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "for dirname, _, filenames in os.walk(data_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset:\n",
      "Found 7,475 texts.\n",
      "\n",
      "Binarized labels!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('been moody all day smh', -1.25, array([1., 0.]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys  \n",
    "from shutil           import copyfile\n",
    "sys.path.insert(0, '../')\n",
    "# sys.path.insert(0, '../config/')\n",
    "\n",
    "# from CustomTokenizer  import *\n",
    "from data_preparation import *\n",
    "# from Embedder         import *\n",
    "# from models           import *\n",
    "# from training         import *\n",
    "# from set_project_seed import *\n",
    "\n",
    "\n",
    "opt_data_path = \"../../data/optimism-twitter-data/tweets_annotation.csv\"\n",
    "\n",
    "opt_tweets, opt_gold_labels = read_OPT_data(data_path=opt_data_path)\n",
    "opt_gold_labels             = np.array(opt_gold_labels)\n",
    "\n",
    "\n",
    "bin_opt_gold_labels = binarize_labels(gold_labels=(opt_gold_labels)\\\n",
    "                                      , max_negative_value=0)\n",
    "\n",
    "# x_train, y_train, x_dev, y_dev, x_test, y_test = \\\n",
    "#     train_dev_test_split(opt_vectorized_tweets\\\n",
    "#                          , bin_opt_gold_labels, R_SEED=16)\n",
    "\n",
    "opt_tweets[-1], opt_gold_labels[-1], bin_opt_gold_labels[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4) (66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA_ROOT = Path(\"..\") / \"/kaggle/input/sentiment-analysis-on-movie-reviews\"\n",
    "DATA_ROOT = Path(\"\") / data_path\n",
    "train = pd.read_csv(DATA_ROOT / 'train.tsv.zip', sep=\"\\t\")\n",
    "test = pd.read_csv(DATA_ROOT / 'test.tsv.zip', sep=\"\\t\")\n",
    "print(train.shape,test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that in the dataset there are no individual movie reviews but rather phrases taken out of context and split into smaller parts, each with an assigned sentiment label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main transformers classes\n",
    "In ``transformers``, each model architecture is associated with 3 main types of classes:\n",
    "* A **model class** to load/store a particular pre-train model.\n",
    "* A **tokenizer class** to pre-process the data and make it compatible with a particular model.\n",
    "* A **configuration class** to load/store the configuration of a particular model.\n",
    "\n",
    "For example, if you want to use the Bert architecture for text classification, you would use [``BertForSequenceClassification``](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification) for the **model class**, [``BertTokenizer``](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer) for the **tokenizer class** and [``BertConfig``](https://huggingface.co/transformers/model_doc/bert.html#bertconfig) for the **configuration class**. \n",
    "\n",
    "In order to switch easily between classes  -  each related to a specific model type  -  I created a dictionary that allows loading the correct classes by just specifying the correct model type name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see later, that those classes share a common class method ``from_pretrained(pretrained_model_name, ...)``. In our case, the parameter ``pretrained_model_name`` is a string with the shortcut name of a pre-trained model/tokenizer/configuration to load, e.g ``'bert-base-uncased'``. We can find all the shortcut names in the transformers documentation [here](https://huggingface.co/transformers/pretrained_models.html#pretrained-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed     = 42\n",
    "use_fp16 = False\n",
    "bs       = 16\n",
    "\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base'\n",
    "\n",
    "# model_type = 'bert'\n",
    "# pretrained_model_name='bert-base-uncased'\n",
    "\n",
    "# model_type = 'distilbert'\n",
    "# pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "#model_type = 'xlm'\n",
    "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "\n",
    "# model_type = 'xlnet'\n",
    "# pretrained_model_name = 'xlnet-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the available values for ``pretrained_model_name`` (shortcut names) corresponding to the ``model_type`` used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that in this case, we use the ``transformers`` library only for a multi-class text classification task. For that reason, this tutorial integrates only the transformer architectures that have a model for sequence classification implemented. These model types are :\n",
    "* BERT (from Google)\n",
    "* XLNet (from Google/CMU)\n",
    "* XLM (from Facebook)\n",
    "* RoBERTa (from Facebook)\n",
    "* DistilBERT (from HuggingFace)\n",
    "\n",
    "However, if you want to go further - by implementing another type of model or NLP task - this tutorial still an excellent starter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to set the seed for generating random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "To match pre-training, we have to format the model input sequence in a specific format.\n",
    "To do so, you have to first **tokenize** and then **numericalize** the texts correctly.\n",
    "The difficulty here is that each pre-trained model, that we will fine-tune, requires exactly the same specific pre-process - **tokenization** & **numericalization** - than the pre-process used during the pre-train part.\n",
    "Fortunately, the **tokenizer class** from ``transformers`` provides the correct pre-process tools that correspond to each pre-trained model.\n",
    "\n",
    "In the ``fastai`` library, data pre-processing is done automatically during the creation of the ``DataBunch``. \n",
    "As you will see in the ``DataBunch`` implementation, the **tokenizer** and **numericalizer** are passed in the processor argument under the following format :\n",
    "\n",
    "``processor = [TokenizeProcessor(tokenizer=tokenizer,...), NumericalizeProcessor(vocab=vocab,...)]``\n",
    "\n",
    "Let's first analyse how we can integrate the ``transformers`` **tokenizer** within the ``TokenizeProcessor`` function.\n",
    "\n",
    "### Custom Tokenizer\n",
    "This part can be a little bit confusing because a lot of classes are wrapped in each other and with similar names.\n",
    "To resume, if we look attentively at the ``fastai`` implementation, we notice that :\n",
    "1. The [``TokenizeProcessor`` object](https://docs.fast.ai/text.data.html#TokenizeProcessor) takes as ``tokenizer`` argument a ``Tokenizer`` object.\n",
    "2. The [``Tokenizer`` object](https://docs.fast.ai/text.transform.html#Tokenizer) takes as ``tok_func`` argument a ``BaseTokenizer`` object.\n",
    "3. The [``BaseTokenizer`` object](https://docs.fast.ai/text.transform.html#BaseTokenizer) implement the function ``tokenizer(t:str) → List[str]`` that take a text ``t`` and returns the list of its tokens.\n",
    "\n",
    "Therefore, we can simply create a new class ``TransformersBaseTokenizer`` that inherits from ``BaseTokenizer`` and overwrite a new ``tokenizer`` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "            tokens = [CLS] + tokens + [SEP]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "            if self.model_type in ['xlnet']:\n",
    "                tokens = tokens + [SEP] +  [CLS]\n",
    "            else:\n",
    "                tokens = [CLS] + tokens + [SEP]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, be carefull about 3 things :\n",
    "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
    "2. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
    "3. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with ``add_prefix_space`` set to ``True``.\n",
    "\n",
    "Below, you can find the resume of each pre-process requirement for the 5 model types used in this tutorial. You can also find this information on the [HuggingFace documentation](https://huggingface.co/transformers/) in each model section.\n",
    "\n",
    "    bert:       [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "    roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
    "    \n",
    "    distilbert: [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "    xlm:        [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "    xlnet:      padding + tokens + [SEP] + [CLS]\n",
    "    \n",
    "It is worth noting that we don't add padding in this part of the implementation. \n",
    "As we will see later, ``fastai`` manage it automatically during the creation of the ``DataBunch``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Numericalizer\n",
    "\n",
    "In ``fastai``, [``NumericalizeProcessor``  object](https://docs.fast.ai/text.data.html#NumericalizeProcessor) takes as ``vocab`` argument a [``Vocab`` object](https://docs.fast.ai/text.transform.html#Vocab). \n",
    "From this analyse, we suggest two ways to adapt the fastai numericalizer:\n",
    "1. You can, like decribed in the [Dev Sharma's article](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Section *1. Setting Up the Tokenizer*), retreive the list of tokens and create a ``Vocab`` object.\n",
    "2. Create a new class ``TransformersVocab`` that inherits from ``Vocab`` and overwrite ``numericalize`` and ``textify`` functions.\n",
    "\n",
    "Even if the first solution seems to be simpler, ``Transformers`` does not provide, for all models, a straightforward way to retreive his list of tokens. \n",
    "Therefore, I implemented the second solution, which runs for each model type.\n",
    "It consists of using the functions ``convert_tokens_to_ids`` and ``convert_ids_to_tokens`` in respectively ``numericalize`` and ``textify``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.itos = state['itos']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: The functions ``__gestate__`` and ``__setstate__`` allow the functions [export](https://docs.fast.ai/basic_train.html#Learner.export) and [load_learner](https://docs.fast.ai/basic_train.html#load_learner) to work correctly with ``TransformersVocab``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom processor\n",
    "Now that we have our custom **tokenizer** and **numericalizer**, we can create the custom **processor**. Notice we are passing the ``include_bos = False`` and ``include_eos = False`` options. This is because ``fastai`` adds its own special tokens by default which interferes with the ``[CLS]`` and ``[SEP]`` tokens added by our custom tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Databunch\n",
    "For the DataBunch creation, you have to pay attention to set the processor argument to our new custom processor ``transformer_processor`` and manage correctly the padding.\n",
    "\n",
    "As mentioned in the HuggingFace documentation, BERT, RoBERTa, XLM and DistilBERT are models with absolute position embeddings, so it's usually advised to pad the inputs on the right rather than the left. Regarding XLNET, it is a model with relative position embeddings, therefore, you can either pad the inputs on the right or on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']\n",
      "[18111, 1182, 740, 3304, 7458, 118, 6, 20920, 24, 579, 162]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
    "print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is multible ways to create a DataBunch, in our implementation, we use [the data block API](https://docs.fast.ai/data_block.html#The-data-block-API), which gives more flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "databunch = (TextList.from_df(train, cols='Phrase', processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= 'Sentiment')\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Optimism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did i just hear clive anderson say peter cooke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anyways that's my evening thesis. write don't ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when teachers ask why im late. (vine by @jimmy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@obafemiwilliams @darren_linzoid @kenboy4 hurr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@karsten_frank @wjelger on the other hand. the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Optimism\n",
       "0  did i just hear clive anderson say peter cooke...         1\n",
       "1  anyways that's my evening thesis. write don't ...         1\n",
       "2  when teachers ask why im late. (vine by @jimmy...         0\n",
       "3  @obafemiwilliams @darren_linzoid @kenboy4 hurr...         0\n",
       "4  @karsten_frank @wjelger on the other hand. the...         1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_dict = {\"Tweet\" : opt_tweets, \"Optimism\" : np.where(opt_gold_labels<=0, 0, 1)}\n",
    "\n",
    "# binarize_labels()\n",
    "opt_df   = pd.DataFrame(opt_dict)\n",
    "opt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('always try to give the world. as much love and goodness as you can .. #healingthoughts',\n",
       " 3.0,\n",
       " array([0., 1.]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_gold_labels.argmax()\n",
    "\n",
    "opt_tweets[578], opt_gold_labels[578], bin_opt_gold_labels[578] #argmin\n",
    "\n",
    "opt_tweets[928], opt_gold_labels[928], bin_opt_gold_labels[928] #argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.TextList"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextList."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_databunch = (TextList.from_df(opt_df, cols='Tweet', processor=transformer_processor)\n",
    "                 .split_by_rand_pct(0.1,seed=seed)\n",
    "                 .label_from_df(cols= 'Optimism')\n",
    "                 .add_test(test)\n",
    "                 .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and tokenizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token : <s>\n",
      "[SEP] token : </s>\n",
      "[PAD] token : <pad>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ġ- L RB - ĠCity Ġ- RR B - Ġreminds Ġus Ġhow Ġrealistically Ġnuanced Ġa ĠRobert ĠDe ĠN iro Ġperformance Ġcan Ġbe Ġwhen Ġhe Ġis Ġnot Ġmore Ġluc r atively Ġengaged Ġin Ġthe Ġshameless Ġself - car ic ature Ġof Ġ` ĠAnaly ze ĠThis Ġ' Ġ- L RB - Ġ1999 Ġ- RR B - Ġand Ġ` ĠAnaly ze ĠThat Ġ, Ġ' Ġpromised Ġ- L RB - Ġor Ġthreatened Ġ-</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠThe Ġreal Ġtriumph s Ġin ĠIg by Ġcome Ġfrom ĠPhilippe Ġ, Ġwho Ġmakes ĠOliver Ġfar Ġmore Ġinteresting Ġthan Ġthe Ġcharacter Ġ' s Ġlines Ġwould Ġsuggest Ġ, Ġand ĠSar andon Ġ, Ġwho Ġcould Ġn 't Ġbe Ġbetter Ġas Ġa Ġcruel Ġbut Ġweird ly Ġlik able ĠWAS P Ġmat ron Ġ. &lt;/s&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠParker Ġshould Ġbe Ġcomm ended Ġfor Ġtaking Ġa Ġfresh Ġapproach Ġto Ġfamiliar Ġmaterial Ġ, Ġbut Ġhis Ġdetermination Ġto Ġremain Ġtrue Ġto Ġthe Ġoriginal Ġtext Ġleads Ġhim Ġto Ġadopt Ġa Ġsomewhat Ġman nered Ġtone Ġ... Ġthat Ġultimately Ġdull s Ġthe Ġhuman Ġtragedy Ġat Ġthe Ġstory Ġ' s Ġcore &lt;/s&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠIt Ġ' s Ġa Ġlong Ġway Ġfrom ĠOrwell Ġ' s Ġdark Ġ, Ġintelligent Ġwarning Ġcry Ġ- L RB - Ġ1984 Ġ- RR B - Ġto Ġthe Ġempty Ġstud Ġknock about Ġof ĠEqu ilibrium Ġ, Ġand Ġwhat Ġonce Ġwas Ġconviction Ġis Ġnow Ġaffect ation Ġ. &lt;/s&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; ĠA Ġdifferent Ġand Ġemotionally Ġreserved Ġtype Ġof Ġsurvival Ġstory Ġ-- Ġa Ġfilm Ġless Ġabout Ġref ract ing Ġall Ġof ĠWorld ĠWar ĠII Ġthrough Ġthe Ġspecific Ġconditions Ġof Ġone Ġman Ġ, Ġand Ġmore Ġabout Ġthat Ġman Ġlost Ġin Ġits Ġmidst Ġ. &lt;/s&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "databunch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and numericalizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] id : 0\n",
      "[SEP] id : 2\n",
      "[PAD] id : 1\n",
      "Batch shape :  torch.Size([16, 79])\n",
      "tensor([[    0,   111,   574,  ...,    76,   479,     2],\n",
      "        [    0,    33,     7,  ...,     1,     1,     1],\n",
      "        [    0,   318,    47,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,     5,  2156,  ...,     1,     1,     1],\n",
      "        [    0,    33, 30291,  ...,     1,     1,     1],\n",
      "        [    0, 45518, 10730,  ...,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = databunch.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model\n",
    "As mentioned [here](https://github.com/huggingface/transformers#models-always-output-tuples), every model's forward method always outputs a ``tuple`` with various elements depending on the model and the configuration parameters. In our case, we are interested to access only to the logits. \n",
    "One way to access them is to create a custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our model architecture \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        # attention_mask\n",
    "        # Mask to avoid performing attention on padding token indices.\n",
    "        # Mask values selected in ``[0, 1]``:\n",
    "        # ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
    "        attention_mask = (input_ids!=pad_idx).type(input_ids.type()) \n",
    "        \n",
    "        logits = self.transformer(input_ids,\n",
    "                                  attention_mask = attention_mask)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our transformers adapted to multiclass classification, before loading the pre-trained model, we need to precise the number of labels. To do so, you can modify the config instance or either modify like in [Keita Kurita's article](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) (Section: *Initializing the Learner*) the ``num_labels`` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da7d08a78c74e2485020cc89acd42f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RobertaConfig {\n",
      "  \"_num_labels\": 5,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = 5\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8f9c605f56480cb99abfdec6166c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner : Custom Optimizer / Custom Metric\n",
    "In ``pytorch-transformers``, HuggingFace had implemented two specific optimizers  -  BertAdam and OpenAIAdam  -  that have been replaced by a single AdamW optimizer.\n",
    "This optimizer matches Pytorch Adam optimizer Api, therefore, it becomes straightforward to integrate it within ``fastai``.\n",
    "It is worth noting that for reproducing BertAdam specific behavior, you have to set ``correct_bias = False``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(databunch, \n",
    "                  custom_transformer_model, \n",
    "                  opt_func = CustomAdamW, \n",
    "                  metrics=[accuracy, error_rate])\n",
    "\n",
    "# Show graph of learner stats and metrics after each epoch.\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Fine-tuning and Gradual unfreezing (Optional)\n",
    "To use **discriminative layer training** and **gradual unfreezing**, ``fastai`` provides one tool that allows to \"split\" the structure model into groups. An instruction to perform that \"split\" is described in the fastai documentation [here](https://docs.fast.ai/basic_train.html#Discriminative-layer-training).\n",
    "\n",
    "Unfortunately,  the model architectures are too different to create a unique generic function that can \"split\" all the model types in a convenient way. Thereby, you will have to implement a custom \"split\" for each different model architecture.\n",
    "\n",
    "For example, if we use the RobBERTa model and that we observe his architecture by making ``print(learner.model)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide to divide the model in 14 blocks :\n",
    "* 1 Embedding\n",
    "* 12 transformer\n",
    "* 1 classifier\n",
    "\n",
    "In this case, we can split our model in this way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT\n",
    "# list_layers = [learner.model.transformer.distilbert.embeddings,\n",
    "#                learner.model.transformer.distilbert.transformer.layer[0],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[1],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[2],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[3],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[4],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[5],\n",
    "#                learner.model.transformer.pre_classifier]\n",
    "\n",
    "# For xlnet-base-cased\n",
    "# list_layers = [learner.model.transformer.transformer.word_embedding,\n",
    "#               learner.model.transformer.transformer.layer[0],\n",
    "#               learner.model.transformer.transformer.layer[1],\n",
    "#               learner.model.transformer.transformer.layer[2],\n",
    "#               learner.model.transformer.transformer.layer[3],\n",
    "#               learner.model.transformer.transformer.layer[4],\n",
    "#               learner.model.transformer.transformer.layer[5],\n",
    "#               learner.model.transformer.transformer.layer[6],\n",
    "#               learner.model.transformer.transformer.layer[7],\n",
    "#               learner.model.transformer.transformer.layer[8],\n",
    "#               learner.model.transformer.transformer.layer[9],\n",
    "#               learner.model.transformer.transformer.layer[10],\n",
    "#               learner.model.transformer.transformer.layer[11],\n",
    "#               learner.model.transformer.sequence_summary]\n",
    "\n",
    "# For roberta-base\n",
    "list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "              learner.model.transformer.roberta.encoder.layer[0],\n",
    "              learner.model.transformer.roberta.encoder.layer[1],\n",
    "              learner.model.transformer.roberta.encoder.layer[2],\n",
    "              learner.model.transformer.roberta.encoder.layer[3],\n",
    "              learner.model.transformer.roberta.encoder.layer[4],\n",
    "              learner.model.transformer.roberta.encoder.layer[5],\n",
    "              learner.model.transformer.roberta.encoder.layer[6],\n",
    "              learner.model.transformer.roberta.encoder.layer[7],\n",
    "              learner.model.transformer.roberta.encoder.layer[8],\n",
    "              learner.model.transformer.roberta.encoder.layer[9],\n",
    "              learner.model.transformer.roberta.encoder.layer[10],\n",
    "              learner.model.transformer.roberta.encoder.layer[11],\n",
    "              learner.model.transformer.roberta.pooler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check groups : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 14 groups\n",
      "[Sequential(\n",
      "  (0): Embedding(50265, 768, padding_idx=1)\n",
      "  (1): Embedding(514, 768, padding_idx=1)\n",
      "  (2): Embedding(1, 768)\n",
      "  (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=5, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "learner.split(list_layers)\n",
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')\n",
    "print(learner.layer_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I didn't found any document that has studied the influence of **Discriminative Fine-tuning** and **Gradual unfreezing** or even **Slanted Triangular Learning Rates** with transformers. Therefore, using these tools does not guarantee better results. If you found any interesting documents, please let us know in the comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Now we can finally use all the fastai build-in features to train our model. Like the ULMFiT method, we will use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and **gradually unfreeze the model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('untrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('untrain');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we first freeze all the groups but the classifier with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check which layer are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [79, 768]            38,603,520 False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 768]            394,752    False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 768]            768        False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Tanh                 [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [5]                  3,845      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 125,240,069\n",
       "Total trainable params: 1,185,029\n",
       "Total non-trainable params: 124,055,040\n",
       "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    ShowGraph"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **Slanted Triangular Learning Rates** you have to use the function ``one_cycle``. For more information please check the fastai documentation [here](https://docs.fast.ai/callbacks.one_cycle.html). \n",
    "\n",
    "To use our ``one_cycle`` we will need an optimum learning rate. We can find this learning rate by using a learning rate finder which can be called by using ``lr_find``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='71' class='' max='8778', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.81% [71/8778 00:47<1:36:36 4.1392]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428270644/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 7.59E-03\n",
      "Min loss divided by 10: 4.37E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end=10,suggestion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pick a value a bit before the minimum, where the loss still improves. Here 2x10^-3 seems to be a good value.\n",
    "\n",
    "Next we will use ``fit_one_cycle`` with the chosen learning rate as the maximum learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='225' class='' max='8778', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.56% [225/8778 02:07<1:21:05 1.3008]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-40bb2603d42f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-03\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-3e632fdbef91>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         logits = self.transformer(input_ids,\n\u001b[0;32m---> 16\u001b[0;31m                                   attention_mask = attention_mask)[0]   \n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         )\n\u001b[1;32m    792\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             )\n\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(1,max_lr=2e-03,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('first_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('first_cycle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then unfreeze the second group of layers and repeat the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that we use slice to create separate learning rate for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.927349</td>\n",
       "      <td>0.900878</td>\n",
       "      <td>0.636935</td>\n",
       "      <td>0.363065</td>\n",
       "      <td>04:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('second_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('second_cycle');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.894050</td>\n",
       "      <td>0.870450</td>\n",
       "      <td>0.648917</td>\n",
       "      <td>0.351083</td>\n",
       "      <td>04:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('third_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('third_cycle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we unfreeze all the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 11:27<11:27]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.710882</td>\n",
       "      <td>0.702230</td>\n",
       "      <td>0.297770</td>\n",
       "      <td>11:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8517' class='' max='8778', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      97.03% [8517/8778 11:05<00:20 0.7110]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can predict examples with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 4,\n",
       " tensor(4),\n",
       " tensor([8.4167e-06, 1.0881e-05, 1.2710e-04, 2.3995e-02, 9.7586e-01]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict('This is the best movie of 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0,\n",
       " tensor(0),\n",
       " tensor([9.6016e-01, 3.8789e-02, 9.0164e-04, 6.7663e-05, 8.4127e-05]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict('This is the worst movie of 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Learner\n",
    "In order to export and load the learner you can do these operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CustomTransformerModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RobertaForSequenceClassification. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RobertaModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RobertaEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertIntermediate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertPooler. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RobertaClassificationHead. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "learner.export(file = 'transformer.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/kaggle/working'\n",
    "export_learner = load_learner(path, file = 'transformer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned [here](https://docs.fast.ai/basic_train.html#load_learner), you have to be careful that each custom classes - like ``TransformersVocab`` - are first defined before executing ``load_learner``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0,\n",
       " tensor(0),\n",
       " tensor([9.6016e-01, 3.8789e-02, 9.0164e-04, 6.7663e-05, 8.4127e-05]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_learner.predict('This is the worst movie of 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating prediction\n",
    "Now that the model is trained, we want to generate predictions from the test dataset.\n",
    "\n",
    "As specified in Keita Kurita's [article](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/), as the function ``get_preds`` does not return elements in order by default, you will have to resort the elements into their correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    the get_preds method does not yield the elements in order by default\n",
    "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
    "    \"\"\"\n",
    "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    return preds[reverse_sampler, :]\n",
    "\n",
    "test_preds = get_preds_as_nparray(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(DATA_ROOT / 'sampleSubmission.csv')\n",
    "sample_submission['Sentiment'] = np.argmax(test_preds,axis=1)\n",
    "sample_submission.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  Sentiment\n",
       "0    156061          2\n",
       "1    156062          2\n",
       "2    156063          2\n",
       "3    156064          2\n",
       "4    156065          2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=predictions.csv>Download CSV file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create a link to download the dataframe which was saved with .to_csv method\n",
    "create_download_link(filename='predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now submit our predictions to Kaggle !  In our example, without playing too much with the parameters, we get a score of 0.70059, which leads us to the 5th position on the leaderboard! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this NoteBook, I explain how to combine the ``transformers`` library with the beloved ``fastai`` library. It aims to make you understand where to look and modify both libraries to make them work together. Likely, it allows you to use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and even **Gradual Unfreezing**. As a result, without even tunning the parameters, you can obtain rapidly state-of-the-art results.\n",
    "\n",
    "This year, the transformers became an essential tool to NLP. Because of that, I think that pre-trained transformers architectures will be integrated soon to future versions of fastai. Meanwhile, this tutorial is a good starter.\n",
    "\n",
    "I hope you enjoyed this first article and found it useful. \n",
    "Thanks for reading and don't hesitate in leaving questions or suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* Hugging Face, Transformers GitHub (Nov 2019), [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)\n",
    "* Fast.ai, Fastai documentation (Nov 2019), [https://docs.fast.ai/text.html](https://docs.fast.ai/text.html)\n",
    "* Jeremy Howard & Sebastian Ruder, Universal Language Model Fine-tuning for Text Classification (May 2018), [https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)\n",
    "* Keita Kurita's article : [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) (May 2019)\n",
    "* Dev Sharma's article : [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Sep 2019)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04af8c8ab4264a4aa24be5ce7c3d6356": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3dc1cc48d64540ce8bc345e054f718e7",
       "max": 501200538,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c04b9a4c489943fb914d74765454b956",
       "value": 501200538
      }
     },
     "06072bb801914fdbb50a818901689aaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0db349fcc5da48ce974d5ca6a5d74ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0dc20e8cb6db4aaf85be250fde458fb5",
       "max": 898823,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_50aa5abe7c4a44458343a9dc2aba73dc",
       "value": 898823
      }
     },
     "0dc20e8cb6db4aaf85be250fde458fb5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f93a2908b1d4eca979f36d4278a3598": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e1100a07ec63445f81f29fd119832e0e",
       "placeholder": "​",
       "style": "IPY_MODEL_94e96540367c40bfb560a8f692d3df96",
       "value": " 456k/456k [00:00&lt;00:00, 1.37MB/s]"
      }
     },
     "162c0469b80a41c4b09493deeb075d8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1e1b327155e043c68fe77d45136743f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_963c6c9ab8834d5a9c87bd4e1aebf467",
       "max": 524,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4137286f012b473ca7da96941fd7c2c8",
       "value": 524
      }
     },
     "22ed017644074184912140c8dab74662": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "25036c2d84cd4d7980c3b5e2a4a8ceb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3dc1cc48d64540ce8bc345e054f718e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3effb5e6c7d745e0afcb18d3dfa97dbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_04af8c8ab4264a4aa24be5ce7c3d6356",
        "IPY_MODEL_dbaec362a5f04949973a7618fd390775"
       ],
       "layout": "IPY_MODEL_b4b3cd9912ab4aad8bf6dfe20b822d37"
      }
     },
     "4137286f012b473ca7da96941fd7c2c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "50aa5abe7c4a44458343a9dc2aba73dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "58e2d230ac834afea6905419421e0c7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6beb3d2743084253af1a8c510a43ae5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1e1b327155e043c68fe77d45136743f8",
        "IPY_MODEL_74b97ad281db4f3d925289c16fa0e937"
       ],
       "layout": "IPY_MODEL_8521940d38fa4c83aa95e1846e5e8fce"
      }
     },
     "74b97ad281db4f3d925289c16fa0e937": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25036c2d84cd4d7980c3b5e2a4a8ceb1",
       "placeholder": "​",
       "style": "IPY_MODEL_886b261c181b4be68941c4a64d1eef55",
       "value": " 524/524 [00:00&lt;00:00, 881B/s]"
      }
     },
     "750d897db40646d09f29e1949aa87003": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e198a334cac4ab49a5a00c81c624512": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e55f8b65bf5f4374a48b31ef690f5e73",
       "max": 456318,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_162c0469b80a41c4b09493deeb075d8e",
       "value": 456318
      }
     },
     "8521940d38fa4c83aa95e1846e5e8fce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "886b261c181b4be68941c4a64d1eef55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8c226c92b5684e989d150a6c1fc65ee9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_06072bb801914fdbb50a818901689aaf",
       "placeholder": "​",
       "style": "IPY_MODEL_93a3957ae16b41c9b710adedaaf02156",
       "value": " 899k/899k [00:01&lt;00:00, 709kB/s]"
      }
     },
     "93a3957ae16b41c9b710adedaaf02156": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "94e96540367c40bfb560a8f692d3df96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "963c6c9ab8834d5a9c87bd4e1aebf467": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e840112621c4243bbcd618bd0e4a550": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af165492e3e74ed0941720ecb7ce9ffa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7e198a334cac4ab49a5a00c81c624512",
        "IPY_MODEL_0f93a2908b1d4eca979f36d4278a3598"
       ],
       "layout": "IPY_MODEL_750d897db40646d09f29e1949aa87003"
      }
     },
     "b4b3cd9912ab4aad8bf6dfe20b822d37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c04b9a4c489943fb914d74765454b956": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "dbaec362a5f04949973a7618fd390775": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e840112621c4243bbcd618bd0e4a550",
       "placeholder": "​",
       "style": "IPY_MODEL_22ed017644074184912140c8dab74662",
       "value": " 501M/501M [00:13&lt;00:00, 36.2MB/s]"
      }
     },
     "e1100a07ec63445f81f29fd119832e0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e55f8b65bf5f4374a48b31ef690f5e73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f2134963e3a44c29a237bee166bbfab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0db349fcc5da48ce974d5ca6a5d74ed7",
        "IPY_MODEL_8c226c92b5684e989d150a6c1fc65ee9"
       ],
       "layout": "IPY_MODEL_58e2d230ac834afea6905419421e0c7f"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
