{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9581556bf34a81961ac42eaca02614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=688.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f0ceab920442bd9545e6c1c3735bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425744429.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RobertaForSequenceClassification:\n\tsize mismatch for classifier.out_proj.weight: copying a param with shape torch.Size([3, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n\tsize mismatch for classifier.out_proj.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4fc957abc4ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Whether the model returns attentions weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Whether the model returns all hidden-states.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m                 raise RuntimeError(\n\u001b[1;32m    612\u001b[0m                     \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[0;32m--> 613\u001b[0;31m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m                     )\n\u001b[1;32m    615\u001b[0m                 )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RobertaForSequenceClassification:\n\tsize mismatch for classifier.out_proj.weight: copying a param with shape torch.Size([3, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n\tsize mismatch for classifier.out_proj.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "from transformers    import RobertaForSequenceClassification\n",
    "\n",
    "#New:\n",
    "#roberta-large-mnli, roberta-large\n",
    "model_name = \"roberta-large\"\n",
    "model_name = \"roberta-large-mnli\"\n",
    "\n",
    "RobertaForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels = 2,\n",
    "            output_attentions = False, # Whether the model returns attentions weights.\n",
    "            output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data_preparation module!\n",
      "Loaded model_logic module!\n",
      "Loaded tokenization module!\n"
     ]
    }
   ],
   "source": [
    "#main method, only logic assembly:\n",
    "# import argparse\n",
    "# import configparser\n",
    "\n",
    "# sys.path.insert(0, './code/')\n",
    "# sys.path.insert(0, './config/')\n",
    "\n",
    "\n",
    "# from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '../utils/BERT/')\n",
    "\n",
    "\n",
    "from data_preparation import *\n",
    "from model_logic      import *\n",
    "from tokenization     import *\n",
    "\n",
    "from torch.optim      import Adam\n",
    "from tqdm             import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(\"2+3\")\n",
    "type(eval(\"[2, 3, 4]\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Misc]\r\n",
      "FREEZE         = False\r\n",
      "SAVE_LOGITS    = True\r\n",
      "# Considered random seeds:\r\n",
      "RANDOM_SEED = [1, 16, 601, 11, 20]\r\n",
      "\r\n",
      "[Paths]\r\n",
      "#../data/EmoNet/Emonet.tsv\r\n",
      "EMONET_PATH    =\r\n",
      "#../data/Hate/hatespeech-twitter.csv\r\n",
      "HATE_PATH      =\r\n",
      "#../data/optimism-twitter-data/processed/optimism_set0_train.csv\r\n",
      "OPT1M1_PATH    =\r\n",
      "OPT_PATH       =../../data/optimism-twitter-data/processed/\r\n",
      "#../data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\r\n",
      "SENT_PATH      =\r\n",
      "HISTORIES_PATH = ./histories/BERT/survey/RoBERTa\r\n",
      "DATA_STORE     = ../data/pck_objects/\r\n",
      "\r\n",
      "\r\n",
      "[Training]\r\n",
      "BATCH_SIZE   = 32\r\n",
      "PRE_TRAINING = True\r\n",
      "SETTING_1M1  = False\r\n",
      "MODEL_NAME   = roberta-base\r\n",
      "NUM_EPOCHS   = 3\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# MODEL_NAME = ['albert-base-v2'\\\r\n",
      "#               , 'bert-base-uncased', 'bert-large-uncased'\\\r\n",
      "#               , 'roberta-base', 'xlnet-base-cased',  ]\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../config/BERT/RoBERTa/RoBERTa_Hate_set0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "config_path = \"../config/BERT/RoBERTa/RoBERTa_Hate_set0\"\n",
    "config      = configparser.ConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "FREEZE         = config.getboolean(\"Misc\", \"FREEZE\")\n",
    "# SAVE_LOGITS    = config.getboolean(\"Misc\", \"SAVE_LOGITS\")\n",
    "# Considered random seeds:\n",
    "RANDOM_SEED    = eval(config.get('Misc', 'RANDOM_SEED'))#[1, 16, 601, 11, 20]\n",
    "\n",
    "#../data/EmoNet/Emonet.tsv\n",
    "EMONET_PATH    = \"../\" + config.get('Paths', 'EMONET_PATH')\n",
    "#../data/Hate/hatespeech-twitter.csv\n",
    "HATE_PATH      = \"../\" + config.get('Paths', 'HATE_PATH')\n",
    "#../data/optimism-twitter-data/processed/optimism_set0_train.csv\n",
    "OPT1M1_PATH    = \"../\" + config.get('Paths', 'OPT1M1_PATH')\n",
    "OPT_PATH       = \"../\" + config.get('Paths', 'OPT_PATH')\n",
    "#../data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\n",
    "SENT_PATH      = \"../\" + config.get('Paths', 'SENT_PATH')\n",
    "HISTORIES_PATH = \"../\" + config.get('Paths', 'HISTORIES_PATH')\n",
    "DATA_STORE     = \"../\" + config.get('Paths', 'DATA_STORE')\n",
    "\n",
    "BATCH_SIZE   = config.getint('Training', 'BATCH_SIZE')\n",
    "PRE_TRAINING = config.getboolean('Training', 'PRE_TRAINING')\n",
    "SETTING_1M1  = config.getboolean('Training', 'SETTING_1M1')\n",
    "MODEL_NAME   = config.get('Training', 'MODEL_NAME')#roberta-base\n",
    "NUM_EPOCHS   = config.getint('Training', 'NUM_EPOCHS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 16, 601, 11, 20], 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED, len(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../', '')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HATE_PATH, config.get('Paths', 'HATE_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"EmoNet\"      if config.get('Paths', 'EMONET_PATH') \\\n",
    "else \"Hate\"   if config.get('Paths', 'HATE_PATH')   \\\n",
    "else \"Opt1M1\" if config.get('Paths', 'OPT1M1_PATH') \\\n",
    "else \"Sent\"   if config.get('Paths', 'SENT_PATH')   \\\n",
    "else \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pre-training.\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 216/5939 [00:00<00:02, 2148.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded roberta-base tokenizer.\n",
      "Loaded Optimism data.\n",
      "\n",
      "Tokenizing Optimism data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5939/5939 [00:02<00:00, 2669.50it/s]\n",
      "100%|██████████| 768/768 [00:00<00:00, 2894.42it/s]\n",
      "100%|██████████| 768/768 [00:00<00:00, 2933.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Optimism data inputs/encodings.\n",
      "Preparing datasets in batches of size 32.\n",
      "Dataloaders lengths are: Train: 186, Test: 24, Val.: 24.\n",
      "\n",
      "\n",
      "DataLoaders prepared!\n",
      "Loading model...\n",
      "Loaded roberta-base model.\n",
      "Model: roberta-base has 125,237,762 parameters;\n",
      "Model: roberta-base ready for fine-tunning.\n",
      "\n",
      "No pretraining was performed!\n",
      "##############################\n",
      "### Run 1of1, using random seed 1:\n",
      "##############################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186it [00:25,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training Accuracy roberta-base: 0.7624\n",
      "  Average training loss roberta-base: 0.48\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation Accuracy roberta-base: 0.8216\n",
      "  Validation Loss roberta-base: 0.42\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test Accuracy roberta-base: 0.8307\n",
      "  Test Loss roberta-base: 0.43\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186it [00:25,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training Accuracy roberta-base: 0.8664\n",
      "  Average training loss roberta-base: 0.33\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation Accuracy roberta-base: 0.8281\n",
      "  Validation Loss roberta-base: 0.41\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test Accuracy roberta-base: 0.8307\n",
      "  Test Loss roberta-base: 0.42\n",
      "  Test took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186it [00:25,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training Accuracy roberta-base: 0.9103\n",
      "  Average training loss roberta-base: 0.24\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation Accuracy roberta-base: 0.8242\n",
      "  Validation Loss roberta-base: 0.50\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Test Accuracy roberta-base: 0.8307\n",
      "  Test Loss roberta-base: 0.50\n",
      "  Test took: 0:00:01\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:01:22 (h:mm:ss)\n",
      "\n",
      "Training stats saved at: .OPT_Hate_roberta-base_set0_it:1of1_ValAcc:0.82421875.csv.\n",
      "Saving logits:\n",
      "\n",
      " Accuracy of model roberta-base on train: 0.9624\n",
      " Loss: 0.11\n",
      " Computation took: 0:01:23\n",
      "\n",
      " Accuracy of model roberta-base on test: 0.8307\n",
      " Loss: 0.50\n",
      " Computation took: 0:00:02\n",
      "\n",
      " Accuracy of model roberta-base on val: 0.8242\n",
      " Loss: 0.50\n",
      " Computation took: 0:00:02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "EMONET_PATH = None#\"../../data/EmoNet/Emonet.tsv\"#None\n",
    "HATE_PATH   = \"../../data/Hate/hatespeech-twitter.csv\"#None\n",
    "OPT_PATH    = \"../../data/optimism-twitter-data/processed/\"#/optimism_set0_train.csv\"\n",
    "SENT_PATH   = None\n",
    "OPT1M1_PATH= None#\"../data/optimism-twitter-data/processed/optimism_set0_train.csv\"\n",
    "\n",
    "# PRE_TRAINING_NAME = \"EmoNet\"  if EMONET_PATH \\\n",
    "#                 else \"Hate\"   if HATE_PATH   \\\n",
    "#                 else \"Sent\"   if SENT_PATH   \\\n",
    "#                 else None\n",
    "# PRE_TRAINING = True\n",
    "PRE_TRAINING = False\n",
    "\n",
    "PRE_TRAINING_NAME = \"Opt1M1\" if (PRE_TRAINING and not(PRE_TRAINING_NAME)) else PRE_TRAINING_NAME\n",
    "\n",
    "PRE_TRAINING_NAME = \"EmoNet\"  if EMONET_PATH \\\n",
    "                else \"Hate\"   if HATE_PATH   \\\n",
    "                else \"Opt1M1\" if OPT1M1_PATH \\\n",
    "                else \"Sent\"   if SENT_PATH   \\\n",
    "                else None\n",
    "\n",
    "\n",
    "SETTING_1M1  = True\n",
    "SETTING_1M1  = False\n",
    "# MODEL_NAME = ['albert-base-v2'\\\n",
    "#               , 'bert-base-uncased', 'bert-large-uncased'\\\n",
    "#               , 'roberta-base', 'xlnet-base-cased',  ]\n",
    "# MODEL_NAME = 'albert-base-v2'\n",
    "MODEL_NAME = 'roberta-base'\n",
    "\n",
    "# Best for each model; and 1 for each pre-training dataset.\n",
    "NUM_EPOCHS = 3\n",
    "# FREEZE = True\n",
    "FREEZE = False\n",
    "HISTORIES_PATH = \".\"\n",
    "SAVE_LOGITS    = True\n",
    "\n",
    "DATA_STORE = \"../../data/pck_objects/\"\n",
    "# Considered random seeds:\n",
    "# RANDOM_SEED = [1, 16, 601, 11, 20]\n",
    "RANDOM_SEED = [1]\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "\n",
    "PRE_TRAINING_NAME = \"EmoNet\"  if EMONET_PATH \\\n",
    "                else \"Hate\"   if HATE_PATH   \\\n",
    "                else \"Opt1M1\" if OPT1M1_PATH \\\n",
    "                else \"Sent\"   if SENT_PATH   \\\n",
    "                else None\n",
    "if PRE_TRAINING:\n",
    "    print(f'Pre-training on {PRE_TRAINING_NAME}.')\n",
    "else:\n",
    "    print(\"No pre-training.\")\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('PyTorch:    No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "tokenizer = pick_tokenizer(model_name=MODEL_NAME)\n",
    "\n",
    "#################################################################\n",
    "#############PRE-Training data-loading procedure:################\n",
    "#################################################################\n",
    "if PRE_TRAINING:\n",
    "    #Read Pre-training data:\n",
    "    sentences_pre, labels_pre = read_pre_training(emo_path=EMONET_PATH   \\\n",
    "                                              , hate_path=HATE_PATH  \\\n",
    "                                              , opt1M1_path=OPT1M1_PATH \\\n",
    "                                              , sent_path=SENT_PATH)\n",
    "    #Train/test/val split:\n",
    "    (sentences_pre_train, labels_pre_train\\\n",
    "    , sentences_pre_test, labels_pre_test\\\n",
    "    , sentences_pre_val, labels_pre_val) = train_test_val_split(sentences_pre, labels_pre)\n",
    "    #Check if inputs they were generated before\n",
    "    data_store = DATA_STORE\n",
    "    if os.path.isfile(data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_tokenizer\"):\n",
    "        print(f\"Loading {PRE_TRAINING_NAME} tokenizations from {data_store}...\")\n",
    "        tokenizer                 = torch.load(data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_tokenizer\")\n",
    "        input_ids_pre_train       = torch.load(data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_input_ids_train\")\n",
    "        attention_masks_pre_train = torch.load(data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_attention_masks_train\")\n",
    "        input_ids_pre_test        = torch.load(data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_input_ids_test\")\n",
    "        attention_masks_pre_test  = torch.load(data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_attention_masks_test\")\n",
    "        input_ids_pre_val         = torch.load(data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_input_ids_val\")\n",
    "        attention_masks_pre_val   = torch.load(data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_attention_masks_val\")\n",
    "#         print(input_ids_pre_train.shape, attention_masks_pre_train.shape, labels_pre_train.shape)\n",
    "#         print(input_ids_pre_test.shape, attention_masks_pre_test.shape, labels_pre_test.shape)\n",
    "#         print(input_ids_pre_val.shape, attention_masks_pre_val.shape, labels_pre_val.shape)\n",
    "    else:\n",
    "        #Fit the tokenizer and save the obtained tokenizations:\n",
    "        print(f\"Tokenizing pre-training {PRE_TRAINING_NAME} data.\")\n",
    "        #Train encodings:\n",
    "        input_ids_pre_train, attention_masks_pre_train   = retrieve_data_encodings(sentences=sentences_pre_train\\\n",
    "                                                                       , tokenizer=tokenizer)\n",
    "        #Test encodings:\n",
    "        input_ids_pre_test, attention_masks_pre_test = retrieve_data_encodings(sentences=sentences_pre_test\\\n",
    "                                                                           , tokenizer=tokenizer)\n",
    "        #Validation encodings:\n",
    "        input_ids_pre_val, attention_masks_pre_val   = retrieve_data_encodings(sentences=sentences_pre_val\\\n",
    "                                                                           , tokenizer=tokenizer)\n",
    "\n",
    "        #Save tokenizations\n",
    "        print(f\"Saving {PRE_TRAINING_NAME} tokenizations at {data_store}...\")\n",
    "        torch.save(tokenizer, data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_tokenizer\")\n",
    "        torch.save(input_ids_pre_train      , data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_input_ids_train\")\n",
    "        torch.save(attention_masks_pre_train, data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_attention_masks_train\")\n",
    "        torch.save(input_ids_pre_test       , data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_input_ids_test\")\n",
    "        torch.save(attention_masks_pre_test , data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_attention_masks_test\")\n",
    "        torch.save(input_ids_pre_val        , data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_input_ids_val\")\n",
    "        torch.save(attention_masks_pre_val  , data_store + f\"{MODEL_NAME}_{PRE_TRAINING_NAME}_attention_masks_val\")\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "#############3\n",
    "##########################\n",
    "#Same data loading procedure when there is no pretraining:\n",
    "(sentences_train, labels_train\\\n",
    "        , sentences_test, labels_test\\\n",
    "        , sentences_val, labels_val) = load_opt_data(opt_df_path=OPT_PATH\\\n",
    "                                                     , setting_1M1=SETTING_1M1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nTokenizing Optimism data:\")\n",
    "input_ids_train, attention_masks_train = retrieve_data_encodings(sentences=sentences_train\\\n",
    "                                                                   , tokenizer=tokenizer)\n",
    "input_ids_test, attention_masks_test = retrieve_data_encodings(sentences=sentences_test\\\n",
    "                                                                   , tokenizer=tokenizer)\n",
    "input_ids_val, attention_masks_val = retrieve_data_encodings(sentences=sentences_val\\\n",
    "                                                                   , tokenizer=tokenizer)\n",
    "print(\"Generated Optimism data inputs/encodings.\")\n",
    "\n",
    "\n",
    "print(f\"Preparing datasets in batches of size {BATCH_SIZE}.\")\n",
    "\n",
    "if PRE_TRAINING:\n",
    "    print(\"Pre-training data inputs/encodings generated.\")\n",
    "    dataloader_pre_train, dataloader_pre_test, dataloader_pre_validation = retrieve_dataloaders(\\\n",
    "                   input_ids_pre_train, attention_masks_pre_train, labels_pre_train \\\n",
    "                 , input_ids_pre_test, attention_masks_pre_test, labels_pre_test  \\\n",
    "                 , input_ids_pre_val, attention_masks_pre_val, labels_pre_val     \\\n",
    "                 , batch_size=128)\n",
    "dataloader_train, dataloader_test, dataloader_validation = retrieve_dataloaders(\\\n",
    "                   input_ids_train, attention_masks_train, labels_train \\\n",
    "                 , input_ids_test, attention_masks_test, labels_test  \\\n",
    "                 , input_ids_val, attention_masks_val, labels_val     \\\n",
    "                 , batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"\\nDataLoaders prepared!\")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "if PRE_TRAINING:\n",
    "    num_labels = np.unique(labels_pre_train).shape[0]\n",
    "else:\n",
    "    num_labels = np.unique(labels_train).shape[0]\n",
    "\n",
    "\n",
    "model = pick_model(model_name=MODEL_NAME\\\n",
    "                   , num_labels=num_labels)\n",
    "\n",
    "\n",
    "#define optimizer:\n",
    "optimizer = Adam(model.parameters()\\\n",
    "                , lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                )\n",
    "\n",
    "\n",
    "print(f\"Model: {MODEL_NAME} has {model.num_parameters():,} parameters;\")\n",
    "# for p in params[-2:]:\n",
    "if FREEZE:\n",
    "    for p in list(model.parameters())[:-4]:\n",
    "        p.requires_grad = False\n",
    "    print(f\"Freezed model: {MODEL_NAME}\\'s hidden layers weights;\")\n",
    "else:\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "    print(f\"Model: {MODEL_NAME} ready for fine-tunning.\")\n",
    "\n",
    "\n",
    "# train_model(model, optimizer\\\n",
    "#             , batch_size=BATCH_SIZE, dataloader_train=dataloader_train     \\\n",
    "#             , dataloader_test=dataloader_test, dataloader_val=dataloader_validation  \\\n",
    "#             , num_epochs=1, random_seed=16\\\n",
    "#             , model_name=MODEL_NAME, weight_decay=False)\n",
    "\n",
    "\n",
    "\n",
    "if PRE_TRAINING:\n",
    "    print(\"\\n##############################\")\n",
    "    print(f\"### Pre-training on {PRE_TRAINING_NAME}:\")\n",
    "    print(\"##############################\")\n",
    "    print(\"\\nStarting pre-training procedure on %s...\" %PRE_TRAINING_NAME)\n",
    "    model, df_stats_pre = train_model(model, optimizer\\\n",
    "                    , batch_size=128\\\n",
    "                      #batch_size Should be 128\n",
    "                    , dataloader_train=dataloader_pre_train     \\\n",
    "                    , dataloader_test=dataloader_pre_test\\\n",
    "                      , dataloader_val=dataloader_pre_validation  \\\n",
    "                    , num_epochs=1\\\n",
    "                      , random_seed=16\\\n",
    "                , model_name=MODEL_NAME\\\n",
    "                  , pre_training_name=PRE_TRAINING_NAME\\\n",
    "                , pre_training=True  \\\n",
    "                , histories_path=\".\" \\\n",
    "                , weight_decay=False)\n",
    "\n",
    "    model_save_path = f\"../../models/{MODEL_NAME}_pre-trained_{PRE_TRAINING_NAME}\"\n",
    "    print(\"\\nPre-training on %s procedure finished!\" %PRE_TRAINING_NAME)\n",
    "    #Change here the final layer depending on the model:\n",
    "    model = change_model_top_layer(model, MODEL_NAME)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo pretraining was performed!\")\n",
    "    model_save_path = f\"../../models/{MODEL_NAME}_untrained\"\n",
    "    torch.save(model.state_dict(), f\"../../models/{MODEL_NAME}_untrained\")\n",
    "\n",
    "###########################3\n",
    "####TRAINING on OPT#########\n",
    "############################\n",
    "\n",
    "for i, rs in enumerate(RANDOM_SEED):\n",
    "    iteration_name=f\"{i+1}of{len(RANDOM_SEED)}\"\n",
    "    #reload model to initial values:\n",
    "    print(\"##############################\")\n",
    "    print(f\"### Run {iteration_name}, using random seed {rs}:\")\n",
    "    print(\"##############################\")\n",
    "\n",
    "    setting_name = \"set1M1\" if SETTING_1M1 else \"set0\"\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "    model, df_stats = train_model(model=model\\\n",
    "                , optimizer=optimizer\\\n",
    "                , batch_size=BATCH_SIZE\\\n",
    "                , dataloader_train=dataloader_train     \\\n",
    "                , dataloader_test=dataloader_test\\\n",
    "                  , dataloader_val=dataloader_validation  \\\n",
    "                , num_epochs=NUM_EPOCHS\\\n",
    "                , random_seed=rs\\\n",
    "                , model_name=MODEL_NAME\\\n",
    "                  , pre_training_name=PRE_TRAINING_NAME\\\n",
    "                , pre_training=False  \\\n",
    "                , histories_path=\".\" \\\n",
    "                , iteration=iteration_name \\\n",
    "                , weight_decay=False\n",
    "                    , setting=setting_name)\n",
    "\n",
    "    opt_df_train = pd.read_csv(OPT_PATH + f\"optimism_{setting_name}_train.csv\")\n",
    "    opt_df_test  = pd.read_csv(OPT_PATH + f\"optimism_{setting_name}_test.csv\")\n",
    "    opt_df_val   = pd.read_csv(OPT_PATH + f\"optimism_{setting_name}_validation.csv\")\n",
    "\n",
    "    print(\"Saving logits:\")\n",
    "    logits_df_train   = retrieve_logits(model        = model            \\\n",
    "                    , opt_df     = opt_df_train     \\\n",
    "                    , dataloader = dataloader_train \\\n",
    "                    , input_ids  = input_ids_train  \\\n",
    "                    , sentences  = sentences_train  \\\n",
    "                    , labels     = labels_train     \\\n",
    "                    , model_name = MODEL_NAME\\\n",
    "                    , batch_size = BATCH_SIZE\\\n",
    "                    , opt_data_path=OPT_PATH\\\n",
    "                    , pre_training_name=PRE_TRAINING_NAME \\\n",
    "                    , iteration=iteration_name\n",
    "                   , data_type=\"train\"\n",
    "                    , setting=setting_name)\n",
    "\n",
    "    logits_df_test   = retrieve_logits(model        = model            \\\n",
    "                , opt_df     = opt_df_test     \\\n",
    "                , dataloader = dataloader_test \\\n",
    "                , input_ids  = input_ids_test  \\\n",
    "                , sentences  = sentences_test  \\\n",
    "                , labels     = labels_test     \\\n",
    "                , model_name = MODEL_NAME\\\n",
    "                , batch_size = BATCH_SIZE\\\n",
    "                , opt_data_path=OPT_PATH\\\n",
    "                , pre_training_name=PRE_TRAINING_NAME\\\n",
    "                , iteration=iteration_name\n",
    "                  , data_type=\"test\"\n",
    "                    , setting=setting_name)\n",
    "\n",
    "    logits_df_val   = retrieve_logits(model        = model            \\\n",
    "            , opt_df     = opt_df_val     \\\n",
    "            , dataloader = dataloader_validation \\\n",
    "            , input_ids  = input_ids_val  \\\n",
    "            , sentences  = sentences_val  \\\n",
    "            , labels     = labels_val     \\\n",
    "            , model_name = MODEL_NAME\\\n",
    "            , batch_size = BATCH_SIZE\\\n",
    "            , opt_data_path=OPT_PATH\\\n",
    "            , pre_training_name=PRE_TRAINING_NAME\\\n",
    "            , iteration=iteration_name\n",
    "                 , data_type=\"val\"\n",
    "                    , setting=setting_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded roberta-base model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = ['albert-base-v2'\\\n",
    "              , 'bert-base-uncased', 'bert-large-uncased'\\\n",
    "              , 'roberta-base', 'xlnet-base-cased',  ]\n",
    "# MODEL_NAME = 'albert-base-v2'\n",
    "# final_layer_names = classifier, \n",
    "# pick_model(MODEL_NAME[0], 8) #albert -> classifier\n",
    "# pick_model(MODEL_NAME[1], 8)   #bert -> classifier \n",
    "pick_model(MODEL_NAME[3], 8)   #Roberta -> out_proj \n",
    "# pick_model(MODEL_NAME[4], 8)   #XLNet -> logits_proj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_model_top_layer(model, model_name):\n",
    "    \"\"\"\n",
    "        Change models' top layer based on its architecture.\n",
    "        Returns the model with only 2 output units.\n",
    "    \"\"\"\n",
    "    if model_name='albert-base-v2':\n",
    "        model.classifier = torch.nn.Linear(in_features=768\\\n",
    "                                        , out_features=2)\n",
    "    if model_name='bert-base-uncased':\n",
    "        model.classifier = torch.nn.Linear(in_features=768\\\n",
    "                                        , out_features=2)\n",
    "    if model_name='bert-large-uncased':\n",
    "        model.classifier = torch.nn.Linear(in_features=1024\\\n",
    "                                        , out_features=2)\n",
    "    if model_name=\"roberta-base\":\n",
    "        model.out_proj = torch.nn.Linear(in_features=768\\\n",
    "                                      , out_features=2)\n",
    "    if model_name=\"xlnet-base-cased\":\n",
    "        model.logits_proj = torch.nn.Linear(in_features=768\\\n",
    "                                         , out_features=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/optimism-twitter-data/processed/optimism_set0_train.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT_PATH + \"optimism_set0_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Username</th>\n",
       "      <th>AverageAnnotation</th>\n",
       "      <th>Original ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>@runge_kelly rest is good!! if you like tea an...</td>\n",
       "      <td>TheAnglophiler</td>\n",
       "      <td>1.25</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>916</td>\n",
       "      <td>dr. budiani-saberi is a medical anthropologist...</td>\n",
       "      <td>JessiKersi</td>\n",
       "      <td>0.00</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321</td>\n",
       "      <td>i want city to win. chelsea going up too far w...</td>\n",
       "      <td>Ajinkyaworld</td>\n",
       "      <td>1.50</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2127</td>\n",
       "      <td>you're annoying the piss out of me</td>\n",
       "      <td>TehhKota</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5643</td>\n",
       "      <td>@arapahoe_basin looking good for tomorrow's sk...</td>\n",
       "      <td>tomfricke</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>3531</td>\n",
       "      <td>@tgirlinterruptd @serynada person appreciates ...</td>\n",
       "      <td>WillJaxx</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>5884</td>\n",
       "      <td>@coryrocker are you excited though?</td>\n",
       "      <td>rdelvillano</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>1045</td>\n",
       "      <td>@urfavelatina is responsible for @lorealparisu...</td>\n",
       "      <td>JAsports70</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>4333</td>\n",
       "      <td>man.. we were the best.</td>\n",
       "      <td>x_VintageBesos</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>2234</td>\n",
       "      <td>@playboyespinosa im just kidding</td>\n",
       "      <td>playboyespinosa</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5939 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              Tweet  \\\n",
       "0            220  @runge_kelly rest is good!! if you like tea an...   \n",
       "1            916  dr. budiani-saberi is a medical anthropologist...   \n",
       "2            321  i want city to win. chelsea going up too far w...   \n",
       "3           2127                 you're annoying the piss out of me   \n",
       "4           5643  @arapahoe_basin looking good for tomorrow's sk...   \n",
       "...          ...                                                ...   \n",
       "5934        3531  @tgirlinterruptd @serynada person appreciates ...   \n",
       "5935        5884                @coryrocker are you excited though?   \n",
       "5936        1045  @urfavelatina is responsible for @lorealparisu...   \n",
       "5937        4333                            man.. we were the best.   \n",
       "5938        2234                   @playboyespinosa im just kidding   \n",
       "\n",
       "             Username  AverageAnnotation  Original ID  \n",
       "0      TheAnglophiler               1.25          220  \n",
       "1          JessiKersi               0.00          916  \n",
       "2        Ajinkyaworld               1.50          321  \n",
       "3            TehhKota              -1.80         2127  \n",
       "4           tomfricke               0.60         5643  \n",
       "...               ...                ...          ...  \n",
       "5934         WillJaxx               1.00         3531  \n",
       "5935      rdelvillano               0.60         5884  \n",
       "5936       JAsports70              -0.80         1045  \n",
       "5937   x_VintageBesos               1.00         4333  \n",
       "5938  playboyespinosa               0.60         2234  \n",
       "\n",
       "[5939 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(opt + \"optimism_set0_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All needed methods, placed in utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch:    No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('PyTorch:    No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_df_train          = pd.read_csv(\"../../data/optimism-twitter-data/processed/optimism_set0_train.csv\")\n",
    "opt_df_train          = pd.read_csv(\"../../data/optimism-twitter-data/processed/optimism_set1M1_train.csv\")\n",
    "opt_train_tweets      = opt_df_train.Tweet.values#np.array(opt_df_train[\"Tweet\"])\n",
    "# opt_train_gold_labels = np.array(opt_df_train[\"AverageAnnotation\"])\n",
    "\n",
    "opt_train_tweets\n",
    "opt_df_train.AverageAnnotation.values[-1]#[\"AverageAnn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3074, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_df_train[np.logical_or(opt_df_train.AverageAnnotation<=-1, opt_df_train.AverageAnnotation>=1)]#.shape\n",
    "opt_df_train[np.logical_or(opt_df_train.AverageAnnotation<=-1, opt_df_train.AverageAnnotation>=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt_df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0814582f2fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_labels\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbinarize_opt_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_df_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAverageAnnotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_opt_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_df_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAverageAnnotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'opt_df_train' is not defined"
     ]
    }
   ],
   "source": [
    "def binarize_opt_labels(gold_labels, max_negative_value=0):\n",
    "    '''\n",
    "        Binarize labels with respect to max_negative_value threshold.\n",
    "    '''\n",
    "    return torch.tensor(np.where(gold_labels<=0, 0, 1).astype(int))\n",
    "\n",
    "binarize_opt_labels(opt_df_train.AverageAnnotation.values), \\\n",
    "binarize_opt_labels(opt_df_train.AverageAnnotation.values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Training on Hate, data ready.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "EMONET_PATH = None\n",
    "HATE_PATH   = \"../../data/Hate/hatespeech-twitter.csv\"#None\n",
    "OPT_PATH    = None#\"../../data/optimism-twitter-data/processed/optimism_set0_train.csv\"\n",
    "SENT_PATH   = None\n",
    "\n",
    "PRE_TRAINING_NAME = \"EmoNet\"  if EMONET_PATH \\\n",
    "                else \"Hate\"   if HATE_PATH   \\\n",
    "                else \"Opt1M1\" if OPT_PATH    \\\n",
    "                else \"Sent\"   if SENT_PATH   \\\n",
    "                else None\n",
    "\n",
    "def read_pre_training(emo_path=None, hate_path=None, opt1M1_path=None, sent_path=None):\n",
    "    \"\"\"\n",
    "        Read pretraing data, if available.\n",
    "        Returns: \n",
    "            sentences -> np. array of objects;\n",
    "            labesl    -> np. array of ints.\n",
    "    \"\"\"\n",
    "    if emo_path:\n",
    "        emonet_df = pd.read_table(emo_path\\\n",
    "                              , names=[\"Tweet\", \"Emotion\"])\n",
    "        emonet_df[\"ELabel\"] = emonet_df.Emotion.astype('category').cat.codes\n",
    "        sentences = emonet_df.Tweet.values\n",
    "        labels    = torch.tensor(emonet_df.ELabel.values.astype(int))\n",
    "        print(\"Pre-Training on EmoNet, data ready.\")\n",
    "    if hate_path:\n",
    "        hate_df     = pd.read_csv(hate_path\\\n",
    "                      , names=[\"ID\", \"Tweet\", \"Label\"])\n",
    "        hate_df[\"HLabel\"] = hate_df.Label.astype('category').cat.codes\n",
    "        sentences         = hate_df.Tweet.values\n",
    "        labels            = torch.tensor(hate_df.HLabel.values.astype(int))\n",
    "        print(\"Pre-Training on Hate, data ready.\")\n",
    "    if opt1M1_path:\n",
    "        opt_df_train          = pd.read_csv(opt1M1_path)\n",
    "        opt_df_train          = opt_df_train[np.logical_or(opt_df_train.AverageAnnotation<=-1\\\n",
    "                                                     , opt_df_train.AverageAnnotation>=1)]\n",
    "        sentences = opt_df_train.Tweet.values\n",
    "        labels    = binarize_opt_labels(opt_df_train.AverageAnnotation.values)\n",
    "        print(\"Pre-Training on Optimism 1/-1, data ready.\")\n",
    "        \n",
    "    if sent_path:\n",
    "        sent_df   = pd.read_csv(sent_path\\\n",
    "                                , error_bad_lines=False) \n",
    "        sentences = sent_df.SentimentText.values\n",
    "        labels    = torch.tensor(sent_df.Sentiment.values.astype(int))\n",
    "        print(\"Pre-Training on Sentiment, data ready.\")\n",
    "    return sentences, labels\n",
    "\n",
    "# mock_sentences, mock_labels = read_pre_training(\"../../data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\"\\\n",
    "#                                                 , sent=True)\n",
    "sentences_pre, labels_pre = read_pre_training(emo_path=EMONET_PATH   \\\n",
    "                                              , hate_path=HATE_PATH  \\\n",
    "                                              , opt1M1_path=OPT_PATH \\\n",
    "                                              , sent_path=SENT_PATH)\n",
    "\n",
    "labels_pre#, mock_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read train test split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"on the other side of all of what you're going through.is the fulfillment of the promises god's made to you!you'll need energy to get there!\",\n",
       "       '@benrobinson09 @samswinn i spent my night making starters and desserts for a bunch of cunts',\n",
       "       \"@broflamingo // there's a cutoff where it's no longer loli and its just..uh...pedo crap. right?\",\n",
       "       ...,\n",
       "       \"during college i'm so motivated then i get home and i'm like nahhh tv shows\",\n",
       "       'we have to win',\n",
       "       \"i'm done with shopping for the rest of the year. maybe for the rest of my life. i hate shopping. it's the most annoying thing in the world.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(mock_sentences)\n",
    "mock_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted pre-training data.\n",
      "Train shapes: (47356,) torch.Size([47356])\n",
      "Test shapes: (5919,) torch.Size([5919])\n",
      "Validation shapes: (5920,) torch.Size([5920])\n",
      "Loaded Optimism data.\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_SIZE = .8\n",
    "# TEST_SIZE  = .1\n",
    "# VAL_SIZE   = .1\n",
    "\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# SETTING_1M1 = True\n",
    "# SETTING_1M1 = False\n",
    "\n",
    "# setting_name = \"set1M1\" if SETTING_1M1 else \"set0\"\n",
    "\n",
    "def train_test_val_split(sentences, labels\\\n",
    "                         , train_size=.8, test_size=.1\\\n",
    "                         , r_seed=16):\n",
    "    \"\"\"\n",
    "        Split sentences and labels into train test val.\n",
    "        val_size is considered as 1-train_size-test_size.\n",
    "        \n",
    "        Returns:\n",
    "            (sentences_train, labels_train\n",
    "            , sentences_test, labels_test\n",
    "            , sentences_val, labels_val)\n",
    "    \"\"\"\n",
    "    np.random.seed(r_seed)\n",
    "    indices = np.arange(len(sentences))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    #Shuffle sentences & labels:\n",
    "    sentences = sentences[indices]\n",
    "    labels    = labels[indices]\n",
    "    \n",
    "    #Split data\n",
    "    num_training_samples = int(train_size * len(sentences))\n",
    "    num_test_samples     = int(test_size  * len(sentences))\n",
    "    \n",
    "    sentences_train = sentences[:num_training_samples]\n",
    "    labels_train    = labels[:num_training_samples]\n",
    "    \n",
    "    sentences_test  = sentences[num_training_samples:num_training_samples+num_test_samples]\n",
    "    labels_test     = labels[num_training_samples:num_training_samples+num_test_samples]\n",
    "        \n",
    "    sentences_val   = sentences[num_training_samples+num_test_samples:]\n",
    "    labels_val      = labels[num_training_samples+num_test_samples:]\n",
    "    \n",
    "    print(\"Splitted pre-training data.\")\n",
    "    \n",
    "    print(\"Train shapes:\", sentences_train.shape, labels_train.shape)\n",
    "    print(\"Test shapes:\", sentences_test.shape, labels_test.shape)\n",
    "    print(\"Validation shapes:\", sentences_val.shape, labels_val.shape)\n",
    "    \n",
    "    return (sentences_train, labels_train\\\n",
    "            , sentences_test, labels_test\\\n",
    "            , sentences_val, labels_val)\n",
    "    \n",
    "\n",
    "    \n",
    "def load_opt_data(opt_df_path, setting_1M1=False):\n",
    "    \"\"\"\n",
    "        Load prepared/splitted OPT data, from path.\n",
    "        \n",
    "        Returns:\n",
    "            (sentences_train, labels_train\n",
    "            , sentences_test, labels_test\n",
    "            , sentences_val, labels_val)\n",
    "    \"\"\"\n",
    "    #opt_data_path = \"../../data/optimism-twitter-data/processed/\"\n",
    "    setting_name = \"set1M1\" if setting_1M1 else \"set0\"\n",
    "    opt_df_train = pd.read_csv(opt_df_path + f\"optimism_{setting_name}_train.csv\")\n",
    "    opt_df_test  = pd.read_csv(opt_df_path + f\"optimism_{setting_name}_test.csv\")\n",
    "    opt_df_val   = pd.read_csv(opt_df_path + f\"optimism_{setting_name}_validation.csv\")\n",
    "\n",
    "    sentences_train = opt_df_train.Tweet.values\n",
    "    labels_train    = binarize_opt_labels(opt_df_train.AverageAnnotation.values)\n",
    "    \n",
    "    sentences_test  = opt_df_test.Tweet.values\n",
    "    labels_test     = binarize_opt_labels(opt_df_test.AverageAnnotation.values)\n",
    "\n",
    "    sentences_val   = opt_df_val.Tweet.values\n",
    "    labels_val      = binarize_opt_labels(opt_df_val.AverageAnnotation.values)\n",
    "    \n",
    "    print(\"Loaded Optimism data.\")\n",
    "    \n",
    "    return (sentences_train, labels_train\\\n",
    "        , sentences_test, labels_test\\\n",
    "        , sentences_val, labels_val)\n",
    "    \n",
    "\n",
    "PRE_TRAINING = True\n",
    "# PRE_TRAINING = False\n",
    "if PRE_TRAINING:\n",
    "    (sentences_pre_train, labels_pre_train\\\n",
    "    , sentences_pre_test, labels_pre_test\\\n",
    "    , sentences_pre_val, labels_pre_val) = train_test_val_split(sentences_pre, labels_pre)\n",
    "    \n",
    "    \n",
    "(sentences_train, labels_train\\\n",
    "        , sentences_test, labels_test\\\n",
    "        , sentences_val, labels_val) = load_opt_data(opt_df_path=\"../../data/optimism-twitter-data/processed/\"\\\n",
    "                                                     , setting_1M1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([307]), (307,))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pre_test.shape, sentences_pre_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded albert-base-v2 tokenizer.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer, BertTokenizer\n",
    "# from transformers import DistilBertTokenizer\n",
    "from transformers import RobertaTokenizer, XLNetTokenizer\n",
    "# from transformers import RobertaTokenizer\n",
    "# from transformers import AlbertTokenizer\n",
    "# # from transformers import ElectraTokenizer\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# GPU_AVAILABLE = False\n",
    "# GPU_AVAILABLE = True\n",
    "#Considered models\n",
    "MODEL_NAME = ['albert-base-v2'\\\n",
    "              , 'bert-base-uncased', 'bert-large-uncased'\\\n",
    "              , 'roberta-base', 'xlnet-base-cased',  ]\n",
    "MODEL_NAME = 'albert-base-v2'\n",
    "\n",
    "def pick_tokenizer(model_name='albert-base-v2'):\n",
    "    \"\"\"\n",
    "        Return specified tokenizer:\n",
    "        Available model names:\n",
    "        ['albert-base-v2'\\\n",
    "          , 'bert-base-uncased', 'bert-large-uncased'\\\n",
    "          , 'roberta-base', 'xlnet-base-cased',  ]\n",
    "    \"\"\"\n",
    "    if model_name == 'albert-base-v2':\n",
    "        tokenizer = AlbertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    if model_name == 'bert-base-uncased':\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    if model_name == 'bert-large-uncased':\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    if model_name == 'roberta-base':\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    if model_name == 'xlnet-base-cased':\n",
    "        tokenizer = XLNetTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    \n",
    "    print(f'Loaded {model_name} tokenizer.')\n",
    "    return tokenizer\n",
    "        \n",
    "# Load the BERT tokenizer.\n",
    "# print('Loading BERT tokenizer...')\n",
    "# # if torch.cuda.is_available():  \n",
    "# if GPU_AVAILABLE:\n",
    "#     tokenizer1 = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# #     tokenizer1 = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
    "#     # tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "#     tokenizer2 = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
    "#     # tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased', do_lower_case=True)\n",
    "# #     tokenizer2 = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "#     # tokenizer = ElectraTokenizer.from_pretrained('google/electra-large-discriminator', do_lower_case=True)\n",
    "# #     tokenizer = AutoTokenizer.from_pretrained(\"ssun32/bert_base_nli_turkle\")\n",
    "\n",
    "# else:\n",
    "#     tokenizer1 = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)\n",
    "#     tokenizer2 = AlbertTokenizer.from_pretrained('albert-large-v2', do_lower_case=True)\n",
    "#     print(f\"Loaded albert-base-v2 as tokenizer1.\")\n",
    "#     print(f\"Loaded albert-large-v2 as tokenizer2.\")\n",
    "    \n",
    "\n",
    "# GPU_AVAILABLE = True\n",
    "# mock_tokenizer = pick_tokenizer(model_name=\"xlnet-base-cased\")\n",
    "tokenizer = pick_tokenizer(model_name='albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 64\n",
    "\n",
    "def retrieve_data_encodings(sentences, tokenizer, max_len=64):\n",
    "    \"\"\"\n",
    "        Returns input_ids & attentin_masks\n",
    "        out of list of sentences.\n",
    "    \"\"\"\n",
    "    input_ids       = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in tqdm(sentences):\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        # The method`encode` returns only the phrase encoding, \n",
    "        # not the masks as well.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_len,           # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_pickle(file_name):\n",
    "    \"\"\"\n",
    "        Return pickled object from location.\n",
    "    \"\"\"\n",
    "    return torch.load(file_name)\n",
    "#     with open(file_name, \"rb\") as file:\n",
    "#         pck_object = pickle.load(file)\n",
    "#     return pck_object\n",
    "\n",
    "def save_pickle(obj, file_name):\n",
    "    \"\"\"\n",
    "        Save obj as pickle to location.\n",
    "    \"\"\"\n",
    "    torch.save(obj, file_name)\n",
    "#     with open(file_name, \"wb\") as file:\n",
    "#         pickle.dump(obj, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 196/47356 [00:00<00:24, 1956.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing pre-training Hate data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47356/47356 [00:24<00:00, 1906.69it/s]\n",
      "100%|██████████| 5919/5919 [00:04<00:00, 1428.84it/s]\n",
      "100%|██████████| 5920/5920 [00:03<00:00, 1866.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Hate tokenizations at ../../data/pck_objects/...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 236/3015 [00:00<00:01, 2356.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training data inputs/encodings generated.\n",
      "\n",
      "Tokenizing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3015/3015 [00:01<00:00, 2587.77it/s]\n",
      "100%|██████████| 416/416 [00:00<00:00, 2711.65it/s]\n",
      "100%|██████████| 416/416 [00:00<00:00, 2628.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Optimism data inputs/encodings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "if PRE_TRAINING:\n",
    "    #Check if inputs they were generated before\n",
    "        \n",
    "    data_store = \"../../data/pck_objects/\"\n",
    "    if os.path.isfile(data_store + f\"{PRE_TRAINING_NAME}_tokenizer\"):\n",
    "        print(f\"Loading {PRE_TRAINING_NAME} tokenizations from {data_store}...\")\n",
    "        tokenizer                 = torch.load(data_store + f\"{PRE_TRAINING_NAME}_tokenizer\")\n",
    "        input_ids_pre_train       = torch.load(data_store + f\"{PRE_TRAINING_NAME}_input_ids_train\")\n",
    "        attention_masks_pre_train = torch.load(data_store + f\"{PRE_TRAINING_NAME}_attention_masks_train\")\n",
    "        input_ids_pre_test        = torch.load(data_store + f\"{PRE_TRAINING_NAME}_input_ids_test\")\n",
    "        attention_masks_pre_test  = torch.load(data_store + f\"{PRE_TRAINING_NAME}_attention_masks_test\")\n",
    "        input_ids_pre_val         = torch.load(data_store + f\"{PRE_TRAINING_NAME}_input_ids_val\")\n",
    "        attention_masks_pre_val   = torch.load(data_store + f\"{PRE_TRAINING_NAME}_attention_masks_val\")\n",
    "        \n",
    "        print(input_ids_pre_train.shape, attention_masks_pre_train.shape, labels_pre_train.shape)\n",
    "        print(input_ids_pre_test.shape, attention_masks_pre_test.shape, labels_pre_test.shape)\n",
    "        print(input_ids_pre_val.shape, attention_masks_pre_val.shape, labels_pre_val.shape)\n",
    "    else:\n",
    "        #Fit the tokenizer and save the obtained tokenizations:\n",
    "        print(f\"Tokenizing pre-training {PRE_TRAINING_NAME} data.\")\n",
    "        #Train encodings:\n",
    "        input_ids_pre_train, attention_masks_pre_train   = retrieve_data_encodings(sentences=sentences_pre_train\\\n",
    "                                                                       , tokenizer=tokenizer)\n",
    "        #Test encodings:\n",
    "        input_ids_pre_test, attention_masks_pre_test = retrieve_data_encodings(sentences=sentences_pre_test\\\n",
    "                                                                           , tokenizer=tokenizer)\n",
    "        #Validation encodings:\n",
    "        input_ids_pre_val, attention_masks_pre_val   = retrieve_data_encodings(sentences=sentences_pre_val\\\n",
    "                                                                           , tokenizer=tokenizer)\n",
    "        \n",
    "        #Save tokenizations\n",
    "        print(f\"Saving {PRE_TRAINING_NAME} tokenizations at {data_store}...\")\n",
    "        torch.save(tokenizer, data_store + f\"{PRE_TRAINING_NAME}_tokenizer\")\n",
    "        torch.save(input_ids_pre_train      , data_store + f\"{PRE_TRAINING_NAME}_input_ids_train\")\n",
    "        torch.save(attention_masks_pre_train, data_store + f\"{PRE_TRAINING_NAME}_attention_masks_train\")\n",
    "        torch.save(input_ids_pre_test       , data_store + f\"{PRE_TRAINING_NAME}_input_ids_test\")\n",
    "        torch.save(attention_masks_pre_test , data_store + f\"{PRE_TRAINING_NAME}_attention_masks_test\")\n",
    "        torch.save(input_ids_pre_val        , data_store + f\"{PRE_TRAINING_NAME}_input_ids_val\")\n",
    "        torch.save(attention_masks_pre_val  , data_store + f\"{PRE_TRAINING_NAME}_attention_masks_val\")\n",
    "    \n",
    "    print(\"Pre-training data inputs/encodings generated.\")\n",
    "    \n",
    "\n",
    "print(\"\\nTokenizing \")\n",
    "input_ids_train, attention_masks_train = retrieve_data_encodings(sentences=sentences_train\\\n",
    "                                                                   , tokenizer=tokenizer)\n",
    "input_ids_test, attention_masks_test = retrieve_data_encodings(sentences=sentences_test\\\n",
    "                                                                   , tokenizer=tokenizer)\n",
    "input_ids_val, attention_masks_val = retrieve_data_encodings(sentences=sentences_val\\\n",
    "                                                                   , tokenizer=tokenizer)\n",
    "print(\"Generated Optimism data inputs/encodings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing datasets in batches of size 4.\n",
      "Dataloaders lengths are: Train: 370, Test: 47, Val.: 47.\n",
      "\n",
      "Dataloaders lengths are: Train: 754, Test: 104, Val.: 104.\n",
      "\n",
      "\n",
      "DataLoaders prepared!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset#, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "# batch_size = 16\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "#     batch_size = 256\n",
    "#     batch_size = 128\n",
    "#     batch_size = 64\n",
    "    BATCH_SIZE = 32\n",
    "else:\n",
    "    BATCH_SIZE = 4\n",
    "\n",
    "\n",
    "def retrieve_dataloaders(ids_train, masks_train, labels_train \\\n",
    "                         , ids_test, masks_test, labels_test  \\\n",
    "                         , ids_val, masks_val, labels_val     \\\n",
    "                         , batch_size=32):\n",
    "    \"\"\"\n",
    "        Transform lists of inputs into dataloaders.\n",
    "        Returns:\n",
    "        dataloader_train, dataloader_test, dataloader_validation\n",
    "    \"\"\"\n",
    "    # Combine the training inputs into a TensorDataset.\n",
    "    dataset_train    = TensorDataset(ids_train, masks_train, labels_train)\n",
    "    dataloader_train = DataLoader(\n",
    "                dataset_train,  # The training samples.\n",
    "                sampler = RandomSampler(dataset_train), # Select batches randomly\n",
    "                batch_size = batch_size # Trains with this batch size.\n",
    "            )\n",
    "    dataset_test = TensorDataset(ids_test, masks_test, labels_test)\n",
    "    dataloader_test = DataLoader(\n",
    "            dataset_test, # The validation samples.\n",
    "            sampler = SequentialSampler(dataset_test), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "    \n",
    "    dataset_val = TensorDataset(ids_val, masks_val, labels_val)\n",
    "    dataloader_validation = DataLoader(\n",
    "            dataset_val, # The validation samples.\n",
    "            sampler = SequentialSampler(dataset_val), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "    \n",
    "    print(\"Dataloaders lengths are: Train: %d, Test: %d, Val.: %d.\\n\" \\\n",
    "          %(len(dataloader_train), len(dataloader_test), len(dataloader_validation)))\n",
    "    return dataloader_train, dataloader_test, dataloader_validation\n",
    "    \n",
    "# dataset_train2 = TensorDataset(input_ids_train2, attention_masks_train2, labels_train)\n",
    "\n",
    "# dataset_test1 = TensorDataset(input_ids_test1, attention_masks_test1, labels_test)\n",
    "# dataset_test2 = TensorDataset(input_ids_test2, attention_masks_test2, labels_test)\n",
    "\n",
    "# dataset_dev1 = TensorDataset(input_ids_dev1, attention_masks_dev1, labels_dev)\n",
    "# dataset_dev2 = TensorDataset(input_ids_dev2, attention_masks_dev2, labels_dev)\n",
    "\n",
    "# print('{:>5,} training samples'.format(len(dataset_train1)))\n",
    "# print('{:>5,} validation samples'.format(len(dataset_dev1)))\n",
    "# print('{:>5,} test samples'.format(len(dataset_test1)))\n",
    "\n",
    "# dataset_train1.tensors[0][0][:10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Preparing datasets in batches of size {BATCH_SIZE}.\")\n",
    "# batch_size = 256    \n",
    "\n",
    "\n",
    "\n",
    "if PRE_TRAINING:\n",
    "    dataloader_pre_train, dataloader_pre_test, dataloader_pre_validation = retrieve_dataloaders(\\\n",
    "                   input_ids_pre_train, attention_masks_pre_train, labels_pre_train \\\n",
    "                 , input_ids_pre_test, attention_masks_pre_test, labels_pre_test  \\\n",
    "                 , input_ids_pre_val, attention_masks_pre_val, labels_pre_val     \\\n",
    "                 , batch_size=128)\n",
    "\n",
    "dataloader_train, dataloader_test, dataloader_validation = retrieve_dataloaders(\\\n",
    "                   input_ids_train, attention_masks_train, labels_train \\\n",
    "                 , input_ids_test, attention_masks_test, labels_test  \\\n",
    "                 , input_ids_val, attention_masks_val, labels_val     \\\n",
    "                 , batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"\\nDataLoaders prepared!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3015, 64]), torch.Size([2459, 64]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input_ids_train.shape), (input_ids_pre_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded albert-base-v2 model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare model:\n",
    "\n",
    "from transformers import AlbertForSequenceClassification, BertForSequenceClassification\n",
    "from transformers import RobertaForSequenceClassification, XLNetForSequenceClassification\n",
    "\n",
    "# MODEL_NAME = ['albert-base-v2'\\\n",
    "#               , 'bert-base-uncased', 'bert-large-uncased'\\\n",
    "#               , 'roberta-base', 'xlnet-base-cased',  ]\n",
    "# MODEL_NAME = 'albert-base-v2'\n",
    "\n",
    "\n",
    "def pick_model(model_name, num_labels):\n",
    "    \"\"\"\n",
    "        Return specified model:\n",
    "        Available model names:\n",
    "        ['albert-base-v2'\\\n",
    "          , 'bert-base-uncased', 'bert-large-uncased'\\\n",
    "          , 'roberta-base', 'xlnet-base-cased',  ]\n",
    "    \"\"\"\n",
    "    if model_name == 'albert-base-v2':   \n",
    "        model = AlbertForSequenceClassification.from_pretrained(\n",
    "            model_name, \n",
    "            num_labels = num_labels, \n",
    "            output_attentions = False, # Whether the model returns attentions weights.\n",
    "            output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "        )\n",
    "    if model_name in ('bert-base-uncased', 'bert-large-uncased'):\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels = num_labels,\n",
    "            output_attentions = False, # Whether the model returns attentions weights.\n",
    "            output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "        )\n",
    "    if model_name == 'roberta-base':\n",
    "        model = RobertaForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels = num_labels,\n",
    "            output_attentions = False, # Whether the model returns attentions weights.\n",
    "            output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "        )\n",
    "    if model_name == 'xlnet-base-cased':\n",
    "        model = XLNetForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels = num_labels,\n",
    "            output_attentions = False, # Whether the model returns attentions weights.\n",
    "            output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "        )\n",
    "    \n",
    "    print(f'Loaded {model_name} model.')\n",
    "    return model\n",
    "     \n",
    "    \n",
    "if PRE_TRAINING:\n",
    "    num_labels = np.unique(labels_pre_train).shape[0]\n",
    "else:\n",
    "    num_labels = np.unique(labels_train).shape[0]\n",
    "    \n",
    "\n",
    "model = pick_model(model_name=MODEL_NAME\\\n",
    "                   , num_labels=num_labels)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: albert-base-v2 has 11,685,122 parameters;\n",
      "\n",
      "Model: albert-base-v2 ready for fine-tunning.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "#define optimizer:\n",
    "optimizer = Adam(model.parameters()\\\n",
    "                , lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                )\n",
    "\n",
    "# FREEZE = True\n",
    "FREEZE = False\n",
    "\n",
    "print(f\"Model: {MODEL_NAME} has {model.num_parameters():,} parameters;\")\n",
    "# for p in params[-2:]:\n",
    "if FREEZE:\n",
    "    for p in list(model.parameters())[:-4]:\n",
    "        p.requires_grad = False\n",
    "    print(f\"\\nFreezed model: {MODEL_NAME}\\'s hidden layers weights;\")\n",
    "else:\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "    print(f\"\\nModel: {MODEL_NAME} ready for fine-tunning.\")\n",
    "\n",
    "# Best for each model; and 1 for each pre-training dataset.\n",
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels, F1=False):\n",
    "    if F1:\n",
    "        return f1_score(preds.argmax(axis=1), labels, average=\"weighted\")\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considered random seeds:\n",
    "# RANDOM_SEED = [1, 16, 601, 11, 20]\n",
    "RANDOM_SEED = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training Accuracy albert-base-v2: 0.0013\n",
      "  Average training loss albert-base-v2: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "Running Validation...\n",
      "  Validation Accuracy albert-base-v2: 0.0072\n",
      "  Validation Loss albert-base-v2: 0.01\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "Running Test...\n",
      "  Test Accuracy albert-base-v2: 0.0024\n",
      "  Test Loss albert-base-v2: 0.01\n",
      "  Test took: 0:00:01\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:00:03 (h:mm:ss)\n",
      "Training stats saved at: ./OPT_albert-base-v2_ValAcc:0.007211538461538462.csv.\n"
     ]
    }
   ],
   "source": [
    "#Training loop.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, optimizer\\\n",
    "                , batch_size, dataloader_train     \\\n",
    "                , dataloader_test, dataloader_val  \\\n",
    "                , num_epochs, random_seed\\\n",
    "                , model_name, pre_training_name=None\\\n",
    "                , pre_training=False  \\\n",
    "                , histories_path=\".\" \\\n",
    "                , weight_decay=False):\n",
    "    \"\"\"\n",
    "        Train the the given `model` using `optimizer`, `batch_size`\n",
    "        and the provided Dataloaders, for `num_epochs` with `random_seed`.\n",
    "        model_name:        should be a cosntant (`MODEL_NAME`) \n",
    "            in the program (see `pick_model`);\n",
    "        pre_training_name: if the model was/is on pre-training \n",
    "            (`PRE_TRAINING_NAME` constant) ;\n",
    "        pre_training:      True of False if pre-training data;\n",
    "        histories_path:    Where to save training stats;\n",
    "        weight_decay:      optimizer decay weights (untested feature).\n",
    "        \n",
    "        Returns: Training stats as pandas DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # This training code is based on the `run_glue.py` script here:\n",
    "    # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "    # and on:\n",
    "    # https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX\n",
    "    # Set the seed value all over the place to make this reproducible.\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    \n",
    "    if weight_decay:\n",
    "        # Create the learning rate scheduler.\n",
    "        scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
    "                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                            num_training_steps = len(dataloader_train) * num_epochs)\n",
    "\n",
    "    \n",
    "    #Criterion:\n",
    "    cse_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "    \n",
    "    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "\n",
    "    # For each epoch...\n",
    "    for epoch_i in (range(num_epochs)):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss     = 0\n",
    "        total_train_accuracy = 0\n",
    "\n",
    "        # Put the model into training mode. Don't be mislead--the call to \n",
    "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "        # `dropout` and `batchnorm` layers behave differently during training\n",
    "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in tqdm(enumerate(dataloader_train)):\n",
    "            if not(GPU_AVAILABLE) and step % 120 == 1:\n",
    "                break\n",
    "                # Report progress.\n",
    " \n",
    "            # Unpack this training batch from our dataloader. \n",
    "            b_input_ids  = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels     = batch[2].to(device)\n",
    "            # Always clear any previously calculated gradients before performing a\n",
    "            # backward pass. PyTorch doesn't do this automatically because \n",
    "            # accumulating the gradients is \"convenient while training RNNs\". \n",
    "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "            model.zero_grad()          \n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "#             loss, logits = model1(b_input_ids, \n",
    "#                                  token_type_ids=None, \n",
    "#                                  attention_mask=b_input_mask, \n",
    "#                                  labels=b_labels)\n",
    "            logits = model(b_input_ids, \n",
    "               token_type_ids=None, \n",
    "               attention_mask=b_input_mask)[0]\n",
    "            loss   = cse_loss(logits, b_labels)\n",
    "            \n",
    "            # Accumulate the training loss over all of the batches so that we can\n",
    "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "            # single value; the `.item()` function just returns the Python value \n",
    "            # from the tensor.\n",
    "            total_train_loss += loss.item() * (len(logits)/BATCH_SIZE)\n",
    "\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0.\n",
    "            # This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and take a step using the computed gradient.\n",
    "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "            # modified based on their gradients, the learning rate, etc.\n",
    "            optimizer.step()\n",
    "            if weight_decay:\n",
    "                # Update the learning rate.\n",
    "                scheduler.step()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits    = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            total_train_accuracy += flat_accuracy(logits, label_ids, F1=False) * (len(logits)/BATCH_SIZE)\n",
    "\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_train_accuracy = total_train_accuracy / len(dataloader_train)\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(dataloader_train)             \n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(f\"  Average training Accuracy {model_name}: {avg_train_accuracy:.4f}\")\n",
    "        print(f\"  Average training loss {model_name}: {avg_train_loss:.2f}\")\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "\n",
    "        ###################################################\n",
    "        #############Validation Stats######################\n",
    "        ###################################################\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "        \n",
    "        # Tracking variables \n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss     = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in dataloader_val:\n",
    "            b_input_ids  = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels     = batch[2].to(device)\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "                logits = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask)[0]\n",
    "                loss   = cse_loss(logits, b_labels)\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item() * (len(logits)/BATCH_SIZE)\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits     = logits.detach().cpu().numpy()\n",
    "            label_ids  = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids, F1=False) * (len(logits)/BATCH_SIZE)\n",
    "\n",
    "            if not(torch.cuda.is_available()):\n",
    "                break\n",
    "\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy = total_eval_accuracy / len(dataloader_val)\n",
    "        print(f\"  Validation Accuracy {model_name}: {avg_val_accuracy:.4f}\")\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(dataloader_val)\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(f\"  Validation Loss {model_name}: {avg_val_loss:.2f}\")\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "\n",
    "        ###################################################\n",
    "        #############Test Stats############################\n",
    "        ###################################################\n",
    "        print(\"\")\n",
    "        print(\"Running Test...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_test_accuracy = 0\n",
    "        total_test_loss     = 0\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in dataloader_test:       \n",
    "            b_input_ids  = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels     = batch[2].to(device)\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "                logits = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask)[0]\n",
    "                loss   = cse_loss(logits, b_labels)\n",
    "            # Accumulate the validation loss.\n",
    "            total_test_loss += loss.item() * (len(logits)/BATCH_SIZE)\n",
    "            # Move logits and labels to CPU\n",
    "            logits    = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_test_accuracy += flat_accuracy(logits, label_ids, F1=False) * (len(logits)/BATCH_SIZE)\n",
    "            if not(torch.cuda.is_available()):\n",
    "                break\n",
    "\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_test_accuracy = total_test_accuracy / len(dataloader_test)\n",
    "        print(f\"  Test Accuracy {model_name}: {avg_test_accuracy:.4f}\")\n",
    "        \n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_test_loss = total_test_loss / len(dataloader_test)\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        test_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(f\"  Test Loss {model_name}: {avg_test_loss:.2f}\")\n",
    "        print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                f'Training Loss': avg_train_loss,\n",
    "                f'Valid. Loss': avg_val_loss,\n",
    "                f'Test. Loss': avg_test_loss,\n",
    "                f'Training Accur.': avg_train_accuracy,\n",
    "                f'Valid. Accur.': avg_val_accuracy,\n",
    "                f'Test Accur.': avg_test_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time,\n",
    "                'Test Time': test_time\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "    \n",
    "    #############################\n",
    "    #Saving training stats:\n",
    "    df_stats  = pd.DataFrame(data=training_stats).set_index('epoch')\n",
    "    val_acc   = df_stats[\"Valid. Accur.\"].values[-1]#.max()\n",
    "    data_name = pre_training_name + \"_\" if pre_training \\\n",
    "            else f\"OPT_{pre_training_name+'_' if pre_training_name else ''}\"\n",
    "    hist_fn = f\"{histories_path}/{data_name}{model_name}_ValAcc:{val_acc}.csv\"\n",
    "    df_stats.to_csv(hist_fn)\n",
    "    print(f\"\\nTraining stats saved at: {hist_fn}.\")\n",
    "    \n",
    "    \n",
    "    return model, df_stats\n",
    "    \n",
    "train_model(model, optimizer\\\n",
    "            , batch_size=BATCH_SIZE, dataloader_train=dataloader_train     \\\n",
    "            , dataloader_test=dataloader_test, dataloader_val=dataloader_validation  \\\n",
    "            , num_epochs=1, random_seed=16\\\n",
    "            , model_name=MODEL_NAME, weight_decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model, optimizer\\\n",
    "#             , batch_size=BATCH_SIZE, dataloader_train=dataloader_train     \\\n",
    "#             , dataloader_test=dataloader_test, dataloader_val=dataloader_validation  \\\n",
    "#             , num_epochs=1, random_seed=16\\\n",
    "#             , model_name=MODEL_NAME, weight_decay=False)\n",
    "\n",
    "HISTORIES_PATH = \".\"\n",
    "SAVE_LOGITS    = True\n",
    "\n",
    "if PRE_TRAINING:\n",
    "    train_model(model, optimizer\\\n",
    "            , batch_size=1, dataloader_train=dataloader_pre_train     \\\n",
    "            , dataloader_test=dataloader_pre_test, dataloader_val=dataloader_pre_validation  \\\n",
    "            , num_epochs=1, random_seed=16\\\n",
    "            , model_name=MODEL_NAME, weight_decay=False)\n",
    "    torch.save(model.state_dict(), f\"../../models/{MODEL_NAME}_pre-trained_{PRE_TRAINING_NAME}\")\n",
    "else:\n",
    "    torch.save(model.state_dict(), f\"../../models/{MODEL_NAME}_untrained\")\n",
    "\n",
    "#To load back the model:\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()\n",
    "\n",
    "retrieve_logits(model        = model            \\\n",
    "                , opt_df     = opt_df_train     \\\n",
    "                , dataloader = dataloader_train \\\n",
    "                , input_ids  = input_ids_train  \\\n",
    "                , sentences  = sentences_train  \\\n",
    "                , labels     = labels_train     \\\n",
    "                , model_name = MODEL_NAME\\\n",
    "                , batch_size = BATCH_SIZE\\\n",
    "                , opt_data_path=\".\"\\\n",
    "                , pre_training_name=PRE_TRAINING_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of model albert-base-v2: 0.6491\n",
      " Loss: 0.74\n",
      " Computation took: 0:06:54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Username</th>\n",
       "      <th>AverageAnnotation</th>\n",
       "      <th>Original ID</th>\n",
       "      <th>albert-base-v2logit0</th>\n",
       "      <th>albert-base-v2logit1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>@runge_kelly rest is good!! if you like tea an...</td>\n",
       "      <td>TheAnglophiler</td>\n",
       "      <td>1.25</td>\n",
       "      <td>220</td>\n",
       "      <td>-0.824011</td>\n",
       "      <td>1.248779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321</td>\n",
       "      <td>i want city to win. chelsea going up too far w...</td>\n",
       "      <td>Ajinkyaworld</td>\n",
       "      <td>1.50</td>\n",
       "      <td>321</td>\n",
       "      <td>-0.765283</td>\n",
       "      <td>1.093548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2127</td>\n",
       "      <td>you're annoying the piss out of me</td>\n",
       "      <td>TehhKota</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>2127</td>\n",
       "      <td>-0.453276</td>\n",
       "      <td>0.720489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5894</td>\n",
       "      <td>xxx . love neil</td>\n",
       "      <td>adorb_zayn</td>\n",
       "      <td>1.20</td>\n",
       "      <td>5894</td>\n",
       "      <td>-0.727588</td>\n",
       "      <td>1.054465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6844</td>\n",
       "      <td>and so begins the work to bring about #change ...</td>\n",
       "      <td>Brit_Mathews</td>\n",
       "      <td>1.50</td>\n",
       "      <td>6844</td>\n",
       "      <td>-0.576202</td>\n",
       "      <td>0.898891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>7370</td>\n",
       "      <td>already irritated and on top of that i have to...</td>\n",
       "      <td>victoria_alvaa</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>7370</td>\n",
       "      <td>-0.629735</td>\n",
       "      <td>0.847870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>1442</td>\n",
       "      <td>a girl with kaleidoscope eyessss. cellophane f...</td>\n",
       "      <td>caitlinnk_</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1442</td>\n",
       "      <td>-0.775267</td>\n",
       "      <td>1.259777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>2003</td>\n",
       "      <td>thanks @museumandrea !  and good luck @_laura_...</td>\n",
       "      <td>mambolica</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2003</td>\n",
       "      <td>-0.728567</td>\n",
       "      <td>1.023334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>1869</td>\n",
       "      <td>@jniall68 becose you are. i choose you to save...</td>\n",
       "      <td>PrincessXMalik</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1869</td>\n",
       "      <td>-0.635119</td>\n",
       "      <td>1.006413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>3072</td>\n",
       "      <td>.@verybritishdude not universally. but the con...</td>\n",
       "      <td>Effiedeans</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>3072</td>\n",
       "      <td>-0.756198</td>\n",
       "      <td>0.820253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3015 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              Tweet  \\\n",
       "0            220  @runge_kelly rest is good!! if you like tea an...   \n",
       "1            321  i want city to win. chelsea going up too far w...   \n",
       "2           2127                 you're annoying the piss out of me   \n",
       "3           5894                                    xxx . love neil   \n",
       "4           6844  and so begins the work to bring about #change ...   \n",
       "...          ...                                                ...   \n",
       "3010        7370  already irritated and on top of that i have to...   \n",
       "3011        1442  a girl with kaleidoscope eyessss. cellophane f...   \n",
       "3012        2003  thanks @museumandrea !  and good luck @_laura_...   \n",
       "3013        1869  @jniall68 becose you are. i choose you to save...   \n",
       "3014        3072  .@verybritishdude not universally. but the con...   \n",
       "\n",
       "            Username  AverageAnnotation  Original ID  albert-base-v2logit0  \\\n",
       "0     TheAnglophiler               1.25          220             -0.824011   \n",
       "1       Ajinkyaworld               1.50          321             -0.765283   \n",
       "2           TehhKota              -1.80         2127             -0.453276   \n",
       "3         adorb_zayn               1.20         5894             -0.727588   \n",
       "4       Brit_Mathews               1.50         6844             -0.576202   \n",
       "...              ...                ...          ...                   ...   \n",
       "3010  victoria_alvaa              -2.25         7370             -0.629735   \n",
       "3011      caitlinnk_               1.20         1442             -0.775267   \n",
       "3012       mambolica               1.50         2003             -0.728567   \n",
       "3013  PrincessXMalik               1.75         1869             -0.635119   \n",
       "3014      Effiedeans              -1.20         3072             -0.756198   \n",
       "\n",
       "      albert-base-v2logit1  \n",
       "0                 1.248779  \n",
       "1                 1.093548  \n",
       "2                 0.720489  \n",
       "3                 1.054465  \n",
       "4                 0.898891  \n",
       "...                    ...  \n",
       "3010              0.847870  \n",
       "3011              1.259777  \n",
       "3012              1.023334  \n",
       "3013              1.006413  \n",
       "3014              0.820253  \n",
       "\n",
       "[3015 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predicted logits by model on dataloader:\n",
    "def retrieve_logits(model, opt_df          \\\n",
    "                    , dataloader, input_ids\\\n",
    "                    , sentences, labels    \\\n",
    "                    , model_name, batch_size  \\\n",
    "                    , opt_data_path, pre_training_name=None):\n",
    "    '''\n",
    "        Return data_frame with additional 2 columns according to\n",
    "        the 2 logits predicted by the model for each entry.\n",
    "    '''\n",
    "        \n",
    "    #Criterion:\n",
    "    cse_loss = torch.nn.CrossEntropyLoss()   \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "    # Tracking variables \n",
    "    total_accuracy = 0\n",
    "    total_loss = 0\n",
    "    nb_steps = 0\n",
    "    assertion_tweets  = [None for i in labels]\n",
    "    predicted_logits0 = [None for i in labels]\n",
    "    predicted_logits1 = [None for i in labels]\n",
    "    \n",
    "    t0=time.time()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in dataloader:\n",
    "        b_input_ids  = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels     = batch[2].to(device)\n",
    "        with torch.no_grad():        \n",
    "            logits = model(b_input_ids, \n",
    "               token_type_ids=None, \n",
    "               attention_mask=b_input_mask)[0]\n",
    "            loss   = cse_loss(logits, b_labels)\n",
    "        # Accumulate the validation loss.\n",
    "        total_loss += loss.item()* (len(label_ids)/batch_size)\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "#         missed_indexes = np.where(label_ids != np.argmax(logits, axis=1).flatten())[0]\n",
    "#         for mi, missed_index in enumerate(missed_indexes):\n",
    "#         missed_indexes = np.where(label_ids != np.argmax(logits, axis=1).flatten())[0]\n",
    "#         for mi, missed_index in enumerate(missed_indexes):\n",
    "        for i, sample in enumerate(batch[0]):\n",
    "#             print(batch[0][i])\n",
    "            original_index = input_ids.tolist().index(batch[0][i].tolist())\n",
    "            \n",
    "            assert(sentences[original_index] ==  opt_df.iloc[original_index][\"Tweet\"])\n",
    "#             missed_val_tweets[\"Tweet\"].append(sentences[original_index])\n",
    "#             missed_val_tweets[\"Predicted Logits\"].append(logits[missed_index])\n",
    "#             predicted_logits.append((original_index\\\n",
    "#                                      , sentences[original_index]\\\n",
    "#                                      , logits[i]))\n",
    "#             predicted_logits0.append(logits[i][0])\n",
    "#             predicted_logits1.append(logits[i][1])\n",
    "#             assertion_tweets.append(sentences[original_index])\n",
    "            predicted_logits0[original_index] = logits[i][0]\n",
    "            predicted_logits1[original_index] = logits[i][1]\n",
    "            assertion_tweets[original_index]  = sentences[original_index]\n",
    "            \n",
    "        \n",
    "\n",
    "    #     break\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_accuracy += flat_accuracy(logits, label_ids) * (len(label_ids)/batch_size)\n",
    "\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_accuracy = total_accuracy / len(dataloader)\n",
    "    print(\"\\n Accuracy of model {0}: {1:.4f}\".format(model_name, avg_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    computation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\" Loss: {0:.2f}\".format(avg_loss))\n",
    "    print(\" Computation took: {:}\".format(computation_time))\n",
    "\n",
    "    \n",
    "    opt_df[model_name+\"logit0\"] = predicted_logits0\n",
    "    opt_df[model_name+\"logit1\"] = predicted_logits1\n",
    "#     assert(np.where(mock_opt_df[\"Tweet\"] == mock_opt_df[\"Model1_tweet\"])[0].shape[0] == mock_opt_df.shape[0])\n",
    "    assert(np.all(np.where(opt_df[\"Tweet\"] == assertion_tweets, True, False)))\n",
    "    \n",
    "    #Save new dataframe:\n",
    "    data_name = f\"OPT_{pre_training_name+'_' if pre_training_name else ''}\"\n",
    "    save_path = f\"{opt_data_path}/Logits_{data_name}{model_name}_Acc:{avg_accuracy}.csv\"\n",
    "    opt_df.to_csv(save_path)\n",
    "    \n",
    "    return opt_df\n",
    "\n",
    "retrieve_logits(model        = model            \\\n",
    "                , opt_df     = opt_df_train     \\\n",
    "                , dataloader = dataloader_train \\\n",
    "                , input_ids  = input_ids_train  \\\n",
    "                , sentences  = sentences_train  \\\n",
    "                , labels     = labels_train     \\\n",
    "                , model_name = MODEL_NAME\\\n",
    "                , batch_size = BATCH_SIZE\\\n",
    "                , opt_data_path=\".\"\\\n",
    "                , pre_training_name=PRE_TRAINING_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3015, 5), 754)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_df_train.shape, len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Username</th>\n",
       "      <th>AverageAnnotation</th>\n",
       "      <th>Original ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>@runge_kelly rest is good!! if you like tea an...</td>\n",
       "      <td>TheAnglophiler</td>\n",
       "      <td>1.25</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>916</td>\n",
       "      <td>dr. budiani-saberi is a medical anthropologist...</td>\n",
       "      <td>JessiKersi</td>\n",
       "      <td>0.00</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321</td>\n",
       "      <td>i want city to win. chelsea going up too far w...</td>\n",
       "      <td>Ajinkyaworld</td>\n",
       "      <td>1.50</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2127</td>\n",
       "      <td>you're annoying the piss out of me</td>\n",
       "      <td>TehhKota</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5643</td>\n",
       "      <td>@arapahoe_basin looking good for tomorrow's sk...</td>\n",
       "      <td>tomfricke</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>3531</td>\n",
       "      <td>@tgirlinterruptd @serynada person appreciates ...</td>\n",
       "      <td>WillJaxx</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>5884</td>\n",
       "      <td>@coryrocker are you excited though?</td>\n",
       "      <td>rdelvillano</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>1045</td>\n",
       "      <td>@urfavelatina is responsible for @lorealparisu...</td>\n",
       "      <td>JAsports70</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>4333</td>\n",
       "      <td>man.. we were the best.</td>\n",
       "      <td>x_VintageBesos</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>2234</td>\n",
       "      <td>@playboyespinosa im just kidding</td>\n",
       "      <td>playboyespinosa</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5939 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              Tweet  \\\n",
       "0            220  @runge_kelly rest is good!! if you like tea an...   \n",
       "1            916  dr. budiani-saberi is a medical anthropologist...   \n",
       "2            321  i want city to win. chelsea going up too far w...   \n",
       "3           2127                 you're annoying the piss out of me   \n",
       "4           5643  @arapahoe_basin looking good for tomorrow's sk...   \n",
       "...          ...                                                ...   \n",
       "5934        3531  @tgirlinterruptd @serynada person appreciates ...   \n",
       "5935        5884                @coryrocker are you excited though?   \n",
       "5936        1045  @urfavelatina is responsible for @lorealparisu...   \n",
       "5937        4333                            man.. we were the best.   \n",
       "5938        2234                   @playboyespinosa im just kidding   \n",
       "\n",
       "             Username  AverageAnnotation  Original ID  \n",
       "0      TheAnglophiler               1.25          220  \n",
       "1          JessiKersi               0.00          916  \n",
       "2        Ajinkyaworld               1.50          321  \n",
       "3            TehhKota              -1.80         2127  \n",
       "4           tomfricke               0.60         5643  \n",
       "...               ...                ...          ...  \n",
       "5934         WillJaxx               1.00         3531  \n",
       "5935      rdelvillano               0.60         5884  \n",
       "5936       JAsports70              -0.80         1045  \n",
       "5937   x_VintageBesos               1.00         4333  \n",
       "5938  playboyespinosa               0.60         2234  \n",
       "\n",
       "[5939 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Something_'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Something_{'' if PRE_TRAINING else ''}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([416, 64]), torch.Size([416, 64]), torch.Size([308]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_train.shape, attention_masks_train.shape, labels_train.shape\n",
    "\n",
    "input_ids_pre_train.shape, attention_masks_pre_train.shape, labels_pre_train.shape\n",
    "input_ids_pre_test.shape, attention_masks_pre_test.shape, labels_pre_test.shape\n",
    "input_ids_pre_val.shape, attention_masks_pre_val.shape, labels_pre_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7fdcc75ff4a8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorDataset(input_ids_train, attention_masks_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_pickle(attention_masks_pre_val  , f\"{PRE_TRAINING_NAME}_attention_masks_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tokenizer, data_store + f\"{PRE_TRAINING_NAME}_tokenizer.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.tokenization_albert.AlbertTokenizer at 0x7fdcc76d95c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(data_store + f\"{PRE_TRAINING_NAME}_tokenizer.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.tokenization_albert.AlbertTokenizer at 0x7fdcc9694b38>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "# from data_preparation import *\n",
    "\n",
    "# opt_data_path = \"../../data/optimism-twitter-data/tweets_annotation.csv\"\n",
    "opt_data_path = \"../../data/optimism-twitter-data/processed/\"\n",
    "\n",
    "SETTING_1M1 = True\n",
    "# SETTING_1M1 = False\n",
    "setting_name = \"set1M1\" if SETTING_1M1 else \"set0\"\n",
    "\n",
    "\n",
    "# def retrieve_logits(\n",
    "opt_df_train = pd.read_csv(opt_data_path + f\"optimism_{setting_name}_train.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "opt_df_test  = pd.read_csv(opt_data_path + f\"optimism_{setting_name}_test.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "opt_df_dev   = pd.read_csv(opt_data_path + f\"optimism_{setting_name}_validation.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "opt_train_tweets      = np.array(opt_df_train[\"Tweet\"])\n",
    "opt_train_gold_labels = np.array(opt_df_train[\"AverageAnnotation\"])\n",
    "opt_test_tweets       = np.array(opt_df_test[\"Tweet\"])\n",
    "opt_test_gold_labels  = np.array(opt_df_test[\"AverageAnnotation\"])\n",
    "opt_dev_tweets        = np.array(opt_df_dev[\"Tweet\"])\n",
    "opt_dev_gold_labels   = np.array(opt_df_dev[\"AverageAnnotation\"])\n",
    "\n",
    "\n",
    "# opt_tweets, opt_gold_labels = read_OPT_data(data_path=opt_data_path)\n",
    "# opt_gold_labels             = np.array(opt_gold_labels)\n",
    "# opt_tweets                  = np.array(opt_tweets)\n",
    "\n",
    "\n",
    "\n",
    "# SETTING_1M1 = True\n",
    "# SETTING_1M1 = False\n",
    "\n",
    "# if SETTING_1M1:\n",
    "#     opt_tweets, opt_gold_labels = remove_vague_tweets(\\\n",
    "#                                                 opt_tweets\\\n",
    "#                                               , opt_gold_labels)\n",
    "\n",
    "# bin_opt_gold_labels = binarize_labels(gold_labels=(opt_gold_labels)\\\n",
    "#                                       , max_negative_value=0)\n",
    "\n",
    "# x_train, y_train, x_dev, y_dev, x_test, y_test = \\\n",
    "#     train_dev_test_split(opt_vectorized_tweets\\\n",
    "#                          , bin_opt_gold_labels, R_SEED=16)\n",
    "\n",
    "# opt_tweets[-1], opt_gold_labels[-1], bin_opt_gold_labels[-1]\n",
    "\n",
    "# Get the lists of sentences and their labels.\n",
    "# sentences = df.sentence.values\n",
    "# labels    = df.label.values\n",
    "sentences_train = opt_train_tweets\n",
    "labels_train    = np.where(opt_train_gold_labels<=0, 0, 1)\n",
    "\n",
    "sentences_test = opt_test_tweets\n",
    "labels_test    = np.where(opt_test_gold_labels<=0, 0, 1)\n",
    "\n",
    "sentences_dev  = opt_dev_tweets\n",
    "labels_dev     = np.where(opt_dev_gold_labels<=0, 0, 1)\n",
    "\n",
    "print(f\"{labels_train.shape[0]} train samples;\")\n",
    "print(f\"{labels_test.shape[0]} test samples;\")\n",
    "print(f\"{labels_dev.shape[0]} validation samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SENTIMENT_PATH = \"../../data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\"\n",
    "HATE_PATH      = \"../../data/Hate/hatespeech-twitter.csv\"\n",
    "EMO_PATH       = \"../../data/EmoNet/Emonet.tsv\"\n",
    "# PRE_TRAINING_ON_TSA = True\n",
    "PRE_TRAINING_ON_TSA = False\n",
    "SENTIMENT_TEXT      = \"SentimentText\"\n",
    "SENTIMENT_LABEL     = \"Sentiment\"\n",
    "# PRE_TRAINING_ON_HATE = True\n",
    "PRE_TRAINING_ON_HATE = False\n",
    "# PRE_TRAINING_ON_EMO  = True\n",
    "PRE_TRAINING_ON_EMO  = False\n",
    "\n",
    "if PRE_TRAINING_ON_HATE:\n",
    "    hate_df     = pd.read_csv(HATE_PATH\\\n",
    "                              , names=[\"ID\", \"Tweet\", \"Label\"])\n",
    "    hate_df[\"HLabel\"] = hate_df.Label.astype('category').cat.codes\n",
    "\n",
    "    # Get the lists of sentences and their labels.\n",
    "    # sentences = df.sentence.values\n",
    "    # labels    = df.label.values\n",
    "    sentences = hate_df.Tweet.values\n",
    "    labels    = hate_df.HLabel.values.astype(int)\n",
    "#     np.unique(labels).shape[0]\n",
    "#     hate_df.groupby(\"Label\").count()[[\"Tweet\"]]\n",
    "#     hate_df.head()\n",
    "    \n",
    "if PRE_TRAINING_ON_TSA:\n",
    "    sent_tweets, sent_gold_labels = read_OPT_data(data_path=SENTIMENT_PATH\\\n",
    "                                       , text_column=SENTIMENT_TEXT\\\n",
    "                                       , label_column=SENTIMENT_LABEL)\n",
    "    \n",
    "    sentences = np.array(sent_tweets)\n",
    "    labels    = np.array(sent_gold_labels)\n",
    "    \n",
    "if PRE_TRAINING_ON_EMO:\n",
    "    emonet_df = pd.read_table(\"../../data/EmoNet/Emonet.tsv\"\\\n",
    "                              , names=[\"Tweet\", \"Emotion\"])\n",
    "\n",
    "#     emonet_df.shape\n",
    "\n",
    "#     emonet_df.head()\n",
    "\n",
    "    emonet_df[\"ELabel\"] = emonet_df.Emotion.astype('category').cat.codes\n",
    "\n",
    "    # Get the lists of sentences and their labels.\n",
    "    # sentences = df.sentence.values\n",
    "    # labels    = df.label.values\n",
    "    sentences = emonet_df.Tweet.values\n",
    "    labels    = emonet_df.ELabel.values.astype(int)\n",
    "\n",
    "    np.unique(labels).shape[0]\n",
    "    emonet_df.groupby(\"Emotion\").count()[[\"Tweet\"]]#Plutchik-2 Emotions\n",
    "    emonet_df.head()\n",
    "    # emonet_df../\n",
    "    # emonet_df.cc.\n",
    "    \n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzed missed tweets:\n",
    "\n",
    "1. Save `.csv` with missed tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find missed tweets and store into pandas Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2bd16d076d97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mmissed_val_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Original ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mmissed_val_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moriginal_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mmissed_val_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Annotation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_gold_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moriginal_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mmissed_val_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moriginal_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "# Tracking variables \n",
    "total_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "missed_val_tweets = {\\\n",
    "                     \"Original ID\" : []\\\n",
    "                     , \"Tweet\":[]\\\n",
    "                     , \"Annotation\": []\\\n",
    "                     , \"Label\": []\\\n",
    "                     , \"Predicted Logits\": []\\\n",
    "                    }\n",
    "\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in dataloader_validation:\n",
    "    \n",
    "    #How to find the position of a list in a list of lists:\n",
    "    #input_ids[input_ids.tolist().index(batch[0][0].tolist())]\n",
    "#     break\n",
    "    \n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids  = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels     = batch[2].to(device)\n",
    "\n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        (loss, logits) = model(b_input_ids, \n",
    "                               token_type_ids=None, \n",
    "                               attention_mask=b_input_mask,\n",
    "                               labels=b_labels)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Accumulate the validation loss.\n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    \n",
    "#     print(logits)\n",
    "#     print(np.argmax(logits, axis=1).flatten())\n",
    "#     print(label_ids)\n",
    "#     print(label_ids != np.argmax(logits, axis=1).flatten())\n",
    "    \n",
    "#     print(np.where(label_ids != np.argmax(logits, axis=1).flatten()))\n",
    "    missed_indexes = np.where(label_ids != np.argmax(logits, axis=1).flatten())[0]\n",
    "    \n",
    "#     missed_index = 6\n",
    "    for mi, missed_index in enumerate(missed_indexes):\n",
    "#         print(missed_index)\n",
    "#         print(\"##################Missed tweet %d:\" %missed_index)\n",
    "# #         print()\n",
    "#         print((input_ids[input_ids.tolist().index(batch[0][missed_index].tolist())] == batch[0][missed_index]).all())\n",
    "#         print((sentences[input_ids.tolist().index(batch[0][missed_index].tolist())]))\n",
    "        \n",
    "#         print(tokenizer.encode_plus(\n",
    "#                         sentences[input_ids.tolist().index(batch[0][missed_index].tolist())],                      # Sentence to encode.\n",
    "#                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "#                         max_length = 64,           # Pad & truncate all sentences.\n",
    "#                         pad_to_max_length = True,\n",
    "#                         return_attention_mask = True,   # Construct attn. masks.\n",
    "#                         return_tensors = 'pt',     # Return pytorch tensors.\n",
    "#                    )[\"input_ids\"] == batch[0][missed_index])\n",
    "#         print(\"True label:\", (labels[input_ids.tolist().index(batch[0][missed_index].tolist())]))\n",
    "#         print(\"True annotation:\", opt_gold_labels[input_ids.tolist().index(batch[0][missed_index].tolist())])\n",
    "#         print(\"Predicted logits:\", logits[missed_index])\n",
    "        \n",
    "        original_index = input_ids_val.tolist().index(batch[0][missed_index].tolist())\n",
    "        \n",
    "        \n",
    "        missed_val_tweets[\"Original ID\"].append(original_index)\n",
    "        missed_val_tweets[\"Tweet\"].append(sentences_val[original_index])\n",
    "        missed_val_tweets[\"Annotation\"].append(opt_gold_labels[original_index])\n",
    "        missed_val_tweets[\"Label\"].append(labels[original_index])\n",
    "        missed_val_tweets[\"Predicted Logits\"].append(logits[missed_index])\n",
    "        \n",
    "#     break\n",
    "    \n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "print(\"  Validation Accuracy: {0:.4f}\".format(avg_val_accuracy))\n",
    "\n",
    "# Calculate the average loss over all of the batches.\n",
    "avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "# Measure how long the validation run took.\n",
    "validation_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "\n",
    "print(\"The number of missed tweets is: %d out of %d.\" %(len(missed_val_tweets[\"Tweet\"]), len(val_dataset)))\n",
    "\n",
    "validation_acc =  100 * (1-len(missed_val_tweets[\"Tweet\"]) / len(val_dataset))\n",
    "print(\"Thus, the validation accuracy score is %.3f%%.\" %(validation_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_val, sentences_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save missed tweets to `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = f\"OPT_{pre_training_name+'_' if pre_training_name else ''}\"\n",
    "save_path = f\"{opt_data_path}/Logits_{data_name}{model_name}_Acc:{avg_accuracy}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_val_tweets_df = pd.DataFrame(missed_val_tweets)\n",
    "\n",
    "\n",
    "missed_val_tweets_df.head()\n",
    "\n",
    "# missed_val_tweets_df.to_csv(f\"./missed_{model._get_name()}Base_validation_tweets_epchs:{epochs}_acc:{validation_acc}.csv\")\n",
    "\n",
    "setting       = \"set1M1\" if SETTING_1M1 else \"set0\"\n",
    "missed_val_tweets_df.to_csv(f\"./missed_{model._get_name()}Base_validation_tweets_epchs:{epochs}_acc:{validation_acc}_{setting}.csv\")\n",
    "\n",
    "# missed_val_tweets_df.to_csv(f\"./missed_{model._get_name()}Large_validation_tweets_epchs:{epochs}_acc:{validation_acc}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missed  tweets analysis\n",
    "\n",
    "2. Load the missed tweets from `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 6), (39, 6))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "xlnet_missed_df = pd.read_csv(\"missed_XLNetForSequenceClassificationBase_validation_tweets_epchs:15_acc:95.58441558441558.csv\")\n",
    "bert_missed_df  = pd.read_csv(\"missed_BertForSequenceClassificationLarge_validation_tweets_epchs:15_acc:94.93506493506494.csv\")\n",
    "\n",
    "xlnet_missed_df.shape, bert_missed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Original ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Label</th>\n",
       "      <th>Predicted Logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>46</td>\n",
       "      <td>@ksiolajidebt is this seriously legit?</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-3.8370638  4.566077 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>your new possibilities won't have a chance to ...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 2.2584069 -2.9003844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>158</td>\n",
       "      <td>i actually can't remember what its like being ...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 3.52532  -4.371325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>481</td>\n",
       "      <td>a dope chick. something like a deep verse and ...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-4.5771003  5.4640937]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "      <td>.@shaunacdaly if it was advised as public even...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[0.11120434 0.06521408]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>763</td>\n",
       "      <td>@drea__xoxo you ride with opps. sorry not sorry</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-2.3617704  2.4823644]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>948</td>\n",
       "      <td>#votetrismtv she's lost everything but she kee...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 2.8543465 -3.5634801]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>956</td>\n",
       "      <td>whatever keeps on troubling you.bothering you ...</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 3.267196  -4.0553365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>987</td>\n",
       "      <td>@atsipras and the fin. min.'s protesting clean...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 3.0608761 -3.9085941]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1064</td>\n",
       "      <td>unintentional girls' night. all my guy friends...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 1.9037702 -2.5630794]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Original ID  \\\n",
       "20          20           46   \n",
       "5            5          116   \n",
       "27          27          158   \n",
       "26          26          481   \n",
       "3            3          700   \n",
       "22          22          763   \n",
       "25          25          948   \n",
       "30          30          956   \n",
       "15          15          987   \n",
       "13          13         1064   \n",
       "\n",
       "                                                Tweet  Annotation      Label  \\\n",
       "20             @ksiolajidebt is this seriously legit?   -1.000000  tensor(0)   \n",
       "5   your new possibilities won't have a chance to ...    2.333333  tensor(1)   \n",
       "27  i actually can't remember what its like being ...    1.500000  tensor(1)   \n",
       "26  a dope chick. something like a deep verse and ...   -1.000000  tensor(0)   \n",
       "3   .@shaunacdaly if it was advised as public even...    1.000000  tensor(1)   \n",
       "22    @drea__xoxo you ride with opps. sorry not sorry   -1.000000  tensor(0)   \n",
       "25  #votetrismtv she's lost everything but she kee...    1.250000  tensor(1)   \n",
       "30  whatever keeps on troubling you.bothering you ...    1.600000  tensor(1)   \n",
       "15  @atsipras and the fin. min.'s protesting clean...    1.000000  tensor(1)   \n",
       "13  unintentional girls' night. all my guy friends...    1.200000  tensor(1)   \n",
       "\n",
       "           Predicted Logits  \n",
       "20  [-3.8370638  4.566077 ]  \n",
       "5   [ 2.2584069 -2.9003844]  \n",
       "27    [ 3.52532  -4.371325]  \n",
       "26  [-4.5771003  5.4640937]  \n",
       "3   [0.11120434 0.06521408]  \n",
       "22  [-2.3617704  2.4823644]  \n",
       "25  [ 2.8543465 -3.5634801]  \n",
       "30  [ 3.267196  -4.0553365]  \n",
       "15  [ 3.0608761 -3.9085941]  \n",
       "13  [ 1.9037702 -2.5630794]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlnet_missed_df.sort_values(by=\"Original ID\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Original ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Label</th>\n",
       "      <th>Predicted Logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>@ksiolajidebt is this seriously legit?</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-6.11965   6.755434]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>158</td>\n",
       "      <td>i actually can't remember what its like being ...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 5.689795 -6.449445]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>i need to start saving money for spring semest...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 3.719918  -4.4732776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>199</td>\n",
       "      <td>i'm an asshole but you really are a terrible p...</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-1.8303442  1.5245974]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>286</td>\n",
       "      <td>@666satanluvr666 then you could threaten to ki...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-5.3200483  6.10768  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>438</td>\n",
       "      <td>@norway_updates @zaynmalik my point wasn't abo...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-1.0477318  0.8311569]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>481</td>\n",
       "      <td>a dope chick. something like a deep verse and ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-6.030591  6.738043]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>710</td>\n",
       "      <td>@makebritnasty wow. that's some fuckery.</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-3.9052863  4.555543 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>733</td>\n",
       "      <td>@pockysquirrel @tsb_says yeah. that's what mak...</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-5.9369564  6.5940228]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>763</td>\n",
       "      <td>@drea__xoxo you ride with opps. sorry not sorry</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-5.695918   6.6404157]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Original ID  \\\n",
       "10          10           46   \n",
       "31          31          158   \n",
       "27          27          176   \n",
       "5            5          199   \n",
       "26          26          286   \n",
       "29          29          438   \n",
       "30          30          481   \n",
       "8            8          710   \n",
       "12          12          733   \n",
       "16          16          763   \n",
       "\n",
       "                                                Tweet  Annotation      Label  \\\n",
       "10             @ksiolajidebt is this seriously legit?        -1.0  tensor(0)   \n",
       "31  i actually can't remember what its like being ...         1.5  tensor(1)   \n",
       "27  i need to start saving money for spring semest...         1.0  tensor(1)   \n",
       "5   i'm an asshole but you really are a terrible p...        -2.2  tensor(0)   \n",
       "26  @666satanluvr666 then you could threaten to ki...        -1.0  tensor(0)   \n",
       "29  @norway_updates @zaynmalik my point wasn't abo...        -1.0  tensor(0)   \n",
       "30  a dope chick. something like a deep verse and ...        -1.0  tensor(0)   \n",
       "8            @makebritnasty wow. that's some fuckery.        -2.0  tensor(0)   \n",
       "12  @pockysquirrel @tsb_says yeah. that's what mak...        -1.2  tensor(0)   \n",
       "16    @drea__xoxo you ride with opps. sorry not sorry        -1.0  tensor(0)   \n",
       "\n",
       "           Predicted Logits  \n",
       "10    [-6.11965   6.755434]  \n",
       "31    [ 5.689795 -6.449445]  \n",
       "27  [ 3.719918  -4.4732776]  \n",
       "5   [-1.8303442  1.5245974]  \n",
       "26  [-5.3200483  6.10768  ]  \n",
       "29  [-1.0477318  0.8311569]  \n",
       "30    [-6.030591  6.738043]  \n",
       "8   [-3.9052863  4.555543 ]  \n",
       "12  [-5.9369564  6.5940228]  \n",
       "16  [-5.695918   6.6404157]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_missed_df.sort_values(by=\"Original ID\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Label</th>\n",
       "      <th>Predicted Logits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Original ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>0</td>\n",
       "      <td>man i feel good that movie was shit and i tota...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-5.3121347  5.8559017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>1</td>\n",
       "      <td>@charlamore is okay bon. she will get the help...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-5.51584   6.010965]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>2</td>\n",
       "      <td>@ghostswami looks like it.. going to be tough ...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>[-6.1653237  6.6193023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>3</td>\n",
       "      <td>unintentional girls' night. all my guy friends...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 4.4649787 -5.1849155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>4</td>\n",
       "      <td>sign petition: #ukip  to apologise for stirrin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>[ 3.9684134 -4.7878494]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Unnamed: 0                                              Tweet  \\\n",
       "Original ID                                                                  \n",
       "2597                  0  man i feel good that movie was shit and i tota...   \n",
       "3464                  1  @charlamore is okay bon. she will get the help...   \n",
       "1551                  2  @ghostswami looks like it.. going to be tough ...   \n",
       "1064                  3  unintentional girls' night. all my guy friends...   \n",
       "1703                  4  sign petition: #ukip  to apologise for stirrin...   \n",
       "\n",
       "             Annotation      Label         Predicted Logits  \n",
       "Original ID                                                  \n",
       "2597               -1.0  tensor(0)  [-5.3121347  5.8559017]  \n",
       "3464               -1.0  tensor(0)    [-5.51584   6.010965]  \n",
       "1551               -1.5  tensor(0)  [-6.1653237  6.6193023]  \n",
       "1064                1.2  tensor(1)  [ 4.4649787 -5.1849155]  \n",
       "1703                1.0  tensor(1)  [ 3.9684134 -4.7878494]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bert_missed_df  = bert_missed_df.set_index(\"Original ID\")\n",
    "xlnet_missed_df = xlnet_missed_df.set_index(\"Original ID\")\n",
    "bert_missed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 10)\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([xlnet_missed_df, bert_missed_df], axis=1, join=\"inner\").shape)#,\\\n",
    "both_missed = pd.concat([xlnet_missed_df, bert_missed_df], axis=1, join=\"inner\")#.head()\n",
    "_, i = np.unique(both_missed.columns, return_index=True)\n",
    "both_missed.head()\n",
    "\n",
    "both_missed = both_missed.iloc[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Predicted Logits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Original ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>man i feel good that movie was shit and i tota...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>[-3.7911136  4.6593223]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>@charlamore is okay bon. she will get the help...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>[-4.729202  5.451662]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>@ghostswami looks like it.. going to be tough ...</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>[-4.7197533  5.799981 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>unintentional girls' night. all my guy friends...</td>\n",
       "      <td>1.20</td>\n",
       "      <td>[ 1.9037702 -2.5630794]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>sign petition: #ukip  to apologise for stirrin...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[ 2.6813018 -3.5829132]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>life is a series of ups and downs. like a roll...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[ 2.7248855 -3.6173534]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>@ksiolajidebt is this seriously legit?</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>[-3.8370638  4.566077 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>omg my grandmom is crazy</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>[-4.565708  5.410697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>@drea__xoxo you ride with opps. sorry not sorry</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>[-2.3617704  2.4823644]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>instead of saying god. i have a big problem. s...</td>\n",
       "      <td>1.80</td>\n",
       "      <td>[ 2.982567  -3.8782692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>everyone here has iphones  and im just like......</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>[-3.895168   4.5623455]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>a dope chick. something like a deep verse and ...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>[-4.5771003  5.4640937]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>i actually can't remember what its like being ...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>[ 3.52532  -4.371325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>jlo better come out half dressed by ten or i'm...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>[-0.5243792   0.82327247]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>i miss you.</td>\n",
       "      <td>1.25</td>\n",
       "      <td>[ 3.1924791 -3.9952202]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Tweet  Annotation  \\\n",
       "Original ID                                                                  \n",
       "2597         man i feel good that movie was shit and i tota...       -1.00   \n",
       "3464         @charlamore is okay bon. she will get the help...       -1.00   \n",
       "1551         @ghostswami looks like it.. going to be tough ...       -1.50   \n",
       "1064         unintentional girls' night. all my guy friends...        1.20   \n",
       "1703         sign petition: #ukip  to apologise for stirrin...        1.00   \n",
       "2474         life is a series of ups and downs. like a roll...        1.00   \n",
       "46                      @ksiolajidebt is this seriously legit?       -1.00   \n",
       "2045                                  omg my grandmom is crazy       -1.00   \n",
       "763            @drea__xoxo you ride with opps. sorry not sorry       -1.00   \n",
       "2066         instead of saying god. i have a big problem. s...        1.80   \n",
       "2382         everyone here has iphones  and im just like......       -1.00   \n",
       "481          a dope chick. something like a deep verse and ...       -1.00   \n",
       "158          i actually can't remember what its like being ...        1.50   \n",
       "3153         jlo better come out half dressed by ten or i'm...       -1.00   \n",
       "2866                                               i miss you.        1.25   \n",
       "\n",
       "                      Predicted Logits  \n",
       "Original ID                             \n",
       "2597           [-3.7911136  4.6593223]  \n",
       "3464             [-4.729202  5.451662]  \n",
       "1551           [-4.7197533  5.799981 ]  \n",
       "1064           [ 1.9037702 -2.5630794]  \n",
       "1703           [ 2.6813018 -3.5829132]  \n",
       "2474           [ 2.7248855 -3.6173534]  \n",
       "46             [-3.8370638  4.566077 ]  \n",
       "2045             [-4.565708  5.410697]  \n",
       "763            [-2.3617704  2.4823644]  \n",
       "2066           [ 2.982567  -3.8782692]  \n",
       "2382           [-3.895168   4.5623455]  \n",
       "481            [-4.5771003  5.4640937]  \n",
       "158              [ 3.52532  -4.371325]  \n",
       "3153         [-0.5243792   0.82327247]  \n",
       "2866           [ 3.1924791 -3.9952202]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_missed[[\"Tweet\", \"Annotation\", \"Predicted Logits\"]]#.drop(\"Tweet\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Missed tweet 1:##########\n",
      "man i feel good that movie was shit and i totally lost interest by the end but the end credit song was good and so i dont even care\n",
      "Annotation: -1.0;\n",
      "Logits: [-3.7911136  4.6593223].\n",
      "##########Missed tweet 2:##########\n",
      "@charlamore is okay bon. she will get the help she needs. also. i won't stand on random biscuits she leaves dotted around. hurting my feets.\n",
      "Annotation: -1.0;\n",
      "Logits: [-4.729202  5.451662].\n",
      "##########Missed tweet 3:##########\n",
      "@ghostswami looks like it.. going to be tough n dirty truth be told..  @rpg_89 @upamanyu70 @india_policy\n",
      "Annotation: -1.5;\n",
      "Logits: [-4.7197533  5.799981 ].\n",
      "##########Missed tweet 4:##########\n",
      "unintentional girls' night. all my guy friends bailed...oh well. more food for us!\n",
      "Annotation: 1.2;\n",
      "Logits: [ 1.9037702 -2.5630794].\n",
      "##########Missed tweet 5:##########\n",
      "sign petition: #ukip  to apologise for stirring up fear:\n",
      "Annotation: 1.0;\n",
      "Logits: [ 2.6813018 -3.5829132].\n",
      "##########Missed tweet 6:##########\n",
      "life is a series of ups and downs. like a roller coaster ride that you were forced to get on by your douchebag friends.\n",
      "Annotation: 1.0;\n",
      "Logits: [ 2.7248855 -3.6173534].\n",
      "##########Missed tweet 7:##########\n",
      "@ksiolajidebt is this seriously legit?\n",
      "Annotation: -1.0;\n",
      "Logits: [-3.8370638  4.566077 ].\n",
      "##########Missed tweet 8:##########\n",
      "omg my grandmom is crazy\n",
      "Annotation: -1.0;\n",
      "Logits: [-4.565708  5.410697].\n",
      "##########Missed tweet 9:##########\n",
      "@drea__xoxo you ride with opps. sorry not sorry\n",
      "Annotation: -1.0;\n",
      "Logits: [-2.3617704  2.4823644].\n",
      "##########Missed tweet 10:##########\n",
      "instead of saying god. i have a big problem. say problem i have a big god.\n",
      "Annotation: 1.8;\n",
      "Logits: [ 2.982567  -3.8782692].\n",
      "##########Missed tweet 11:##########\n",
      "everyone here has iphones  and im just like.........penny phone.\n",
      "Annotation: -1.0;\n",
      "Logits: [-3.895168   4.5623455].\n",
      "##########Missed tweet 12:##########\n",
      "a dope chick. something like a deep verse and i'm hooked\n",
      "Annotation: -1.0;\n",
      "Logits: [-4.5771003  5.4640937].\n",
      "##########Missed tweet 13:##########\n",
      "i actually can't remember what its like being scared of approaching a girl.. got rid of my gwababa waaay long ago!\n",
      "Annotation: 1.5;\n",
      "Logits: [ 3.52532  -4.371325].\n",
      "##########Missed tweet 14:##########\n",
      "jlo better come out half dressed by ten or i'm shutting off the #grammyawards and putting on #bettercallsaul #amc\n",
      "Annotation: -1.0;\n",
      "Logits: [-0.5243792   0.82327247].\n",
      "##########Missed tweet 15:##########\n",
      "i miss you.\n",
      "Annotation: 1.25;\n",
      "Logits: [ 3.1924791 -3.9952202].\n"
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(both_missed[[\"Tweet\", \"Annotation\", \"Predicted Logits\"]].values):\n",
    "    print(f\"##########Missed tweet {i+1}:##########\")\n",
    "    print(e[0])\n",
    "    print(f\"Annotation: {e[1]};\")\n",
    "    print(f\"Logits: {e[2]}.\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularized code workflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import project structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../set_project_seed.py:33: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "from shutil           import copyfile\n",
    "sys.path.insert(0, '../')\n",
    "# sys.path.insert(0, '../config/')\n",
    "\n",
    "from CustomTokenizer  import *\n",
    "from data_preparation import *\n",
    "from Embedder         import *\n",
    "from models           import *\n",
    "from training         import *\n",
    "from set_project_seed import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE      = 4096\n",
    "# DATA_PATH       = \"../../data/optimism-twitter-data/tweets_annotation.csv\"\n",
    "# EMBEDDINGS_PATH = '../../embeddings/glove.twitter.27B/glove.twitter.27B.25d.txt' \n",
    "# # EMBEDDINGS_PATH = '../../embeddings/glove.840B.300d/glove.840B.300d.txt' \n",
    "# # EMBEDDINGS_PATH = '../../embeddings/crawl-300d-2M-subword/crawl-300d-2M-subword.vec' \n",
    "# LOGGING_PATH    = ''\n",
    "# # LOGGING_PATH    ='./code/logging/first_log'\n",
    "# # MODEL_NAME          = \"BiLSTM_model\"\n",
    "# MODEL_NAME          = \"CNN_model\"\n",
    "# #MODEL_NAME          = \"GRUstack_model\"\n",
    "# MODELS_PATH     = \"../models/\"\n",
    "# NUM_EPOCHS      = 20\n",
    "# #Consider only Tweets with reviews not in (-1, 1):\n",
    "# # SETTING_1M1     = True\n",
    "# SETTING_1M1     = False\n",
    "# HISTORY_PATH    = '../histories/'\n",
    "\n",
    "# # PRE_TRAINING_ON_TSA = False\n",
    "# PRE_TRAINING_ON_TSA = True\n",
    "# SENTIMENT_PATH      = \"../../data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\"\n",
    "# SENTIMENT_LABEL     = \"Sentiment\"\n",
    "# SENTIMENT_TEXT      = \"SentimentText\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Misc]\r\n",
      "RANDOM_SEED         = 7\r\n",
      "\r\n",
      "[Paths]\r\n",
      "DATA_PATH           = ../data/optimism-twitter-data/tweets_annotation.csv\r\n",
      "EMBEDDINGS_PATH     = ../embeddings/glove.840B.300d/glove.840B.300d.txt\r\n",
      "#EMBEDDINGS_PATH     = ../embeddings/crawl-300d-2M-subword/crawl-300d-2M-subword.vec\r\n",
      "HISTORY_PATH        = ./histories/largeRAM/\r\n",
      "LOGGING_PATH        =\r\n",
      "#LOGGING_PATH        = ./logging/first_log\r\n",
      "MODELS_PATH         = ./models/largeRAM/\r\n",
      "SENTIMENT_PATH      = ../data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\r\n",
      "\r\n",
      "[Training]\r\n",
      "BATCH_SIZE          = 4096\r\n",
      "MODEL_NAME          = BiLSTM_model\r\n",
      "NUM_EPOCHS          = 10\r\n",
      "SETTING_1M1         = False\r\n",
      "\r\n",
      "[Sentiment]\r\n",
      "PRE_TRAINING_ON_TSA = True\r\n",
      "SENTIMENT_LABEL     = Sentiment\r\n",
      "SENTIMENT_TEXT      = SentimentText\r\n",
      "TRIM                = True\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../config/largeRAM/lRAM_TSA_0_BiLSTM\n",
    "# !cat ../histories/largeRAM/config_lRAM_TSA_0_CNN_valAcc0.706_133149_20200320 #GloVe\n",
    "\n",
    "# !cat ../histories/largeRAM/config_lRAM_TSA_0_GRUStack_valAcc0.716_130346_20200320 #FastText\n",
    "# !cat ../histories/largeRAM/config_lRAM_TSA_0_GRUStack_valAcc0.706_132245_20200320 #GloVe\n",
    "\n",
    "# !cat ../histories/largeRAM/config_lRAM_TSA_0_BiLSTM_valAcc0.714_134843_20200320 #GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "\n",
    "config_path = \"../config/smallRAM/sRAM_OPT_1M1_CNN\"\n",
    "# config_path = \"./config/smallRAM/sRAM_OPT_1M1_GRUStack\"\n",
    "\n",
    "config_path = \"../config/smallRAM/sRAM_OPT_0_CNN\"\n",
    "config_path = \"../config/smallRAM/sRAM_OPT_0_Transformer\"\n",
    "\n",
    "# config_path = \"../config/largeRAM/lRAM_TSA_0_BiLSTM\"\n",
    "# config_path = \"../config/largeRAM/lRAM_TSA_0_CNN\"\n",
    "# config_path = \"../config/largeRAM/lRAM_TSA_0_GRUStack\"\n",
    "# config_path = \"../config/largeRAM/lRAM_OPT_0_BiLSTM\"\n",
    "# config_path = \"../config/largeRAM/lRAM_OPT_0_CNN\"\n",
    "# config_path = \"../config/largeRAM/lRAM_OPT_0_GRUStack\"\n",
    "# config_path = \"../config/largeRAM/lRAM_OPT_1M1_BiLSTM\"\n",
    "# config_path = \"../config/largeRAM/lRAM_OPT_1M1_CNN\"\n",
    "# config_path = \"../config/largeRAM/lRAM_OPT_1M1_GRUStack\"\n",
    "config      = configparser.ConfigParser()\n",
    "# config.read('../config/OPT_small_RAM')\n",
    "config.read(config_path)\n",
    "# config.read('../config/OPT_large_RAM')\n",
    "\n",
    "\n",
    "RANDOM_SEED         = config.getint(\"Misc\", \"RANDOM_SEED\")\n",
    "\n",
    "BATCH_SIZE          = config.getint('Training', 'BATCH_SIZE') #- 2048 - 1024\n",
    "NUM_EPOCHS          = config.getint('Training', 'NUM_EPOCHS')\n",
    "MODEL_NAME          = config.get('Training', 'MODEL_NAME')\n",
    "SETTING_1M1         = config.getboolean('Training', 'SETTING_1M1')\n",
    "\n",
    "DATA_PATH           = \"../\" + config.get('Paths', 'DATA_PATH')\n",
    "EMBEDDINGS_PATH     = \"../\" + config.get('Paths', 'EMBEDDINGS_PATH')\n",
    "HISTORY_PATH        = \"../\" + config.get('Paths', 'HISTORY_PATH')\n",
    "LOGGING_PATH        = \"\"#config.get('Paths', 'LOGGING_PATH')\n",
    "MODELS_PATH         = \"../\" + config.get('Paths', 'MODELS_PATH')\n",
    "SENTIMENT_PATH      = \"../\" + config.get('Paths', 'SENTIMENT_PATH')\n",
    "\n",
    "\n",
    "PRE_TRAINING_ON_TSA = config.getboolean('Sentiment', 'PRE_TRAINING_ON_TSA')\n",
    "SENTIMENT_LABEL     = config.get('Sentiment', 'SENTIMENT_LABEL')\n",
    "SENTIMENT_TEXT      = config.get('Sentiment', 'SENTIMENT_TEXT')\n",
    "TRIM                = config.getboolean('Sentiment', 'TRIM')\n",
    "TRIM                = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 11.\n",
      "Processing text dataset:\n",
      "Found 7,475 texts.\n",
      "\n",
      "Tokenizer created!\n",
      "Tokenizer fitted on 7,475 texts.\n",
      "\n",
      "Vectorizing given data...\n",
      "The longest tweet/text has 34 words.\n",
      "Shape of data_sequences tensor: (7475, 35)\n",
      "Shape of label tensor: (7475,).\n",
      "\n",
      "Binarized labels!\n"
     ]
    }
   ],
   "source": [
    "#Set random seed for the experiment:\n",
    "np.random.seed(RANDOM_SEED)\n",
    "# random.seed(RANDOM_SEED)\n",
    "print(\"Random seed set to %d.\" %RANDOM_SEED)\n",
    "\n",
    "#Project pipeline:\n",
    "if LOGGING_PATH != \"\":\n",
    "    sys.stdout = open(LOGGING_PATH, 'w')\n",
    "# else:\n",
    "#     sys.stdout = sys.__stdout__\n",
    "#     pass\n",
    "\n",
    "#Read data: list of tweets & list of golden lables:\n",
    "opt_tweets, opt_gold_labels = read_OPT_data(DATA_PATH)\n",
    "#Define tokenizer:\n",
    "custom_tokenizer    = CustomTokenizer()#.fit_on_texts(tweets)\n",
    "MAX_SEQUENCE_LENGTH = None\n",
    "\n",
    "\n",
    "if PRE_TRAINING_ON_TSA:\n",
    "    sent_tweets, sent_gold_labels = read_OPT_data(data_path=SENTIMENT_PATH\\\n",
    "                                       , text_column=SENTIMENT_TEXT\\\n",
    "                                       , label_column=SENTIMENT_LABEL)\n",
    "    custom_tokenizer    = custom_tokenizer.fit_on_texts(opt_tweets\\\n",
    "                                                        + sent_tweets)\n",
    "\n",
    "    if TRIM:\n",
    "        MAX_SEQUENCE_LENGTH = max(map(lambda x: len(x.split(\" \")), opt_tweets))\n",
    "    else:\n",
    "        MAX_SEQUENCE_LENGTH = max(map(lambda x: len(x.split(\" \")), sent_tweets))\n",
    "    #Tokenize data using the tokenizer:\n",
    "    sent_vectorized_tweets, sent_gold_labels = vectorize_data(\\\n",
    "                                                   sent_tweets\\\n",
    "                                                 , sent_gold_labels\\\n",
    "                                                 , custom_tokenizer\\\n",
    "                                                 , MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH)\n",
    "    sent_gold_labels = binarize_labels(sent_gold_labels, max_negative_value=0)\n",
    "else:\n",
    "    custom_tokenizer    = custom_tokenizer.fit_on_texts(opt_tweets)\n",
    "    #Tokenize data using the tokenizer:\n",
    "\n",
    "opt_vectorized_tweets, opt_gold_labels = vectorize_data(opt_tweets\\\n",
    "                                             , opt_gold_labels\\\n",
    "                                             , custom_tokenizer\\\n",
    "                                             , MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "#If we ignore tweets with annotation in (-1, 1):\n",
    "if SETTING_1M1:\n",
    "    opt_vectorized_tweets, opt_gold_labels = remove_vague_tweets(\\\n",
    "                                                            opt_vectorized_tweets\\\n",
    "                                                          , opt_gold_labels)\n",
    "#Binarize gold_labels:\n",
    "opt_gold_labels = binarize_labels(opt_gold_labels\\\n",
    "                                  , max_negative_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted data into Train: 5981; Dev: 747; Test: 747.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if PRE_TRAINING_ON_TSA:\n",
    "    x_train, y_train = sent_vectorized_tweets, sent_gold_labels\n",
    "    x_dev, y_dev     = opt_vectorized_tweets, opt_gold_labels\n",
    "    x_test, y_test   = opt_vectorized_tweets, opt_gold_labels\n",
    "\n",
    "    x_train_opt, y_train_opt, x_dev_opt, y_dev_opt, x_test_opt, y_test_opt = \\\n",
    "        train_dev_test_split(opt_vectorized_tweets\\\n",
    "                             , opt_gold_labels, R_SEED=RANDOM_SEED)\n",
    "    x_dev_opt = np.vstack([x_dev_opt, x_test_opt])\n",
    "    y_dev_opt = np.vstack([y_dev_opt, y_test_opt])\n",
    "    \n",
    "else:\n",
    "    #Train/Dev/Test split:\n",
    "    x_train, y_train, x_dev, y_dev, x_test, y_test = \\\n",
    "        train_dev_test_split(opt_vectorized_tweets\\\n",
    "                             , opt_gold_labels, R_SEED=RANDOM_SEED)\n",
    "    \n",
    "    x_dev_opt = np.vstack([x_dev, x_test])\n",
    "    y_dev_opt = np.vstack([y_dev, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing pre-trained word vectors...\n",
      "Using glove.twitter.27B.200d.txt:\n",
      "Found 1,193,514 pre-trained word vectors.\n",
      "The words will be embedded in 200-dimensional vectors.\n",
      "Embedding layer prepared.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load pretrained Embeddings:\n",
    "# EMBEDDINGS_PATH = \"../../embeddings/glove.840B.300d/glove.840B.300d.txt\"\n",
    "# EMBEDDINGS_PATH = \"../../embeddings/crawl-300d-2M-subword/crawl-300d-2M-subword.vec\"\n",
    "EMBEDDINGS_PATH = \"../../embeddings/glove.twitter.27B/glove.twitter.27B.200d.txt\"\n",
    "\n",
    "\n",
    "embedder = Embedder(EMBEDDINGS_PATH)\n",
    "embedding_layer = embedder.build_embedding_layers(custom_tokenizer,\\\n",
    "                                                 trainable=False)\n",
    "\n",
    "from copy import deepcopy as copy\n",
    "\n",
    "embedding_layer_bk = copy(embedding_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The only fragment which needs to be rerun after changing configs, without emedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Transformer model...\n"
     ]
    }
   ],
   "source": [
    "#model architecture:\n",
    "model_builder = get_model_builder(MODEL_NAME)\n",
    "# model_builder = get_model_builder(\"GRUstack_model\")\n",
    "model         = model_builder(embedding_layer, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 35)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 35, 200)           3233800   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 35, 200)           174632    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               2100300   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 5,589,234\n",
      "Trainable params: 2,355,434\n",
      "Non-trainable params: 3,233,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'activity_regularizer': None,\n",
       "  'batch_input_shape': (None, 35),\n",
       "  'dtype': 'float32',\n",
       "  'embeddings_constraint': None,\n",
       "  'embeddings_initializer': {'class_name': 'Constant',\n",
       "   'config': {'value': array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "             0.        ,  0.        ],\n",
       "           [ 0.056404  ,  0.49535999,  0.18438999, ...,  0.63598001,\n",
       "            -0.18880001, -0.035558  ],\n",
       "           [ 0.49349999,  0.35698   ,  0.66068   , ...,  0.17705999,\n",
       "            -0.53694999, -0.29699001],\n",
       "           ...,\n",
       "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "             0.        ,  0.        ],\n",
       "           [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "             0.        ,  0.        ],\n",
       "           [ 0.053869  ,  0.3964    , -0.2141    , ...,  0.55834001,\n",
       "            -0.85913998,  0.47907001]])}},\n",
       "  'embeddings_regularizer': None,\n",
       "  'input_dim': 16169,\n",
       "  'input_length': 35,\n",
       "  'mask_zero': False,\n",
       "  'name': 'embedding_1',\n",
       "  'output_dim': 200,\n",
       "  'trainable': False},\n",
       " 35)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUM_EPOCHS = 15\n",
    "embedding_layer.get_config(), embedding_layer.get_config()[\"input_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[-1].output_shape\n",
    "\n",
    "freeze = False\n",
    "\n",
    "if freeze = True:\n",
    "    for layer in model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    \n",
    "model.layers[-4].trainable, model.layers[-4]\\, # BATCH_SIZE = 256\n",
    "x_train.shape, x_dev_opt.shape, BATCH_SIZE, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3079, 35), (768, 35), 256)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Transformer_model...\n",
      "Train on 5981 samples, validate on 1494 samples\n",
      "Epoch 1/15\n",
      "5981/5981 [==============================] - 25s 4ms/sample - loss: 0.5973 - accuracy: 0.6944 - val_loss: 0.5287 - val_accuracy: 0.7262\n",
      "Epoch 2/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.4782 - accuracy: 0.7719 - val_loss: 0.5211 - val_accuracy: 0.7323\n",
      "Epoch 3/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.4547 - accuracy: 0.7836 - val_loss: 0.4795 - val_accuracy: 0.7764\n",
      "Epoch 4/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.4285 - accuracy: 0.8022 - val_loss: 0.4735 - val_accuracy: 0.7718\n",
      "Epoch 5/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.4059 - accuracy: 0.8057 - val_loss: 0.4861 - val_accuracy: 0.7871\n",
      "Epoch 6/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.3609 - accuracy: 0.8366 - val_loss: 0.5076 - val_accuracy: 0.7764\n",
      "Epoch 7/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.3100 - accuracy: 0.8624 - val_loss: 0.5655 - val_accuracy: 0.7758\n",
      "Epoch 8/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.2448 - accuracy: 0.8903 - val_loss: 0.5878 - val_accuracy: 0.7590\n",
      "Epoch 9/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.1884 - accuracy: 0.9166 - val_loss: 0.7424 - val_accuracy: 0.7282\n",
      "Epoch 10/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.1418 - accuracy: 0.9416 - val_loss: 0.8315 - val_accuracy: 0.7396\n",
      "Epoch 11/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.1012 - accuracy: 0.9607 - val_loss: 0.9606 - val_accuracy: 0.7677\n",
      "Epoch 12/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.0789 - accuracy: 0.9719 - val_loss: 1.1425 - val_accuracy: 0.7771\n",
      "Epoch 13/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.0544 - accuracy: 0.9789 - val_loss: 1.2977 - val_accuracy: 0.7644\n",
      "Epoch 14/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.0511 - accuracy: 0.9814 - val_loss: 1.2440 - val_accuracy: 0.7336\n",
      "Epoch 15/15\n",
      "5981/5981 [==============================] - 23s 4ms/sample - loss: 0.0356 - accuracy: 0.9885 - val_loss: 1.4363 - val_accuracy: 0.7657\n",
      "Transformer_model trained!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Train model:\n",
    "training_history, model = train_model(model=model\\\n",
    "                                      , model_name = MODEL_NAME\\\n",
    "                                      , x_train = x_train\\\n",
    "                                      , y_train = y_train\\\n",
    "                                      , x_dev   = x_dev_opt\\\n",
    "                                      , y_dev   = y_dev_opt\\\n",
    "                                      , epochs      = NUM_EPOCHS\\\n",
    "                                      , batch_size  = BATCH_SIZE\\\n",
    "                                      , models_path = MODELS_PATH\\\n",
    "                                      , histories_path=HISTORY_PATH)\n",
    "##########################################\n",
    "#Save trained model & Training history:\n",
    "if \"val_acc\" not in training_history.history:\n",
    "    val_acc    = \"valAcc%.3f\"%(training_history.history[\"val_accuracy\"][-1])\n",
    "    # training_history.history[\"val_acc\"] = training_history.history[\"val_accuracy\"]\n",
    "else:\n",
    "    val_acc    = \"valAcc%.3f\"%(training_history.history[\"val_acc\"][-1])\n",
    "\n",
    "\n",
    "# emb_name   = \"GloVe\" if \"glove\" in EMBEDDINGS_PATH else \"FastText\"\n",
    "# time_stamp = strftime(\"%H%M%S_%Y%m%d\", gmtime())\n",
    "# time_stamp = \"_\".join((config_path.split(\"/\")[-1], emb_name, val_acc, time_stamp))\n",
    "\n",
    "# #Save configuration file:\n",
    "# config_hist = HISTORY_PATH + \"config_%s\" %time_stamp\n",
    "# copyfile(config_path, config_hist)\n",
    "# print(\"Configurations saved in %s.\" \\\n",
    "#         %(config_hist))\n",
    "\n",
    "# #Save training history dictionary:\n",
    "# training_history_fn = HISTORY_PATH + (\"history_%s.csv\" %time_stamp)\n",
    "# pd.DataFrame(training_history.history)\\\n",
    "#     .to_csv(training_history_fn)\n",
    "# print(\"Training history saved in %s.\" \\\n",
    "#         %(training_history_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.utils.plot_model(model, to_file=\"../plots/uncontextual_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If transfer learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted data into Train: 5981; Dev: 747; Test: 747.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_dev, y_dev, x_test, y_test = \\\n",
    "    train_dev_test_split(opt_vectorized_tweets\\\n",
    "                         , opt_gold_labels, R_SEED=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN_model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5981 samples, validate on 747 samples\n",
      "Epoch 1/15\n",
      "5981/5981 [==============================] - 1s 107us/step - loss: 0.4261 - accuracy: 0.8022 - val_loss: 0.3910 - val_accuracy: 0.8139\n",
      "Epoch 2/15\n",
      "5981/5981 [==============================] - 0s 45us/step - loss: 0.2112 - accuracy: 0.9189 - val_loss: 0.4221 - val_accuracy: 0.8340\n",
      "Epoch 3/15\n",
      "5981/5981 [==============================] - 0s 45us/step - loss: 0.1202 - accuracy: 0.9530 - val_loss: 0.4466 - val_accuracy: 0.8461\n",
      "Epoch 4/15\n",
      "5981/5981 [==============================] - 0s 44us/step - loss: 0.0669 - accuracy: 0.9743 - val_loss: 0.5010 - val_accuracy: 0.8434\n",
      "Epoch 5/15\n",
      "5981/5981 [==============================] - 0s 44us/step - loss: 0.0367 - accuracy: 0.9865 - val_loss: 0.6085 - val_accuracy: 0.8541\n",
      "Epoch 6/15\n",
      "5981/5981 [==============================] - 0s 44us/step - loss: 0.0202 - accuracy: 0.9926 - val_loss: 0.7337 - val_accuracy: 0.8541\n",
      "Epoch 7/15\n",
      "5981/5981 [==============================] - 0s 45us/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.8401 - val_accuracy: 0.8514\n",
      "Epoch 8/15\n",
      "5981/5981 [==============================] - 0s 45us/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.9364 - val_accuracy: 0.8527\n",
      "Epoch 9/15\n",
      "5981/5981 [==============================] - 0s 45us/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.0065 - val_accuracy: 0.8527\n",
      "Epoch 10/15\n",
      "5981/5981 [==============================] - 0s 45us/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.0339 - val_accuracy: 0.8527\n",
      "Epoch 11/15\n",
      "5981/5981 [==============================] - 0s 45us/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 1.0686 - val_accuracy: 0.8541\n",
      "Epoch 12/15\n",
      "5981/5981 [==============================] - 0s 44us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.0867 - val_accuracy: 0.8487\n",
      "Epoch 13/15\n",
      "5981/5981 [==============================] - 0s 44us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 1.1138 - val_accuracy: 0.8568\n",
      "Epoch 14/15\n",
      "5981/5981 [==============================] - 0s 44us/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.1430 - val_accuracy: 0.8541\n",
      "Epoch 15/15\n",
      "5981/5981 [==============================] - 0s 44us/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.1682 - val_accuracy: 0.8541\n",
      "CNN_model trained!\n",
      "Configurations saved in .././histories/largeRAM/config_lRAM_TSA_0_CNN_valAcc0.854_173620_20200325.\n",
      "Training history saved in .././histories/largeRAM/history_lRAM_TSA_0_CNN_valAcc0.854_173620_20200325.csv.\n"
     ]
    }
   ],
   "source": [
    "#model architecture:\n",
    "# model_builder = get_model_builder(MODEL_NAME)\n",
    "# model         = model_builder(embedding_layer, RANDOM_SEED)\n",
    "\n",
    "\n",
    "#Train model:\n",
    "training_history, model = train_model(model=model\\\n",
    "                                      , model_name = MODEL_NAME\\\n",
    "                                      , x_train = x_train\\\n",
    "                                      , y_train = y_train\\\n",
    "                                      , x_dev   = x_dev\\\n",
    "                                      , y_dev   = y_dev\\\n",
    "                                      , epochs      = NUM_EPOCHS\\\n",
    "                                      , batch_size  = BATCH_SIZE\\\n",
    "                                      , models_path = MODELS_PATH\\\n",
    "                                      , histories_path=HISTORY_PATH)\n",
    "##########################################\n",
    "#Save trained model & Training history:\n",
    "if \"val_acc\" not in training_history.history:\n",
    "    val_acc    = \"valAcc%.3f\"%(training_history.history[\"val_accuracy\"][-1])\n",
    "    # training_history.history[\"val_acc\"] = training_history.history[\"val_accuracy\"]\n",
    "else:\n",
    "    val_acc    = \"valAcc%.3f\"%(training_history.history[\"val_acc\"][-1])\n",
    "\n",
    "\n",
    "time_stamp = strftime(\"%H%M%S_%Y%m%d\", gmtime())\n",
    "time_stamp = \"_\".join((config_path.split(\"/\")[-1], val_acc, time_stamp))\n",
    "\n",
    "#Save configuration file:\n",
    "config_hist = HISTORY_PATH + \"config_%s\" %time_stamp\n",
    "copyfile(config_path, config_hist)\n",
    "print(\"Configurations saved in %s.\" \\\n",
    "        %(config_hist))\n",
    "\n",
    "#Save training history dictionary:\n",
    "training_history_fn = HISTORY_PATH + (\"history_%s.csv\" %time_stamp)\n",
    "pd.DataFrame(training_history.history)\\\n",
    "    .to_csv(training_history_fn)\n",
    "print(\"Training history saved in %s.\" \\\n",
    "        %(training_history_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drafts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset:\n",
      "Found 7,475 texts.\n",
      "\n",
      "Tokenizer created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset:\n",
      "Found 1,578,612 texts.\n",
      "\n",
      "Tokenizer fitted on 1,586,087 texts.\n",
      "\n",
      "Vectorizing given data...\n",
      "The longest tweet/text has 110 words.\n",
      "Shape of data_sequences tensor: (1578612, 111)\n",
      "Shape of label tensor: (1578612,).\n",
      "\n",
      "Binarized labels!\n",
      "Vectorizing given data...\n",
      "The longest tweet/text has 110 words.\n",
      "Shape of data_sequences tensor: (7475, 111)\n",
      "Shape of label tensor: (7475,).\n",
      "\n",
      "Binarized labels!\n"
     ]
    }
   ],
   "source": [
    "#Project pipeline:\n",
    "if LOGGING_PATH != \"\":\n",
    "    sys.stdout = open(LOGGING_PATH, 'w')\n",
    "# else:\n",
    "#     sys.stdout = sys.__stdout__\n",
    "#     pass\n",
    "\n",
    "#Read data: list of tweets & list of golden lables:\n",
    "opt_tweets, opt_gold_labels = read_OPT_data(DATA_PATH)\n",
    "#Define tokenizer:\n",
    "custom_tokenizer    = CustomTokenizer()#.fit_on_texts(tweets)\n",
    "MAX_SEQUENCE_LENGTH = None\n",
    "\n",
    "\n",
    "if PRE_TRAINING_ON_TSA:\n",
    "    sent_tweets, sent_gold_labels = read_OPT_data(data_path=SENTIMENT_PATH\\\n",
    "                                       , text_column=SENTIMENT_TEXT\\\n",
    "                                       , label_column=SENTIMENT_LABEL)\n",
    "    custom_tokenizer    = custom_tokenizer.fit_on_texts(opt_tweets\\\n",
    "                                                        + sent_tweets)\n",
    "    \n",
    "#     MAX_SEQUENCE_LENGTH = max(map(lambda x: len(x.split(\" \")), opt_tweets)) + 1\n",
    "    MAX_SEQUENCE_LENGTH = max(map(lambda x: len(x.split(\" \")), sent_tweets)) + 1\n",
    "    \n",
    "    #Tokenize data using the tokenizer:\n",
    "    sent_vectorized_tweets, sent_gold_labels = vectorize_data(\\\n",
    "                                                   sent_tweets\\\n",
    "                                                 , sent_gold_labels\\\n",
    "                                                 , custom_tokenizer\\\n",
    "                                                 , MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH)\n",
    "    sent_gold_labels = binarize_labels(sent_gold_labels, max_negative_value=0)\n",
    "else:\n",
    "    custom_tokenizer    = custom_tokenizer.fit_on_texts(opt_tweets)\n",
    "    #Tokenize data using the tokenizer:\n",
    "\n",
    "opt_vectorized_tweets, opt_gold_labels = vectorize_data(opt_tweets\\\n",
    "                                             , opt_gold_labels\\\n",
    "                                             , custom_tokenizer\\\n",
    "                                             , MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "#Binarize gold_labels:\n",
    "opt_gold_labels = binarize_labels(opt_gold_labels\\\n",
    "                                  , max_negative_value=0)\n",
    "\n",
    "\n",
    "if PRE_TRAINING_ON_TSA:\n",
    "    x_train, y_train = sent_vectorized_tweets, sent_gold_labels\n",
    "    x_dev, y_dev     = opt_vectorized_tweets, opt_gold_labels\n",
    "    x_test, y_test   = opt_vectorized_tweets, opt_gold_labels\n",
    "\n",
    "else:\n",
    "    #Train/Dev/Test split:\n",
    "    x_train, y_train, x_dev, y_dev, x_test, y_test = \\\n",
    "        train_dev_test_split(opt_vectorized_tweets\\\n",
    "                             , opt_gold_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing pre-trained word vectors...\n",
      "Using glove.twitter.27B.25d.txt:\n",
      "Found 1,193,514 pre-trained word vectors.\n",
      "The words will be embedded in 25-dimensional vectors.\n"
     ]
    }
   ],
   "source": [
    "# embedder = Embedder(\"../../embeddings/glove.840B.300d/glove.840B.300d.txt\")\n",
    "# embedder = Embedder(\"../../embeddings/crawl-300d-2M-subword/crawl-300d-2M-subword.vec\")\n",
    "embedder = Embedder('../../embeddings/glove.twitter.27B/glove.twitter.27B.25d.txt' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The only fragment which needs to be rerun after changing configs, without emedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model architecture:\n",
    "model_builder = get_model_builder(MODEL_NAME)\n",
    "model         = model_builder(embedding_layer)\n",
    "\n",
    "\n",
    "#Train model:\n",
    "training_history, model = train_model(model=model\\\n",
    "                                      , model_name=MODEL_NAME\\\n",
    "                                      , x_train = x_train\\\n",
    "                                      , y_train = y_train\\\n",
    "                                      , x_dev   = x_dev\\\n",
    "                                      , y_dev   = y_dev\\\n",
    "                                      , epochs      = NUM_EPOCHS\\\n",
    "                                      , batch_size  = BATCH_SIZE\\\n",
    "                                      , models_path = MODELS_PATH\\\n",
    "                                      , histories_path=HISTORY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Embedder.Embedder at 0x7f0a693cc748>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Embedding layer prepared.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load pretrained Embeddings:\n",
    "# embedder = Embedder(EMBEDDINGS_PATH)\n",
    "embedding_layer = embedder.build_embedding_layers(custom_tokenizer,\\\n",
    "                                                 trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.embeddings_size#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-329c18a089f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"anaaaa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'm'"
     ]
    }
   ],
   "source": [
    "embedder.embeddings_index.get(\"anaaaa\").m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project  configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config/OPT_small_RAM')\n",
    "# config.read('../config/OPT_large_RAM')\n",
    "\n",
    "\n",
    "BATCH_SIZE          = config.getint('Training', 'BATCH_SIZE')\n",
    "NUM_EPOCHS          = config.getint('Training', 'NUM_EPOCHS')\n",
    "MODEL_NAME          = config.get('Training', 'MODEL_NAME')\n",
    "SETTING_1M1         = config.getboolean('Training', 'SETTING_1M1')\n",
    "\n",
    "DATA_PATH           = config.get('Paths', 'DATA_PATH')\n",
    "EMBEDDINGS_PATH     = config.get('Paths', 'EMBEDDINGS_PATH')\n",
    "HISTORY_PATH        = config.get('Paths', 'HISTORY_PATH')\n",
    "LOGGING_PATH        = config.get('Paths', 'LOGGING_PATH')\n",
    "MODELS_PATH         = config.get('Paths', 'MODELS_PATH')\n",
    "SENTIMENT_PATH      = config.get('Paths', 'SENTIMENT_PATH')\n",
    "\n",
    "                                 \n",
    "PRE_TRAINING_ON_TSA = config.getboolean('Sentiment', 'PRE_TRAINING_ON_TSA')\n",
    "SENTIMENT_LABEL     = config.get('Sentiment', 'SENTIMENT_LABEL')\n",
    "SENTIMENT_TEXT      = config.get('Sentiment', 'SENTIMENT_TEXT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE      = 4096\n",
    "DATA_PATH       = \"../../data/optimism-twitter-data/tweets_annotation.csv\"\n",
    "# EMBEDDINGS_PATH = '../../embeddings/glove.twitter.27B/glove.twitter.27B.25d.txt' \n",
    "# EMBEDDINGS_PATH = '../../embeddings/glove.840B.300d/glove.840B.300d.txt' \n",
    "EMBEDDINGS_PATH = '../../embeddings/crawl-300d-2M-subword/crawl-300d-2M-subword.vec' \n",
    "LOGGING_PATH    = ''\n",
    "# LOGGING_PATH    ='./code/logging/first_log'\n",
    "MODEL_NAME          = \"BiLSTM_model\"\n",
    "# MODEL_NAME          = \"CNN_model\"\n",
    "#MODEL_NAME          = \"GRUstack_model\"\n",
    "MODELS_PATH     = \"../models/\"\n",
    "NUM_EPOCHS      = 20\n",
    "#Consider only Tweets with reviews not in (-1, 1):\n",
    "# SETTING_1M1     = True\n",
    "SETTING_1M1     = False\n",
    "HISTORY_PATH    = '../histories/'\n",
    "\n",
    "# PRE_TRAINING_ON_TSA = False\n",
    "PRE_TRAINING_ON_TSA = True\n",
    "SENTIMENT_PATH      = \"../../data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\"\n",
    "SENTIMENT_LABEL     = \"Sentiment\"\n",
    "SENTIMENT_TEXT      = \"SentimentText\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset:\n",
      "Found 7,475 texts.\n",
      "\n",
      "Tokenizer created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset:\n",
      "Found 1,578,612 texts.\n",
      "\n",
      "Tokenizer fitted on 1,586,087 texts.\n",
      "\n",
      "Vectorizing given data...\n",
      "The longest tweet/text has 34 words.\n",
      "Shape of data_sequences tensor: (1578612, 35)\n",
      "Shape of label tensor: (1578612,).\n",
      "\n",
      "Binarized labels!\n",
      "Vectorizing given data...\n",
      "The longest tweet/text has 34 words.\n",
      "Shape of data_sequences tensor: (7475, 35)\n",
      "Shape of label tensor: (7475,).\n",
      "\n",
      "Binarized labels!\n",
      "Indexing pre-trained word vectors...\n",
      "Using crawl-300d-2M-subword.vec:\n",
      "Found 2,000,000 pre-trained word vectors.\n",
      "The words will be embedded in 300-dimensional vectors.\n",
      "Embedding layer prepared.\n",
      "\n",
      "Building BiLSTM model...\n",
      "Training model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1578612 samples, validate on 7475 samples\n",
      "Epoch 1/20\n",
      "1578612/1578612 [==============================] - 80s 50us/step - loss: 0.4251 - accuracy: 0.8023 - val_loss: 0.5243 - val_accuracy: 0.7385\n",
      "Epoch 2/20\n",
      "1578612/1578612 [==============================] - 79s 50us/step - loss: 0.3150 - accuracy: 0.8638 - val_loss: 0.5609 - val_accuracy: 0.7387\n",
      "Epoch 3/20\n",
      "1578612/1578612 [==============================] - 79s 50us/step - loss: 0.2237 - accuracy: 0.9068 - val_loss: 0.6368 - val_accuracy: 0.7328\n",
      "Epoch 4/20\n",
      "1578612/1578612 [==============================] - 79s 50us/step - loss: 0.1657 - accuracy: 0.9309 - val_loss: 0.8547 - val_accuracy: 0.7212\n",
      "Epoch 5/20\n",
      "1578612/1578612 [==============================] - 79s 50us/step - loss: 0.1307 - accuracy: 0.9454 - val_loss: 1.0022 - val_accuracy: 0.7168\n",
      "Epoch 6/20\n",
      "1578612/1578612 [==============================] - 79s 50us/step - loss: 0.1083 - accuracy: 0.9551 - val_loss: 1.2556 - val_accuracy: 0.7061\n",
      "Epoch 7/20\n",
      "1578612/1578612 [==============================] - 79s 50us/step - loss: 0.0922 - accuracy: 0.9622 - val_loss: 1.4068 - val_accuracy: 0.7077\n",
      "Epoch 8/20\n",
      "1578612/1578612 [==============================] - 79s 50us/step - loss: 0.0799 - accuracy: 0.9676 - val_loss: 1.5874 - val_accuracy: 0.7080\n",
      "Epoch 9/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0705 - accuracy: 0.9715 - val_loss: 1.6780 - val_accuracy: 0.7073\n",
      "Epoch 10/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0627 - accuracy: 0.9748 - val_loss: 1.7934 - val_accuracy: 0.7053\n",
      "Epoch 11/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0558 - accuracy: 0.9777 - val_loss: 1.9217 - val_accuracy: 0.7038\n",
      "Epoch 12/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0504 - accuracy: 0.9800 - val_loss: 1.9809 - val_accuracy: 0.7054\n",
      "Epoch 13/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0454 - accuracy: 0.9820 - val_loss: 2.0468 - val_accuracy: 0.7081\n",
      "Epoch 14/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0415 - accuracy: 0.9836 - val_loss: 2.1692 - val_accuracy: 0.7022\n",
      "Epoch 15/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0376 - accuracy: 0.9852 - val_loss: 2.2617 - val_accuracy: 0.7002\n",
      "Epoch 16/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0343 - accuracy: 0.9865 - val_loss: 2.1637 - val_accuracy: 0.7060\n",
      "Epoch 17/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0312 - accuracy: 0.9878 - val_loss: 2.2772 - val_accuracy: 0.7021\n",
      "Epoch 18/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0290 - accuracy: 0.9886 - val_loss: 2.3862 - val_accuracy: 0.7086\n",
      "Epoch 19/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0264 - accuracy: 0.9896 - val_loss: 2.4392 - val_accuracy: 0.7057\n",
      "Epoch 20/20\n",
      "1578612/1578612 [==============================] - 78s 50us/step - loss: 0.0243 - accuracy: 0.9905 - val_loss: 2.3942 - val_accuracy: 0.7002\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b2a1a8db985f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                       \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                       \u001b[0;34m,\u001b[0m \u001b[0mmodels_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODELS_PATH\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                       , histories_path=HISTORY_PATH)\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# return training_history, model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/optimism/Exploring-Optimism/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name, x_train, y_train, x_dev, y_dev, epochs, batch_size, models_path, trained_model_fn, histories_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#Save trained model & Training history:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mval_acc\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;34m\"valAcc%.3f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mtime_stamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%H%M%S_%Y%m%d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtime_stamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_stamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "#Project pipeline:\n",
    "if LOGGING_PATH != \"\":\n",
    "    sys.stdout = open(LOGGING_PATH, 'w')\n",
    "# else:\n",
    "#     sys.stdout = sys.__stdout__\n",
    "#     pass\n",
    "\n",
    "#Read data: list of tweets & list of golden lables:\n",
    "opt_tweets, opt_gold_labels = read_OPT_data(DATA_PATH)\n",
    "#Define tokenizer:\n",
    "custom_tokenizer    = CustomTokenizer()#.fit_on_texts(tweets)\n",
    "MAX_SEQUENCE_LENGTH = None\n",
    "\n",
    "\n",
    "if PRE_TRAINING_ON_TSA:\n",
    "    sent_tweets, sent_gold_labels = read_OPT_data(data_path=SENTIMENT_PATH\\\n",
    "                                       , text_column=SENTIMENT_TEXT\\\n",
    "                                       , label_column=SENTIMENT_LABEL)\n",
    "    custom_tokenizer    = custom_tokenizer.fit_on_texts(opt_tweets\\\n",
    "                                                        + sent_tweets)\n",
    "    \n",
    "    MAX_SEQUENCE_LENGTH = max(map(lambda x: len(x.split(\" \")), opt_tweets)) + 1\n",
    "    #Tokenize data using the tokenizer:\n",
    "    sent_vectorized_tweets, sent_gold_labels = vectorize_data(\\\n",
    "                                                   sent_tweets\\\n",
    "                                                 , sent_gold_labels\\\n",
    "                                                 , custom_tokenizer\\\n",
    "                                                 , MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH)\n",
    "    sent_gold_labels = binarize_labels(sent_gold_labels, max_negative_value=0)\n",
    "else:\n",
    "    custom_tokenizer    = custom_tokenizer.fit_on_texts(opt_tweets)\n",
    "    #Tokenize data using the tokenizer:\n",
    "\n",
    "opt_vectorized_tweets, opt_gold_labels = vectorize_data(opt_tweets\\\n",
    "                                             , opt_gold_labels\\\n",
    "                                             , custom_tokenizer\\\n",
    "                                             , MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "#If we ignore tweets with annotation in (-1, 1):\n",
    "if SETTING_1M1:\n",
    "    opt_vectorized_tweets, opt_gold_labels = remove_vague_tweets(\\\n",
    "                                                            opt_vectorized_tweets\\\n",
    "                                                          , opt_gold_labels)\n",
    "#Binarize gold_labels:\n",
    "opt_gold_labels = binarize_labels(opt_gold_labels\\\n",
    "                                  , max_negative_value=0)\n",
    "\n",
    "\n",
    "if PRE_TRAINING_ON_TSA:\n",
    "    x_train, y_train = sent_vectorized_tweets, sent_gold_labels\n",
    "    x_dev, y_dev     = opt_vectorized_tweets, opt_gold_labels\n",
    "    x_test, y_test   = opt_vectorized_tweets, opt_gold_labels\n",
    "\n",
    "else:\n",
    "    #Train/Dev/Test split:\n",
    "    x_train, y_train, x_dev, y_dev, x_test, y_test = \\\n",
    "        train_dev_test_split(opt_vectorized_tweets\\\n",
    "                             , opt_gold_labels)\n",
    "\n",
    "#Load pretrained Embeddings:\n",
    "embedder = Embedder(EMBEDDINGS_PATH)\n",
    "embedding_layer = embedder.build_embedding_layers(custom_tokenizer,\\\n",
    "                                                 trainable=True)\n",
    "\n",
    "#model architecture:\n",
    "model_builder = get_model_builder(MODEL_NAME)\n",
    "model         = model_builder(embedding_layer)\n",
    "\n",
    "\n",
    "#Train model:\n",
    "training_history, model = train_model(model=model\\\n",
    "                                      , model_name=MODEL_NAME\\\n",
    "                                      , x_train = x_train\\\n",
    "                                      , y_train = y_train\\\n",
    "                                      , x_dev   = x_dev\\\n",
    "                                      , y_dev   = y_dev\\\n",
    "                                      , epochs      = NUM_EPOCHS\\\n",
    "                                      , batch_size  = BATCH_SIZE\\\n",
    "                                      , models_path = MODELS_PATH\\\n",
    "                                      , histories_path=HISTORY_PATH)\n",
    "\n",
    "# return training_history, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f18c5dd6c1fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_history' is not defined"
     ]
    }
   ],
   "source": [
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.857_CNN_model'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"_\".join((\"%.3f\"%(training_history.history[\"val_acc\"][-1]), MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"../main.py\", line 50, in <module>\n",
      "    opt_tweets, opt_gold_labels = read_OPT_data(DATA_PATH)\n",
      "  File \"/media/stefan/New Volume/master_materials/Thesis/Optimism/Exploring-Optimism/data_preparation.py\", line 22, in read_OPT_data\n",
      "    , error_bad_lines=False)# + train_file)\n",
      "  File \"/home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas/io/parsers.py\", line 709, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas/io/parsers.py\", line 449, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas/io/parsers.py\", line 818, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas/io/parsers.py\", line 1049, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas/io/parsers.py\", line 1695, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 402, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 718, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: File b'../data/optimism-twitter-data/tweets_annotation.csv' does not exist\n"
     ]
    }
   ],
   "source": [
    "!python ../main.py -c ../config/TSA_small_RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drafts separator update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset:\n",
      "Found 7,475 texts.\n",
      "\n",
      "Tokenizer created!\n",
      "Tokenizer fitted on 7475 texts.\n",
      "\n",
      "Vectorizing given data...\n",
      "The longest tweet/text has 34 words.\n",
      "Shape of data_sequences tensor: (7475, 35)\n",
      "Shape of label tensor: (7475,).\n",
      "\n",
      "Removed tweets with AverageAnnotation in (-1, 1).\n",
      "Binarized labels!\n",
      "Splitted data into Train: 3079; Dev: 384; Test: 384.\n",
      "\n",
      "Indexing pre-trained word vectors...\n",
      "Using glove.840B.300d.txt:\n",
      "Found 2,195,884 pre-trained word vectors.\n",
      "The words will be embedded in 300-dimensional vectors.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0) into shape (300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f4698c2fa37c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0membedder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDINGS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m embedding_layer = embedder.build_embedding_layers(custom_tokenizer,\\\n\u001b[0;32m---> 56\u001b[0;31m                                                  trainable=True)\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#model architecture:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/optimism/code/Embedder.py\u001b[0m in \u001b[0;36mbuild_embedding_layers\u001b[0;34m(self, custom_tokenizer, trainable)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;31m# words not found in embedding index will be all-zeros.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# load pre-trained word embeddings into an Embedding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (0) into shape (300)"
     ]
    }
   ],
   "source": [
    "if LOGGING_PATH != \"\":\n",
    "    print(\"Normal printing.\")\n",
    "    sys.stdout = open(LOGGING_PATH, 'w')\n",
    "# else:\n",
    "#     sys.stdout = sys.__stdout__\n",
    "#     pass\n",
    "\n",
    "#Read data: list of tweets & list of golden lables:\n",
    "opt_tweets, opt_gold_labels = read_OPT_data(DATA_PATH)\n",
    "#Define tokenizer:\n",
    "custom_tokenizer    = CustomTokenizer()#.fit_on_texts(tweets)\n",
    "\n",
    "if PRE_TRAINING_ON_TSA:\n",
    "    sent_tweets, sent_gold_labels = read_OPT_data(data_path=SENTIMENT_PATH\\\n",
    "                                       , text_column=SENTIMENT_TEXT\\\n",
    "                                       , label_column=SENTIMENT_LABEL)\n",
    "    custom_tokenizer    = custom_tokenizer.fit_on_texts(opt_tweets\\\n",
    "                                                        + sent_tweets)\n",
    "    #Tokenize data using the tokenizer:\n",
    "    sent_vectorized_tweets, sent_gold_labels = vectorize_data(\\\n",
    "                                                   sent_tweets\\\n",
    "                                                 , sent_gold_labels\\\n",
    "                                                 , custom_tokenizer)\n",
    "else:\n",
    "    custom_tokenizer    = custom_tokenizer.fit_on_texts(opt_tweets)\n",
    "    #Tokenize data using the tokenizer:\n",
    "    \n",
    "opt_vectorized_tweets, opt_gold_labels = vectorize_data(opt_tweets\\\n",
    "                                             , opt_gold_labels\\\n",
    "                                             , custom_tokenizer)\n",
    "\n",
    "#If we ignore tweets with annotation in (-1, 1):\n",
    "if SETTING_1M1:\n",
    "    opt_vectorized_tweets, opt_gold_labels = remove_vague_tweets(\\\n",
    "                                                            opt_vectorized_tweets\\\n",
    "                                                          , opt_gold_labels) \n",
    "#Binarize gold_labels:\n",
    "opt_gold_labels = binarize_labels(opt_gold_labels\\\n",
    "                                  , max_negative_value=0)\n",
    "\n",
    "\n",
    "if PRE_TRAINING_ON_TSA:\n",
    "    x_train, y_train = sent_vectorized_tweets, sent_gold_labels\n",
    "    x_dev, y_dev     = opt_vectorized_tweets, opt_gold_labels\n",
    "    x_test, y_test   = opt_vectorized_tweets, opt_gold_labels\n",
    "    \n",
    "else:\n",
    "    #Train/Dev/Test split:    \n",
    "    x_train, y_train, x_dev, y_dev, x_test, y_test = \\\n",
    "        train_dev_test_split(opt_vectorized_tweets\\\n",
    "                             , opt_gold_labels)\n",
    "\n",
    "#Load pretrained Embeddings:\n",
    "embedder = Embedder(EMBEDDINGS_PATH)\n",
    "embedding_layer = embedder.build_embedding_layers(custom_tokenizer,\\\n",
    "                                                 trainable=True)\n",
    "\n",
    "#model architecture:\n",
    "model = GRUstack_model(embedding_layer)\n",
    "\n",
    "\n",
    "#Train model:\n",
    "# training_history, model = train_model(model=model\\\n",
    "#                                       , x_train = x_train\\\n",
    "#                                       , y_train = y_train\\\n",
    "#                                       , x_dev   = x_dev\\\n",
    "#                                       , y_dev   = y_dev\\\n",
    "#                                       , epochs      = NUM_EPOCHS\\\n",
    "#                                       , batch_size  = BATCH_SIZE\\\n",
    "#                                       , models_path = MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3079 samples, validate on 384 samples\n",
      "Epoch 1/20\n",
      "3079/3079 [==============================] - 3s 977us/step - loss: 0.4324 - accuracy: 0.7928 - val_loss: 0.3892 - val_accuracy: 0.8333\n",
      "Epoch 2/20\n",
      "3079/3079 [==============================] - 1s 389us/step - loss: 0.1948 - accuracy: 0.9247 - val_loss: 0.5625 - val_accuracy: 0.8411\n",
      "Epoch 3/20\n",
      "3079/3079 [==============================] - 1s 377us/step - loss: 0.1079 - accuracy: 0.9627 - val_loss: 0.3882 - val_accuracy: 0.8724\n",
      "Epoch 4/20\n",
      "3079/3079 [==============================] - 1s 392us/step - loss: 0.0422 - accuracy: 0.9864 - val_loss: 0.4782 - val_accuracy: 0.8932\n",
      "Epoch 5/20\n",
      "3079/3079 [==============================] - 1s 384us/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.6188 - val_accuracy: 0.8542\n",
      "Epoch 6/20\n",
      "3079/3079 [==============================] - 1s 411us/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.7787 - val_accuracy: 0.8594\n",
      "Epoch 7/20\n",
      "3079/3079 [==============================] - 1s 411us/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.9183 - val_accuracy: 0.8438\n",
      "Epoch 8/20\n",
      "3079/3079 [==============================] - 1s 411us/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.7901 - val_accuracy: 0.8776\n",
      "Epoch 9/20\n",
      "3079/3079 [==============================] - 1s 396us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.8637 - val_accuracy: 0.8646\n",
      "Epoch 10/20\n",
      "3079/3079 [==============================] - 1s 423us/step - loss: 4.8611e-04 - accuracy: 1.0000 - val_loss: 0.9222 - val_accuracy: 0.8672\n",
      "Epoch 11/20\n",
      "3079/3079 [==============================] - 1s 400us/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.9722 - val_accuracy: 0.8672\n",
      "Epoch 12/20\n",
      "3079/3079 [==============================] - 1s 426us/step - loss: 4.0582e-04 - accuracy: 1.0000 - val_loss: 0.9200 - val_accuracy: 0.8802\n",
      "Epoch 13/20\n",
      "3079/3079 [==============================] - 1s 416us/step - loss: 1.3545e-04 - accuracy: 1.0000 - val_loss: 0.9529 - val_accuracy: 0.8750\n",
      "Epoch 14/20\n",
      "3079/3079 [==============================] - 1s 396us/step - loss: 6.3841e-05 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "3079/3079 [==============================] - 1s 396us/step - loss: 3.8018e-05 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "3079/3079 [==============================] - 1s 400us/step - loss: 2.2141e-05 - accuracy: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.8776\n",
      "Epoch 17/20\n",
      "3079/3079 [==============================] - 1s 421us/step - loss: 2.0266e-05 - accuracy: 1.0000 - val_loss: 1.0224 - val_accuracy: 0.8776\n",
      "Epoch 18/20\n",
      "3079/3079 [==============================] - 1s 386us/step - loss: 1.7545e-05 - accuracy: 1.0000 - val_loss: 1.0306 - val_accuracy: 0.8776\n",
      "Epoch 19/20\n",
      "3079/3079 [==============================] - 1s 404us/step - loss: 1.5556e-05 - accuracy: 1.0000 - val_loss: 1.0391 - val_accuracy: 0.8776\n",
      "Epoch 20/20\n",
      "3079/3079 [==============================] - 1s 411us/step - loss: 1.8210e-05 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.8776\n",
      "Training history saved in ./histories/history_182903_20200314.csv.\n",
      "Trained model saved in ./models/trained_model_182903_20200314.h5.\n"
     ]
    }
   ],
   "source": [
    "training_history, model = train_model(model=model\\\n",
    "                                      , x_train = x_train\\\n",
    "                                      , y_train = y_train\\\n",
    "                                      , x_dev   = x_dev\\\n",
    "                                      , y_dev   = y_dev\\\n",
    "                                      , epochs      = NUM_EPOCHS\\\n",
    "                                      , batch_size  = BATCH_SIZE\\\n",
    "                                      , models_path = MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "validation_errors = training_history.history[\"val_accuracy\"]\n",
    "training_errors   = training_history.history[\"accuracy\"]\n",
    "\n",
    "plt.title(\"Accuracy improvement over training epochs\")\n",
    "plt.plot(training_errors, label=\"Training Acc\")\n",
    "plt.plot(validation_errors, label = \"Validation Acc\" )\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.grid()\n",
    "plt.ylim(0.4, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./histories/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HISTORY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'102847_20200314'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strftime(\"%H%M%S_%Y%m%d\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fdbe9093fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history.model.pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(training_history.history).to_csv(HISTORY_PATH \\\n",
    "        + \"training_history_%s\"\\\n",
    "        %(strftime(\"%H%M%S_%Y%m%d\", gmtime())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-453d0f9c60b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHISTORY_PATH\u001b[0m         \u001b[0;34m+\u001b[0m \u001b[0;34m\"training_history_%s\"\u001b[0m        \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%H%M%S_%Y%m%d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_history\u001b[0m                \u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "with open(HISTORY_PATH \\\n",
    "        + \"training_history_%s\"\\\n",
    "        %(strftime(\"%H%M%S_%Y%m%d\", gmtime())), \"wb\")\\\n",
    "as f:\n",
    "    pickle.dump(obj=training_history, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbeba60dd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'102354_20200314'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "strftime(\"%H%M%S_%Y%m%d\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.5821441728746396, 0.5494509581900345, 0.5276355892619295, 0.5194235832656084, 0.5141240493999109, 0.5379772003555553, 0.5696049698864121, 0.5751632916400711, 0.6421923654944383, 0.7236489731783529], 'val_acc': [0.680053556061174, 0.7014725620009334, 0.7282463263475911, 0.736278439541578, 0.7550200830342141, 0.7630522004571785, 0.7630522081172131, 0.7657295911506796, 0.7282463186875564, 0.7402945022027655], 'loss': [0.6418126856597086, 0.5484520900341165, 0.5103917119246306, 0.47617404456123463, 0.44523060863441777, 0.40573940159405103, 0.37078165107099453, 0.3337985585712904, 0.2678994527380914, 0.23231941718428137], 'acc': [0.6273198458507017, 0.7242935966377054, 0.7435211499505489, 0.7689349606092549, 0.7898344754813965, 0.8182578167973543, 0.8393245275713014, 0.8552081590710506, 0.8941648552756987, 0.9048654067039968]}\n"
     ]
    }
   ],
   "source": [
    "print(training_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2db8850a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "validation_errors = training_history.history[\"val_acc\"]\n",
    "training_errors   = training_history.history[\"acc\"]\n",
    "\n",
    "plt.title(\"Accuracy improvement over training epochs\")\n",
    "plt.plot(training_errors, label=\"Training Acc\")\n",
    "plt.plot(validation_errors, label = \"Validation Acc\" )\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.grid()\n",
    "plt.ylim(0.4, ymax = 1.01)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_labels(gold_labels):\n",
    "    return to_categorical(gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_vague_tweets(tweets, gold_labels):\n",
    "    '''\n",
    "        Remove tweets with labels in (-1, 1):\n",
    "    '''\n",
    "    clear_indexes = np.logical_or(gold_labels <= -1\\\n",
    "                                  , gold_labels >= 1)\n",
    "    \n",
    "    return tweets[clear_indexes], gold_labels[clear_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, ...,  True, False,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_or(gold_labels <= -1, gold_labels >= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_test_split(vectorized_tweets, gold_labels\\\n",
    "                         , DEV_SPLIT  = .1\\\n",
    "                         , TEST_SPLIT = .1\\\n",
    "                         , R_SEED     = 7):\n",
    "    \n",
    "    #Shuffle indicies:\n",
    "    data_dim = vectorized_tweets.shape[0] \n",
    "    indices  = np.arange(data_dim)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    #Shuffle data accordingly:\n",
    "    vectorized_tweets = vectorized_tweets[indices]\n",
    "    gold_labels       = gold_labels[indices]\n",
    "    \n",
    "    #Compute number of Dev & Test samples:\n",
    "    num_dev_samples  = int(DEV_SPLIT  * data_dim)\n",
    "    num_test_samples = int(TEST_SPLIT * data_dim)\n",
    "    \n",
    "    #Split data according to the above proportions:\n",
    "    x_train = vectorized_tweets[:-(num_dev_samples+num_test_samples)] \n",
    "    y_train = gold_labels[:-(num_dev_samples+num_test_samples)]\n",
    "\n",
    "    x_dev   = vectorized_tweets[-(num_dev_samples+num_test_samples)\\\n",
    "                                :-num_test_samples] \n",
    "    y_dev   = gold_labels[-(num_dev_samples+num_test_samples)\\\n",
    "                                :-num_test_samples] \n",
    "\n",
    "    x_test  = vectorized_tweets[-num_test_samples:] \n",
    "    y_test  = gold_labels[-num_test_samples:]\n",
    "    \n",
    "    return x_train, y_train, x_dev, y_dev, x_test, y_test\n",
    "\n",
    "\n",
    "x_train, y_train, x_dev, y_dev, x_test, y_test = train_dev_test_split(\\\n",
    "                                                vectorized_tweets\\\n",
    "                                                , gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5981, 35), (5981,), (747, 35), (747,), (747, 35), (747,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_dev.shape, y_dev.shape\\\n",
    ", x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a dev set\n",
    "\n",
    "DEV_SPLIT = .1\n",
    "\n",
    "indices = np.arange(data_sequences.shape[0])\n",
    "np.random.seed(7)#Irina 1, Stef 7\n",
    "np.random.shuffle(indices)\n",
    "data_sequences_shuff     = data_sequences[indices]\n",
    "gold_labels_binary = np.where(gold_labels<=0, 0, 1)\n",
    "gold_labels_binary = gold_labels_binary[indices]\n",
    "gold_labels_binary = to_categorical(np.asarray(gold_labels_binary))\n",
    "\n",
    "\n",
    "num_dev_samples = int(DEV_SPLIT \\\n",
    "                             * data_sequences_shuff.shape[0])\n",
    "\n",
    "x_train_seq = data_sequences_shuff[:2*-num_dev_samples] \n",
    "y_train     = gold_labels_binary[:2*-num_dev_samples]\n",
    "\n",
    "x_dev_seq   = data_sequences_shuff[2*-num_dev_samples:-num_dev_samples] \n",
    "y_dev       = gold_labels_binary[2*-num_dev_samples:-num_dev_samples]\n",
    "\n",
    "x_test_seq  = data_sequences_shuff[-num_dev_samples:] \n",
    "y_test      = gold_labels_binary[-num_dev_samples:]\n",
    "\n",
    "print(y_train.shape, y_dev.shape, y_test.shape\\\n",
    "      , y_train.shape[0] + y_dev.shape[0] + y_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFold_split(data_sequences, data_hot_sequences, gold_labels,\\\n",
    "               num_folds=3, random_seed=7):\n",
    "    '''\n",
    "        KFold split for our data format:\n",
    "\n",
    "        input:  data_sequences, data_hot_sequences, gold_labels,\n",
    "                num_folds=3\n",
    "        output: tuple list of\n",
    "                (data_sequences, data_hot_sequences, gold_labels)\n",
    "                of length num_folds\n",
    "\n",
    "    '''\n",
    "    #Manual K folds split in 2 steps (shuffle & split):\n",
    "\n",
    "    # from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "    #1. Shuffle the data:\n",
    "    indices = np.arange(data_sequences.shape[0])\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "    data_sequences     = data_sequences[indices]\n",
    "    data_hot_sequences = data_hot_sequences[indices]\n",
    "    gold_labels        = gold_labels[indices]\n",
    "\n",
    "    #2. Split the data:\n",
    "\n",
    "    #compute indexes for fair splits:\n",
    "    fold_dim  = len(indices) // num_folds + 1\n",
    "    folds_indexes = [(i*fold_dim, (i+1)*fold_dim) \\\n",
    "                     for i in range(num_folds)]\n",
    "\n",
    "    #create the splits according to the indexes:\n",
    "    folds = []\n",
    "    for l, r in folds_indexes:\n",
    "        fold = (data_sequences[l:r], data_hot_sequences[l:r]\\\n",
    "                , gold_labels[l:r])\n",
    "        folds.append(fold)\n",
    "\n",
    "    return folds\n",
    "\n",
    "#Call that can be tested:\n",
    "#KFold_split(*vectorize_data(*read_WCE_data(data_path)))[-2][1][2][-3:]\n",
    "#array([   0, 2721,  433], dtype=int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np \n",
    "import pandas            as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7475 tweets in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Username</th>\n",
       "      <th>AverageAnnotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did i just hear clive anderson say peter cooke...</td>\n",
       "      <td>The_Bounder</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anyways that's my evening thesis. write don't ...</td>\n",
       "      <td>Satori_Paris</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when teachers ask why im late. (vine by @jimmy...</td>\n",
       "      <td>Sizzurp_713</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@obafemiwilliams @darren_linzoid @kenboy4 hurr...</td>\n",
       "      <td>NathElCuchillo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@karsten_frank @wjelger on the other hand. the...</td>\n",
       "      <td>Aethien</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet        Username  \\\n",
       "0  did i just hear clive anderson say peter cooke...     The_Bounder   \n",
       "1  anyways that's my evening thesis. write don't ...    Satori_Paris   \n",
       "2  when teachers ask why im late. (vine by @jimmy...     Sizzurp_713   \n",
       "3  @obafemiwilliams @darren_linzoid @kenboy4 hurr...  NathElCuchillo   \n",
       "4  @karsten_frank @wjelger on the other hand. the...         Aethien   \n",
       "\n",
       "   AverageAnnotation  \n",
       "0                1.0  \n",
       "1                1.0  \n",
       "2               -0.8  \n",
       "3                0.0  \n",
       "4                1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SST:\n",
    "# pd.read_csv(\"data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\"\\\n",
    "#            , error_bad_lines=False).head()\n",
    "#TSA:\n",
    "# pd.read_table(\"data/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSentences.txt\"\\\n",
    "#              ).head()\n",
    "\n",
    "#OPT:\n",
    "tweets_df = pd.read_csv(\"data/optimism-twitter-data/tweets_annotation.csv\")\n",
    "\n",
    "print(\"There are %d tweets in the dataset.\" %tweets_df.shape[0])\n",
    "tweets_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset:\n",
      "Found 7475 texts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path   = \"data/optimism-twitter-data/\"\n",
    "train_file  = \"tweets_annotation.csv\"\n",
    "# MAX_SEQUENCE_LENGTH     = 0\n",
    "# MAX_HOT_SEQUENCE_LENGTH = 0\n",
    "\n",
    "def read_WCE_data(data_path, train=True):\n",
    "    \"\"\"\n",
    "        Read data format given at the Word Complexity Estimation\n",
    "        task, Deep Learning course, FMI UniBuc 2020.\n",
    "        \n",
    "        input:  folder containing given data file;\n",
    "        output: texts, hot_words, gold_labels\n",
    "    \"\"\"\n",
    "    original_df = pd.read_csv(data_path + train_file)\n",
    "    \n",
    "    print('Processing text dataset:')\n",
    "\n",
    "    texts         = list(original_df['Tweet']) # list of text samples\n",
    "    print('Found %s texts.\\n' % len(texts))\n",
    "    \n",
    "    if train:\n",
    "        gold_labels   = list(original_df['AverageAnnotation']) #list of gold labels\n",
    "        return texts, gold_labels#, original_df\n",
    "    \n",
    "    return texts\n",
    "\n",
    "tweets, gold_labels = read_WCE_data(data_path)#[2][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Cleanup process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/envs/cwi/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text     import Tokenizer\n",
    "from keras.utils                  import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest tweet has 34 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"The longest tweet has %d words.\" \\\n",
    "      %max([len(t.split(\" \")) for t in tweets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/envs/nlp/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text     import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "class CustomTokenizer:\n",
    "    def __init__(self, MAX_SEQUENCE_LENGTH=40):\n",
    "        self.MAX_SEQUENCE_LENGTH     = MAX_SEQUENCE_LENGTH\n",
    "        self.tokenizer = Tokenizer()\n",
    "        print(\"Tokenizer created!\")\n",
    "#         print(\"TTT %s\" %ana)\n",
    "        \n",
    "    def fit_on_texts(self, texts):\n",
    "#         self.MAX_SEQUENCE_LENGTH = 1 + max(map(lambda x: \\\n",
    "#                                                len(x.split(\" \"))\\\n",
    "#                                            , texts))\n",
    "    \n",
    "        self.tokenizer.fit_on_texts(texts)\n",
    "        \n",
    "    def texts_to_sequences(self, texts):\n",
    "        return self.tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    def get_word_index(self):\n",
    "        return self.tokenizer.word_index\n",
    "    \n",
    "    def pad_sequences(self, sequences, maxlen):\n",
    "        return pad_sequences(sequences, maxlen=maxlen)\n",
    "    \n",
    "    \n",
    "custom_tokenizer = CustomTokenizer()#2, 3)\n",
    "custom_tokenizer.fit_on_texts(tweets)\n",
    "custom_tokenizer.get_word_index()[\"are\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing given data...\n",
      "The longest phrase has 34 words.\n",
      "Shape of data_sequences tensor: (7475, 35)\n",
      "Shape of label tensor: (7475,).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def vectorize_data(texts, gold_labels\\\n",
    "                   , custom_tokenizer\\\n",
    "                  , MAX_SEQUENCE_LENGTH=None):\n",
    "    \"\"\"\n",
    "        Given a list of texts, a list of subsequences and \n",
    "        a list of labels for each of the texts, vectorie them.\n",
    "        \n",
    "        input:  texts, hot_words, gold_labels\n",
    "        output: data_sequences, data_hot_sequences, gold_labels\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Vectorizing given data...\")\n",
    "    if not(MAX_SEQUENCE_LENGTH):\n",
    "        MAX_SEQUENCE_LENGTH = max(map(lambda x: len(x.split(\" \")), texts)) + 1\n",
    "    custom_tokenizer.MAX_SEQUENCE_LENGTH = MAX_SEQUENCE_LENGTH\n",
    "    \n",
    "    print(\"The longest phrase has %d words.\" \\\n",
    "          %(MAX_SEQUENCE_LENGTH - 1))\n",
    "\n",
    "    # finally, vectorize the text samples into a 2D integer tensor\n",
    "\n",
    "    sequences      = custom_tokenizer.texts_to_sequences(texts)\n",
    "    data_sequences = custom_tokenizer.pad_sequences(sequences\\\n",
    "                                       , maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    gold_labels = (np.asarray(gold_labels))\n",
    "    print('Shape of data_sequences tensor:', data_sequences.shape)\n",
    "    print('Shape of label tensor: %s.\\n' %str(gold_labels.shape))\n",
    "                                  \n",
    "    return data_sequences, gold_labels\n",
    "                                  \n",
    "# vectorize_data(*read_WCE_data(data_path))[-1][:6]\n",
    "                                                        \n",
    "data_sequences, gold_labels = vectorize_data(tweets, gold_labels\\\n",
    "                   , custom_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5981, 2) (747, 2) (747, 2) 7475\n"
     ]
    }
   ],
   "source": [
    "# split the data into a training set and a dev set\n",
    "\n",
    "DEV_SPLIT = .1\n",
    "\n",
    "indices = np.arange(data_sequences.shape[0])\n",
    "np.random.seed(7)#Irina 1, Stef 7\n",
    "np.random.shuffle(indices)\n",
    "data_sequences_shuff     = data_sequences[indices]\n",
    "gold_labels_binary = np.where(gold_labels<=0, 0, 1)\n",
    "gold_labels_binary = gold_labels_binary[indices]\n",
    "gold_labels_binary = to_categorical(np.asarray(gold_labels_binary))\n",
    "\n",
    "\n",
    "num_dev_samples = int(DEV_SPLIT \\\n",
    "                             * data_sequences_shuff.shape[0])\n",
    "\n",
    "x_train_seq = data_sequences_shuff[:2*-num_dev_samples] \n",
    "y_train     = gold_labels_binary[:2*-num_dev_samples]\n",
    "\n",
    "x_dev_seq   = data_sequences_shuff[2*-num_dev_samples:-num_dev_samples] \n",
    "y_dev       = gold_labels_binary[2*-num_dev_samples:-num_dev_samples]\n",
    "\n",
    "x_test_seq  = data_sequences_shuff[-num_dev_samples:] \n",
    "y_test      = gold_labels_binary[-num_dev_samples:]\n",
    "\n",
    "print(y_train.shape, y_dev.shape, y_test.shape\\\n",
    "      , y_train.shape[0] + y_dev.shape[0] + y_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Using One-Hot-Encode embedding.\n",
      "Indexing word vectors.\n",
      "Found 1193514 word vectors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16168"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self, path_to_emb, emb_size=25,\\\n",
    "                ):\n",
    "        print('Indexing word vectors.')\n",
    "        \n",
    "        self.path_to_emb = path_to_emb\n",
    "        self.embeddings_size  = emb_size\n",
    "        \n",
    "        if self.path_to_emb == False: \n",
    "            print(\"Using One-Hot-Encode embedding.\")\n",
    "            return\n",
    "        \n",
    "        self.embeddings_index = {}\n",
    "#         \"glove.twitter.27B\"\n",
    "#         'glove.6B.%dd.txt'\n",
    "        with open(os.path.join(path_to_emb\\\n",
    "                               , \"glove.twitter.27B.%dd.txt\") \\\n",
    "                  %self.embeddings_size) as f:\n",
    "            for line in f:\n",
    "                word, coefs = line.split(maxsplit=1)\n",
    "                coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "                self.embeddings_index[word] = coefs\n",
    "\n",
    "        print('Found %s word vectors.' % len(self.embeddings_index))\n",
    "\n",
    "    \n",
    "    \n",
    "embedder = Embedder(False)#'./glove.6B/')\n",
    "# embedder = Embedder(path_to_emb='./embeddings/glove.6B/',\\\n",
    "#                    emb_size=300)\n",
    "embedder = Embedder(path_to_emb='./embeddings/glove.twitter.27B/',\\\n",
    "                   emb_size=200)\n",
    "len(custom_tokenizer.get_word_index())\n",
    "\n",
    "'./embeddings/glove.twitter.27B/glove.twitter.27B.%dd.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer prepared.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "from keras.layers import Embedding\n",
    "\n",
    "def build_embedding_layers(embedder, custom_tokenizer\\\n",
    "                          , trainable=True):\n",
    "    '''\n",
    "        We neeed the word_index, \n",
    "    '''\n",
    "    EMBEDDING_DIM = embedder.embeddings_size\n",
    "    word_index    = custom_tokenizer.get_word_index()\n",
    "    num_words     = len(word_index) + 1\n",
    "    # prepare embedding matrix\n",
    "    embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "    MAX_SEQUENCE_LENGTH     = custom_tokenizer.MAX_SEQUENCE_LENGTH\n",
    "    \n",
    "    #If No pretrained embeddings were provided: \n",
    "    if embedder.path_to_emb == False:\n",
    "        embedding_layer = Embedding(num_words, EMBEDDING_DIM,\n",
    "                 input_length=MAX_SEQUENCE_LENGTH, trainable=trainable)\n",
    "        return embedding_layer\n",
    "        \n",
    "    #If GloVe embeddings were provided:\n",
    "    for word, i in word_index.items():\n",
    "        if i >= num_words:\n",
    "            continue\n",
    "        embedding_vector = embedder.embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    # load pre-trained word embeddings into an Embedding layer\n",
    "    # note that we set trainable = False so as to keep the embeddings fixed\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                embeddings_initializer=Constant(embedding_matrix),\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=trainable)\n",
    "    \n",
    "    \n",
    "    print('Embedding layer prepared.')  \n",
    "    \n",
    "    return embedding_layer\n",
    "\n",
    "embedding_layer = build_embedding_layers(embedder, custom_tokenizer,\\\n",
    "                                        trainable=True)\n",
    "embedding_layer.input_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv1D, MaxPooling1D, LSTM, GRU#, GlobalMaxPooling1D\n",
    "from keras.layers import Input, Concatenate, Flatten, Dropout#, Embedding\n",
    "from keras.models import Model\n",
    "# from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Convs & Recurrences.\n",
      "2. Dense layers.\n"
     ]
    }
   ],
   "source": [
    "def build_model(embedding_layer):\n",
    "    print('1. Convs & Recurrences.')\n",
    "\n",
    "    # train a 1D convnet with global maxpooling\n",
    "    sequence_input = Input(shape=(embedding_layer.input_length, )\\\n",
    "                           , dtype='int32')\n",
    "\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "#     x = Conv1D(256, 3, activation='relu')(embedded_sequences)\n",
    "#     x = MaxPooling1D(3)(x)\n",
    "#     x = Conv1D(128, 5, activation='relu')(x)\n",
    "#     x = MaxPooling1D(5)(x)\n",
    "    \n",
    "    x = GRU(256, return_sequences=True)(embedded_sequences)\n",
    "    x = GRU(128)(x)\n",
    "    \n",
    "#     x = Conv1D(64, 3, activation='relu')(x)\n",
    "#     x = MaxPooling1D(3)(x)\n",
    "    \n",
    "#     x = LSTM(256)(x)\n",
    "\n",
    "    tweet_branch = x\n",
    "    dense_branch = tweet_branch\n",
    "\n",
    "    \n",
    "    print('2. Dense layers.')\n",
    "\n",
    "#     dense_branch = Concatenate()([hot_branch, phrase_branch])#.shape\n",
    "#     dense_branch = Flatten()(tweet_branch)\n",
    "    \n",
    "#     dense_branch = Dense(512, activation='relu')(dense_branch)\n",
    "#     dense_branch = Dropout(rate = .5)(dense_branch)\n",
    "\n",
    "    dense_branch = Dense(300, activation='relu')(dense_branch)\n",
    "    dense_branch = Dropout(rate = .2)(dense_branch)\n",
    "\n",
    "    dense_branch = Dense(200, activation='relu')(dense_branch)\n",
    "    dense_branch = Dense(100, activation='relu')(dense_branch)\n",
    "    dense_branch = Dropout(rate = .1)(dense_branch)\n",
    "\n",
    "    preds = Dense(2, activation='softmax')(dense_branch)\n",
    "    \n",
    "    model = Model([sequence_input], preds)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 35, 200)           3233800   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 35, 256)           350976    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               147840    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               38700     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 3,851,818\n",
      "Trainable params: 3,851,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy as copy\n",
    "def train_model(model, folds, epochs=100, batch_size=2048):\n",
    "    \n",
    "    model.save('./models/untrained_model.h5')\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', #\"mean_squared_logarithmic_error\", #'binary_crossentropy',\n",
    "              optimizer='adam',#'adam',#'rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    if len(folds) == 1:\n",
    "        print(\"Training final model:\")\n",
    "        training_history = model.fit(#[x_train_seq, x_train_hot], y_train,\n",
    "                            [folds[0][0]],\\\n",
    "                            folds[0][1],\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=([x_dev_seq], y_dev))\n",
    "            #validation_data=([x_val_seq, x_val_hot], y_val))\n",
    "\n",
    "#         histories.append(training_history)\n",
    "#         models.append(copy(model))\n",
    "        model.save(\"./models/full_model.h5\")\n",
    "        return training_history, model\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(\"%d-Fold Cross Validation:\" %len(folds))\n",
    "        \n",
    "#     histories = []\n",
    "#     models    = []\n",
    "    \n",
    "#     for i, f in enumerate(folds):\n",
    "        \n",
    "#         print(\"\\nFold %d/%d.\" %(i+1, len(folds)))\n",
    "#         x_train_seq = np.vstack(list(map(lambda f: f[0]\\\n",
    "#                                          , folds[:i] + folds[i+1:])))\n",
    "#         x_train_hot = np.vstack(list(map(lambda f: f[1]\\\n",
    "#                                          , folds[:i] + folds[i+1:])))\n",
    "#         y_train     = np.hstack(list(map(lambda f: f[2]\\\n",
    "#                                          , folds[:i] + folds[i+1:]))) \n",
    "        \n",
    "#         x_val_seq, x_val_hot, y_val = f\n",
    "        \n",
    "\n",
    "#         training_history = model.fit(#[x_train_seq, x_train_hot], y_train,\n",
    "#                     [x_train_seq, x_train_hot],\\\n",
    "#                     y_train,\n",
    "#                     batch_size=batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=([x_val_seq, x_val_hot], y_val))\n",
    "\n",
    "#         histories.append(training_history)\n",
    "#         models.append(copy(model))\n",
    "#         model.save(\"./models/model_fold_%d.h5\" %i)\n",
    "#         model.load_weights(\"models/untrained_model.h5\")\n",
    "        \n",
    "#     return histories, models\n",
    "\n",
    "\n",
    "# training_history, model = train_model(model, [[x_train_seq, y_train]]\\\n",
    "#                                , epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fe6053388e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvalidation_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtraining_errors\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtraining_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "validation_errors = training_history.history[\"val_acc\"]\n",
    "training_errors   = training_history.history[\"acc\"]\n",
    "\n",
    "plt.title(\"Accuracy improvement over training epochs\")\n",
    "plt.plot(training_errors, label=\"Training Acc\")\n",
    "plt.plot(validation_errors, label = \"Validation Acc\" )\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.grid()\n",
    "plt.ylim(0.4, ymax = 1.01)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ed2ba6748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "validation_errors = training_history.history[\"val_acc\"]\n",
    "training_errors   = training_history.history[\"acc\"]\n",
    "\n",
    "plt.title(\"Accuracy improvement over training epochs\")\n",
    "plt.plot(training_errors, label=\"Training Acc\")\n",
    "plt.plot(validation_errors, label = \"Validation Acc\" )\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.grid()\n",
    "plt.ylim(0.4, ymax = 1.01)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment vs Optimism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1024087</th>\n",
       "      <td>1024103</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@maccast The 5.01 ep isn't on iTunes mobile yet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76847</th>\n",
       "      <td>76860</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@aplusk lol, Awesomely sweet dude!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417690</th>\n",
       "      <td>1417706</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>had a rough day today. My violin teacher actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442309</th>\n",
       "      <td>442322</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@psalmist_one Okay I seriously didn't realise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324250</th>\n",
       "      <td>1324266</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>Why does Space Mountain always shut down when ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ItemID  Sentiment SentimentSource  \\\n",
       "1024087  1024103          0    Sentiment140   \n",
       "76847      76860          1    Sentiment140   \n",
       "1417690  1417706          1    Sentiment140   \n",
       "442309    442322          0    Sentiment140   \n",
       "1324250  1324266          0    Sentiment140   \n",
       "\n",
       "                                             SentimentText  \n",
       "1024087  @maccast The 5.01 ep isn't on iTunes mobile yet.   \n",
       "76847                 @aplusk lol, Awesomely sweet dude!    \n",
       "1417690  had a rough day today. My violin teacher actua...  \n",
       "442309   @psalmist_one Okay I seriously didn't realise ...  \n",
       "1324250  Why does Space Mountain always shut down when ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)#Irina 1, Stef 7\n",
    "\n",
    "tsa_df = pd.read_csv(\"data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\"\\\n",
    "           , error_bad_lines=False)\n",
    "\n",
    "\n",
    "tsa_df = tsa_df.sample(frac=.25)\n",
    "tsa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TSA text dataset:\n",
      "Found 394,653 texts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Processing TSA text dataset:')\n",
    "\n",
    "tsa_tweets         = list(tsa_df['SentimentText']) # list of text samples\n",
    "print('Found %s texts.\\n'  %(f'{len(tsa_tweets):,}'))\n",
    "\n",
    "tsa_gold_labels   = list(tsa_df['Sentiment']) #list of gold labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer created!\n",
      "Vectorizing given data...\n",
      "The longest phrase has 34 words.\n",
      "Shape of data_sequences tensor: (394653, 35)\n",
      "Shape of label tensor: (394653,).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_tsa_tokenizer = CustomTokenizer()\n",
    "custom_tsa_tokenizer.fit_on_texts(tsa_tweets)\n",
    "custom_tsa_tokenizer.get_word_index()[\"are\"]\n",
    "\n",
    "tsa_data_sequences, tsa_gold_labels = vectorize_data(tsa_tweets\\\n",
    "                                             , tsa_gold_labels\\\n",
    "                   , custom_tsa_tokenizer\\\n",
    "                    , MAX_SEQUENCE_LENGTH=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(394653, 2) (7475, 2) (7475, 2) 409603\n"
     ]
    }
   ],
   "source": [
    "# indices = np.arange(tsa_data_sequences.shape[0])\n",
    "np.random.seed(7)#Irina 1, Stef 7\n",
    "# np.random.shuffle(indices)\n",
    "\n",
    "x_train_seq = tsa_data_sequences\n",
    "y_train     = to_categorical(np.asarray(tsa_gold_labels))#np.where(tsa_gold_labels<=0, 0, 1)\n",
    "\n",
    "x_dev_seq   = data_sequences_shuff#[2*-num_dev_samples:-num_dev_samples] \n",
    "y_dev       = gold_labels_binary#[2*-num_dev_samples:-num_dev_samples]\n",
    "\n",
    "x_test_seq  = data_sequences_shuff#[-num_dev_samples:] \n",
    "y_test      = gold_labels_binary#[-num_dev_samples:]\n",
    "\n",
    "\n",
    "print(y_train.shape, y_dev.shape, y_test.shape\\\n",
    "      , y_train.shape[0] + y_dev.shape[0] + y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Using One-Hot-Encode embedding.\n",
      "Indexing word vectors.\n",
      "Found 1193514 word vectors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16168"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder = Embedder(False)#'./glove.6B/')\n",
    "# embedder = Embedder(path_to_emb='./embeddings/glove.6B/',\\\n",
    "#                    emb_size=300)\n",
    "embedder = Embedder(path_to_emb='./embeddings/glove.twitter.27B/',\\\n",
    "                   emb_size=200)\n",
    "len(custom_tokenizer.get_word_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer prepared.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tsa_embedding_layer = build_embedding_layers(embedder, custom_tsa_tokenizer,\\\n",
    "                                        trainable=True)\n",
    "tsa_embedding_layer.input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Convs & Recurrences.\n",
      "2. Dense layers.\n"
     ]
    }
   ],
   "source": [
    "tsa_model = build_model(tsa_embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 35, 200)           52971800  \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 35, 256)           350976    \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 128)               147840    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               38700     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 53,589,818\n",
      "Trainable params: 53,589,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tsa_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model:\n",
      "Train on 394653 samples, validate on 7475 samples\n",
      "Epoch 1/30\n",
      " 34816/394653 [=>............................] - ETA: 17:42 - loss: 0.6342 - acc: 0.6324"
     ]
    }
   ],
   "source": [
    "\n",
    "training_tsa_history, tsa_model = train_model(tsa_model\\\n",
    "                                              , [[x_train_seq, y_train]]\\\n",
    "                               , epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa61c295e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "validation_errors = training_history.history[\"val_acc\"]\n",
    "training_errors   = training_history.history[\"acc\"]\n",
    "\n",
    "plt.title(\"Accuracy improvement over training epochs\")\n",
    "plt.plot(training_errors, label=\"Training Acc\")\n",
    "plt.plot(validation_errors, label = \"Validation Acc\" )\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.grid()\n",
    "plt.ylim(0.4, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6084268714807086, 3765, -0.34307064964981704, 2216, 0.6294933957532185)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_train>=0, y_train, 0).mean(), \\\n",
    "np.where(y_train>=0, 1, 0).sum(),   \\\n",
    "np.where(y_train<0, y_train, 0).mean(),  \\\n",
    "np.where(y_train<0, 1, 0).sum(), \\\n",
    "np.where(y_train>=0, 1, 0).sum() / y_train.shape[0]\n",
    "# np.where(y_train>=0, 1, 0).sum() / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00],\n",
       "       [1.26168627e-04],\n",
       "       [6.14342561e-14],\n",
       "       [2.66689040e-06],\n",
       "       [3.72153908e-01],\n",
       "       [9.96450424e-01],\n",
       "       [9.98922110e-01],\n",
       "       [2.89182931e-01],\n",
       "       [6.35423756e-04],\n",
       "       [2.89182931e-01],\n",
       "       [9.59633484e-11],\n",
       "       [1.00000000e+00],\n",
       "       [7.72400411e-18],\n",
       "       [3.56431782e-16],\n",
       "       [1.30154717e-07],\n",
       "       [2.01904757e-10],\n",
       "       [9.99568880e-01],\n",
       "       [1.29228420e-05],\n",
       "       [1.53103663e-08],\n",
       "       [2.89182931e-01],\n",
       "       [1.69390063e-07],\n",
       "       [8.84888649e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.93355155e-01],\n",
       "       [1.64813559e-31],\n",
       "       [1.00000000e+00],\n",
       "       [9.47249879e-04],\n",
       "       [6.54796930e-03],\n",
       "       [2.89182931e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [9.81449604e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.11881241e-35],\n",
       "       [5.24594099e-04],\n",
       "       [2.29678470e-27],\n",
       "       [4.11586883e-03],\n",
       "       [1.20586023e-01],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.40237476e-04],\n",
       "       [2.89182931e-01],\n",
       "       [1.91873774e-17],\n",
       "       [9.99039829e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [9.99986887e-01],\n",
       "       [3.89713504e-21],\n",
       "       [1.09468021e-06],\n",
       "       [0.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.08266213e-05],\n",
       "       [8.40404968e-11],\n",
       "       [9.99995708e-01],\n",
       "       [9.99792993e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.22303106e-07],\n",
       "       [9.99917626e-01],\n",
       "       [3.18230838e-02],\n",
       "       [5.08023157e-26],\n",
       "       [4.65024475e-35],\n",
       "       [9.85847056e-01],\n",
       "       [1.32687256e-01],\n",
       "       [9.67321157e-01],\n",
       "       [2.89182931e-01],\n",
       "       [5.71658239e-02],\n",
       "       [2.89182931e-01],\n",
       "       [9.89636838e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.82499582e-25],\n",
       "       [9.80538487e-01],\n",
       "       [9.99728978e-01],\n",
       "       [1.69258905e-17],\n",
       "       [9.98421311e-01],\n",
       "       [8.58022511e-01],\n",
       "       [4.29844022e-06],\n",
       "       [4.53741057e-03],\n",
       "       [8.90260348e-12],\n",
       "       [2.89182931e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.89397883e-01],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [5.71497139e-07],\n",
       "       [2.89182931e-01],\n",
       "       [1.12815881e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.97987114e-25],\n",
       "       [2.89182931e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.63179925e-06],\n",
       "       [9.43688772e-09],\n",
       "       [1.93677731e-02],\n",
       "       [0.00000000e+00],\n",
       "       [5.49448020e-13],\n",
       "       [2.89182931e-01],\n",
       "       [2.41543839e-05],\n",
       "       [9.99963403e-01],\n",
       "       [5.32704603e-10],\n",
       "       [2.89182931e-01],\n",
       "       [1.33496267e-03],\n",
       "       [3.10646328e-07],\n",
       "       [3.41100356e-04],\n",
       "       [9.98871386e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.39401598e-25],\n",
       "       [1.00000000e+00],\n",
       "       [1.15809404e-35],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [3.15125957e-19],\n",
       "       [1.87187652e-23],\n",
       "       [5.21836569e-07],\n",
       "       [1.12270269e-28],\n",
       "       [9.99886513e-01],\n",
       "       [9.99994040e-01],\n",
       "       [6.49161637e-02],\n",
       "       [1.00000000e+00],\n",
       "       [5.04900809e-12],\n",
       "       [2.89182931e-01],\n",
       "       [2.77595222e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.65562766e-22],\n",
       "       [2.89182931e-01],\n",
       "       [9.33622702e-37],\n",
       "       [8.60693634e-12],\n",
       "       [9.99925256e-01],\n",
       "       [3.06766527e-18],\n",
       "       [2.89182931e-01],\n",
       "       [8.86161268e-01],\n",
       "       [2.89182931e-01],\n",
       "       [4.97912701e-16],\n",
       "       [2.72820245e-07],\n",
       "       [1.52590621e-06],\n",
       "       [9.99995112e-01],\n",
       "       [2.42206024e-08],\n",
       "       [1.00000000e+00],\n",
       "       [2.57342867e-06],\n",
       "       [9.99790847e-01],\n",
       "       [5.38509395e-13],\n",
       "       [2.45090860e-06],\n",
       "       [2.89182931e-01],\n",
       "       [9.99869227e-01],\n",
       "       [1.03188184e-04],\n",
       "       [2.89182931e-01],\n",
       "       [1.26351791e-08],\n",
       "       [4.66292230e-15],\n",
       "       [7.08222578e-05],\n",
       "       [6.27366461e-08],\n",
       "       [3.61466460e-04],\n",
       "       [4.30649816e-05],\n",
       "       [4.75865715e-18],\n",
       "       [3.80200311e-03],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.99999881e-01],\n",
       "       [4.05127034e-19],\n",
       "       [1.44245001e-14],\n",
       "       [1.00000000e+00],\n",
       "       [6.29442232e-03],\n",
       "       [2.89182931e-01],\n",
       "       [1.32687256e-01],\n",
       "       [6.08432945e-03],\n",
       "       [7.86920680e-07],\n",
       "       [2.10804615e-06],\n",
       "       [1.73825177e-03],\n",
       "       [9.00019944e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.24898122e-05],\n",
       "       [3.95773611e-07],\n",
       "       [2.89182931e-01],\n",
       "       [1.39911572e-11],\n",
       "       [6.77967194e-23],\n",
       "       [8.64788353e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.99872088e-01],\n",
       "       [1.86650698e-16],\n",
       "       [9.99999523e-01],\n",
       "       [2.21052294e-04],\n",
       "       [2.05708464e-04],\n",
       "       [1.51854185e-09],\n",
       "       [2.89182931e-01],\n",
       "       [1.13747700e-19],\n",
       "       [2.15888383e-13],\n",
       "       [5.13151500e-11],\n",
       "       [2.89182931e-01],\n",
       "       [9.57703352e-01],\n",
       "       [7.37336872e-31],\n",
       "       [9.98541474e-01],\n",
       "       [8.23948067e-04],\n",
       "       [3.51180017e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.86059666e-01],\n",
       "       [8.12175632e-01],\n",
       "       [9.99998689e-01],\n",
       "       [6.03007153e-03],\n",
       "       [7.01468050e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.28521532e-01],\n",
       "       [6.31736826e-17],\n",
       "       [2.89182931e-01],\n",
       "       [1.44480600e-19],\n",
       "       [5.80775831e-03],\n",
       "       [1.46615620e-16],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [2.21207365e-01],\n",
       "       [1.22038892e-03],\n",
       "       [9.99996424e-01],\n",
       "       [4.02023949e-24],\n",
       "       [3.42659943e-04],\n",
       "       [5.81009772e-07],\n",
       "       [2.89182931e-01],\n",
       "       [2.18340536e-26],\n",
       "       [2.66193485e-08],\n",
       "       [6.40642655e-04],\n",
       "       [1.32102649e-13],\n",
       "       [2.89182931e-01],\n",
       "       [1.12861333e-17],\n",
       "       [1.18974466e-02],\n",
       "       [9.99960303e-01],\n",
       "       [9.15763199e-01],\n",
       "       [2.88210572e-07],\n",
       "       [1.81968258e-25],\n",
       "       [9.99999642e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.07762048e-06],\n",
       "       [9.98488545e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.13347362e-03],\n",
       "       [9.99937654e-01],\n",
       "       [1.17564620e-03],\n",
       "       [9.94626462e-01],\n",
       "       [1.69869529e-17],\n",
       "       [4.12459224e-02],\n",
       "       [7.32749421e-03],\n",
       "       [9.98120368e-01],\n",
       "       [1.75289447e-29],\n",
       "       [3.59364231e-13],\n",
       "       [6.24436787e-12],\n",
       "       [9.99764979e-01],\n",
       "       [2.89182931e-01],\n",
       "       [4.07989733e-02],\n",
       "       [9.62920904e-01],\n",
       "       [8.99634858e-16],\n",
       "       [9.72710733e-17],\n",
       "       [5.88384665e-08],\n",
       "       [2.89182931e-01],\n",
       "       [1.34050727e-01],\n",
       "       [2.73939252e-01],\n",
       "       [5.21283156e-11],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.85328019e-01],\n",
       "       [3.95237930e-06],\n",
       "       [5.32077916e-04],\n",
       "       [1.41524250e-16],\n",
       "       [1.04986271e-13],\n",
       "       [5.70488989e-01],\n",
       "       [2.80680766e-14],\n",
       "       [4.26088184e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.54933583e-11],\n",
       "       [7.71877679e-14],\n",
       "       [1.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [7.69428479e-11],\n",
       "       [9.99999166e-01],\n",
       "       [1.65805616e-07],\n",
       "       [1.00000000e+00],\n",
       "       [8.80543828e-01],\n",
       "       [2.10616123e-02],\n",
       "       [1.39005967e-13],\n",
       "       [2.89182931e-01],\n",
       "       [9.99999642e-01],\n",
       "       [6.86695039e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.52553229e-25],\n",
       "       [2.70912581e-11],\n",
       "       [4.79309821e-11],\n",
       "       [9.93688147e-15],\n",
       "       [1.54122404e-08],\n",
       "       [9.99983907e-01],\n",
       "       [8.64026919e-02],\n",
       "       [4.89642948e-01],\n",
       "       [9.99998808e-01],\n",
       "       [9.15745139e-01],\n",
       "       [4.84389979e-16],\n",
       "       [4.44531615e-04],\n",
       "       [2.94338664e-12],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.99999762e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.32535113e-06],\n",
       "       [5.52780023e-07],\n",
       "       [2.99987479e-10],\n",
       "       [6.63879216e-01],\n",
       "       [9.98123109e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.66474685e-32],\n",
       "       [2.89182931e-01],\n",
       "       [5.55987120e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.17867027e-08],\n",
       "       [1.42959894e-10],\n",
       "       [9.99994993e-01],\n",
       "       [9.99956727e-01],\n",
       "       [9.97293413e-01],\n",
       "       [9.99957681e-01],\n",
       "       [3.74231146e-20],\n",
       "       [9.99991536e-01],\n",
       "       [2.91905337e-07],\n",
       "       [7.13726506e-02],\n",
       "       [4.75369906e-20],\n",
       "       [1.00000000e+00],\n",
       "       [2.52574356e-17],\n",
       "       [8.39984349e-09],\n",
       "       [4.70354956e-14],\n",
       "       [1.50897193e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.24316430e-03],\n",
       "       [1.17060984e-03],\n",
       "       [2.89182931e-01],\n",
       "       [1.32687256e-01],\n",
       "       [1.12030220e-05],\n",
       "       [9.69109058e-01],\n",
       "       [4.76753973e-19],\n",
       "       [2.89182931e-01],\n",
       "       [9.87909794e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.99999881e-01],\n",
       "       [1.77300903e-14],\n",
       "       [9.72279253e-08],\n",
       "       [4.90812295e-25],\n",
       "       [2.11977909e-04],\n",
       "       [8.30703062e-10],\n",
       "       [9.94524110e-19],\n",
       "       [1.16644672e-03],\n",
       "       [2.89182931e-01],\n",
       "       [1.00485424e-08],\n",
       "       [3.49454830e-25],\n",
       "       [8.03558290e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.95943964e-01],\n",
       "       [1.50860513e-09],\n",
       "       [1.52725410e-02],\n",
       "       [5.71658239e-02],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.99999404e-01],\n",
       "       [9.99456108e-01],\n",
       "       [1.90422349e-21],\n",
       "       [4.37776073e-08],\n",
       "       [3.20812017e-01],\n",
       "       [1.16925747e-10],\n",
       "       [1.04859433e-31],\n",
       "       [1.04703152e-16],\n",
       "       [1.69701618e-03],\n",
       "       [9.99998927e-01],\n",
       "       [6.12249517e-15],\n",
       "       [2.89182931e-01],\n",
       "       [2.94424384e-17],\n",
       "       [9.99302268e-01],\n",
       "       [2.12989040e-20],\n",
       "       [1.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [9.31782275e-02],\n",
       "       [9.99812424e-01],\n",
       "       [9.92119193e-01],\n",
       "       [1.41445171e-20],\n",
       "       [4.95005186e-18],\n",
       "       [9.99999881e-01],\n",
       "       [9.99984026e-01],\n",
       "       [9.98064138e-08],\n",
       "       [9.99999762e-01],\n",
       "       [2.89182931e-01],\n",
       "       [3.18175972e-01],\n",
       "       [5.05582809e-01],\n",
       "       [9.47401151e-02],\n",
       "       [6.97229147e-01],\n",
       "       [1.13461866e-12],\n",
       "       [1.01597444e-03],\n",
       "       [1.00000000e+00],\n",
       "       [7.22383353e-09],\n",
       "       [9.99999642e-01],\n",
       "       [2.89182931e-01],\n",
       "       [3.88576067e-04],\n",
       "       [1.32687256e-01],\n",
       "       [6.76655281e-06],\n",
       "       [1.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [6.34965691e-05],\n",
       "       [9.59607005e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.99997377e-01],\n",
       "       [1.53770723e-33],\n",
       "       [2.89182931e-01],\n",
       "       [9.99998331e-01],\n",
       "       [2.89182931e-01],\n",
       "       [5.80844207e-21],\n",
       "       [1.00000000e+00],\n",
       "       [6.15485352e-09],\n",
       "       [2.89182931e-01],\n",
       "       [3.25354706e-13],\n",
       "       [2.89182931e-01],\n",
       "       [7.74645507e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.74117368e-01],\n",
       "       [1.16067667e-07],\n",
       "       [3.64638981e-05],\n",
       "       [1.09295415e-05],\n",
       "       [2.46104509e-01],\n",
       "       [4.66740951e-02],\n",
       "       [8.44018883e-04],\n",
       "       [1.52482633e-02],\n",
       "       [2.10263005e-11],\n",
       "       [6.61075592e-01],\n",
       "       [2.66862422e-01],\n",
       "       [2.06290618e-01],\n",
       "       [4.69445549e-09],\n",
       "       [9.99999285e-01],\n",
       "       [5.85051923e-20],\n",
       "       [9.99995470e-01],\n",
       "       [5.26066287e-07],\n",
       "       [9.34353590e-01],\n",
       "       [8.07368577e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.74213422e-03],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [9.99352515e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.76867259e-01],\n",
       "       [1.78222984e-01],\n",
       "       [5.17445207e-02],\n",
       "       [3.53454765e-10],\n",
       "       [8.07987154e-01],\n",
       "       [5.71296084e-07],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [4.70819998e-07],\n",
       "       [2.28601671e-03],\n",
       "       [8.04802724e-10],\n",
       "       [8.19170475e-01],\n",
       "       [9.99979734e-01],\n",
       "       [1.14988880e-02],\n",
       "       [9.99999642e-01],\n",
       "       [9.25347805e-01],\n",
       "       [2.31815183e-16],\n",
       "       [2.89182931e-01],\n",
       "       [9.99999285e-01],\n",
       "       [9.99987841e-01],\n",
       "       [9.82816160e-01],\n",
       "       [3.96704010e-17],\n",
       "       [2.15570745e-03],\n",
       "       [9.24882770e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.26695588e-01],\n",
       "       [7.65839696e-01],\n",
       "       [3.16734388e-02],\n",
       "       [1.58817718e-12],\n",
       "       [9.99999762e-01],\n",
       "       [1.00000000e+00],\n",
       "       [7.76807606e-01],\n",
       "       [2.56733501e-09],\n",
       "       [9.81812477e-01],\n",
       "       [5.84470990e-06],\n",
       "       [1.00000000e+00],\n",
       "       [4.59657158e-22],\n",
       "       [9.90073085e-01],\n",
       "       [5.20952092e-03],\n",
       "       [3.67738376e-03],\n",
       "       [1.00000000e+00],\n",
       "       [2.79367729e-08],\n",
       "       [1.01556282e-13],\n",
       "       [3.31165398e-17],\n",
       "       [2.89182931e-01],\n",
       "       [6.81458553e-03],\n",
       "       [9.99998212e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.79737083e-12],\n",
       "       [1.00000000e+00],\n",
       "       [9.97115135e-01],\n",
       "       [1.23994774e-03],\n",
       "       [1.66961226e-13],\n",
       "       [1.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [0.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [1.82916921e-07],\n",
       "       [9.99994278e-01],\n",
       "       [9.99956846e-01],\n",
       "       [8.32787088e-19],\n",
       "       [9.99963522e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.10694357e-26],\n",
       "       [9.00042194e-11],\n",
       "       [3.67654457e-06],\n",
       "       [2.89182931e-01],\n",
       "       [9.99957919e-01],\n",
       "       [0.00000000e+00],\n",
       "       [7.32884161e-15],\n",
       "       [9.99999166e-01],\n",
       "       [1.05151551e-14],\n",
       "       [1.00000000e+00],\n",
       "       [9.99992013e-01],\n",
       "       [5.21837592e-01],\n",
       "       [2.89182931e-01],\n",
       "       [7.89355272e-06],\n",
       "       [6.09568758e-07],\n",
       "       [2.89182931e-01],\n",
       "       [3.85011286e-02],\n",
       "       [1.79762102e-22],\n",
       "       [1.00000000e+00],\n",
       "       [9.53813739e-08],\n",
       "       [4.51244588e-04],\n",
       "       [9.99999166e-01],\n",
       "       [8.72165110e-05],\n",
       "       [9.99950647e-01],\n",
       "       [9.97376561e-01],\n",
       "       [1.15440649e-07],\n",
       "       [9.94749606e-01],\n",
       "       [2.80846933e-13],\n",
       "       [2.86431550e-05],\n",
       "       [2.89182931e-01],\n",
       "       [1.79717725e-04],\n",
       "       [2.97692643e-14],\n",
       "       [9.99998569e-01],\n",
       "       [9.99994755e-01],\n",
       "       [2.88259625e-01],\n",
       "       [9.99031425e-01],\n",
       "       [9.99946713e-01],\n",
       "       [9.47281660e-06],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999404e-01],\n",
       "       [4.49571162e-02],\n",
       "       [9.77953017e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.99907494e-01],\n",
       "       [3.73979892e-05],\n",
       "       [9.99913454e-01],\n",
       "       [5.85411499e-06],\n",
       "       [1.10005317e-02],\n",
       "       [1.16906722e-05],\n",
       "       [1.20169077e-18],\n",
       "       [9.99921083e-01],\n",
       "       [9.99866724e-01],\n",
       "       [7.12419003e-02],\n",
       "       [9.99983311e-01],\n",
       "       [7.98832953e-01],\n",
       "       [9.99489784e-01],\n",
       "       [3.20269050e-20],\n",
       "       [5.55596080e-06],\n",
       "       [1.00000000e+00],\n",
       "       [9.99989390e-01],\n",
       "       [9.26896906e-13],\n",
       "       [1.09696835e-11],\n",
       "       [9.99998569e-01],\n",
       "       [9.91867959e-01],\n",
       "       [9.97862518e-01],\n",
       "       [9.70083475e-02],\n",
       "       [1.46366558e-10],\n",
       "       [5.57455787e-05],\n",
       "       [2.89182931e-01],\n",
       "       [9.81479585e-01],\n",
       "       [5.56586113e-23],\n",
       "       [2.66862422e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.84509353e-22],\n",
       "       [2.54178216e-04],\n",
       "       [1.04368773e-04],\n",
       "       [2.89182931e-01],\n",
       "       [9.83713150e-01],\n",
       "       [5.26114828e-18],\n",
       "       [6.25588715e-01],\n",
       "       [1.59941286e-01],\n",
       "       [2.44040081e-15],\n",
       "       [1.67333540e-02],\n",
       "       [7.25668144e-07],\n",
       "       [5.94442710e-03],\n",
       "       [3.13451025e-08],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999881e-01],\n",
       "       [7.76090292e-06],\n",
       "       [2.89182931e-01],\n",
       "       [1.58759547e-04],\n",
       "       [1.00000000e+00],\n",
       "       [2.36946530e-13],\n",
       "       [3.17203776e-05],\n",
       "       [5.19883513e-01],\n",
       "       [1.56469378e-06],\n",
       "       [2.63181282e-03],\n",
       "       [1.42016151e-12],\n",
       "       [4.66297889e-36],\n",
       "       [6.23927545e-03],\n",
       "       [5.71090730e-08],\n",
       "       [3.13013752e-19],\n",
       "       [9.99733508e-01],\n",
       "       [6.02196553e-04],\n",
       "       [5.12899219e-14],\n",
       "       [9.99999523e-01],\n",
       "       [1.42205805e-02],\n",
       "       [1.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.99999762e-01],\n",
       "       [9.99943376e-01],\n",
       "       [2.00219397e-09],\n",
       "       [9.98991907e-01],\n",
       "       [9.97023642e-01],\n",
       "       [5.61546074e-07],\n",
       "       [2.89182931e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.54807037e-17],\n",
       "       [7.88723664e-09],\n",
       "       [1.46532529e-05],\n",
       "       [1.97347775e-24],\n",
       "       [2.89182931e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.64848186e-06],\n",
       "       [3.06939370e-13],\n",
       "       [4.55475734e-19],\n",
       "       [9.99999881e-01],\n",
       "       [6.85322084e-19],\n",
       "       [2.38040143e-12],\n",
       "       [1.85929339e-09],\n",
       "       [1.83025403e-21],\n",
       "       [2.89182931e-01],\n",
       "       [7.88463175e-01],\n",
       "       [2.21793612e-12],\n",
       "       [9.93733466e-01],\n",
       "       [9.99925375e-01],\n",
       "       [7.60707497e-09],\n",
       "       [7.10389692e-23],\n",
       "       [1.03265494e-02],\n",
       "       [2.89182931e-01],\n",
       "       [2.62218564e-05],\n",
       "       [1.00000000e+00],\n",
       "       [2.30158210e-12],\n",
       "       [1.60435792e-02],\n",
       "       [3.08682729e-07],\n",
       "       [3.45206900e-05],\n",
       "       [4.14046486e-09],\n",
       "       [1.00000000e+00],\n",
       "       [5.08857369e-01],\n",
       "       [9.96568441e-01],\n",
       "       [1.27753842e-28],\n",
       "       [2.89182931e-01],\n",
       "       [1.86132732e-27],\n",
       "       [9.13905799e-01],\n",
       "       [9.74495471e-01],\n",
       "       [3.08943953e-07],\n",
       "       [1.12895917e-11],\n",
       "       [1.14481958e-21],\n",
       "       [2.96843111e-34],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.66499031e-25],\n",
       "       [8.86695325e-01],\n",
       "       [1.32687256e-01],\n",
       "       [4.75894213e-09],\n",
       "       [7.18856692e-01],\n",
       "       [5.60850520e-13],\n",
       "       [1.41469980e-09],\n",
       "       [2.17684388e-01],\n",
       "       [1.58131439e-02],\n",
       "       [9.99997377e-01],\n",
       "       [1.34908867e-18],\n",
       "       [1.00000000e+00],\n",
       "       [9.99918580e-01],\n",
       "       [1.13526450e-22],\n",
       "       [5.89465239e-12],\n",
       "       [8.01708400e-01],\n",
       "       [2.19686042e-15],\n",
       "       [1.18147182e-06],\n",
       "       [9.99998331e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.99994874e-01],\n",
       "       [9.99998331e-01],\n",
       "       [9.99999881e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.21281888e-12],\n",
       "       [6.90495786e-11],\n",
       "       [1.82292461e-05],\n",
       "       [3.14915886e-25],\n",
       "       [4.06412326e-09],\n",
       "       [1.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [5.63695794e-05],\n",
       "       [2.89182931e-01],\n",
       "       [3.73081304e-02],\n",
       "       [2.89182931e-01],\n",
       "       [4.79455376e-14],\n",
       "       [5.50772272e-09],\n",
       "       [9.79275703e-01],\n",
       "       [8.02394559e-18],\n",
       "       [9.99998808e-01],\n",
       "       [2.89182931e-01],\n",
       "       [9.99955416e-01],\n",
       "       [4.24756407e-04],\n",
       "       [8.00151029e-05],\n",
       "       [9.97818351e-01],\n",
       "       [1.41963421e-22],\n",
       "       [1.31951101e-05],\n",
       "       [7.51171529e-01],\n",
       "       [9.99518991e-01],\n",
       "       [1.00353872e-03],\n",
       "       [1.04947279e-12],\n",
       "       [1.00000000e+00],\n",
       "       [9.13936257e-01],\n",
       "       [8.57351969e-29],\n",
       "       [4.45888985e-15],\n",
       "       [2.89182931e-01],\n",
       "       [6.21966898e-01],\n",
       "       [4.46202790e-07],\n",
       "       [1.32687256e-01],\n",
       "       [2.89182931e-01],\n",
       "       [4.15981640e-25],\n",
       "       [2.89182931e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.68914073e-16],\n",
       "       [2.89182931e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.89182931e-01],\n",
       "       [2.89182931e-01],\n",
       "       [2.37809528e-09],\n",
       "       [6.83285177e-01],\n",
       "       [8.84264529e-01],\n",
       "       [1.12643011e-05],\n",
       "       [2.89182931e-01],\n",
       "       [2.63711996e-07],\n",
       "       [1.02477262e-16],\n",
       "       [2.89182931e-01],\n",
       "       [1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_dev_seq)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(predictions<=0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.groupby(by=\"Username\").count().shape#.shape#[\"Tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   0,   0,   1,   2,   0,   1,   0,   1,   3,   6,  25,\n",
       "         79, 194, 187,   0,   0]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(tweets_df.groupby(by=\"Username\").count()[\"Tweet\"].tolist()\\\n",
    "             , bins = range(1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAGK9JREFUeJzt3X+U3XV95/Hni4QfMYMJyJiNJG6yNcyWwhpJFulq7QypNkSPwVY5eFxNhO60u+iCpq1B97S4LudgNdL1tKUnGpqoKEwRShqgBUOmLOcsIMHAJARwkFAyDUnFEJyF0g6894/vJyfXaWbune/33sl1Pq/HOffc78/3fd8733nd7/3e771XEYGZmeXhuGPdgJmZTR6HvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhoOfUnTJP1A0pY0vlDSA5IGJd0k6YQ0/cQ0PpjmL2hN62ZmNlET2dO/HNhdM/5F4NqIeAtwELg0Tb8UOJimX5uWMzOzNtBQ6EuaB7wX+HoaF3A+cHNaZBNwYRpemcZJ85el5c3M7Bib3uByfwz8PnByGn8D8EJEjKTxvcDpafh04FmAiBiRdCgt/+PagpJ6gV6Ak046acmb3/zmsvfhZ7z22mscd1z1tyqaVadda7mnya/lnia/1lTv6cknn/xxRHROaKWIGPcCvA/4szTcDWwBTgMGa5aZD+xMwzuBeTXzngJOG+82zjjjjGiWbdu2tVWddq3lnia/lnua/FpTvSfgoaiT4aMvjezpvwN4v6QVwEnA64H/DcyWND2Kvf15wFBafig9CeyVNB2YBTw/oWciMzNribqvMSLiyoiYFxELgIuBeyLiI8A24INpsVXAbWl4cxonzb8nPSOZmdkxVuXA0meAT0sapDhmvyFN3wC8IU3/NLC2WotmZtYsjb6RC0BE9AP9afhHwLlHWeafgA81oTczM2syfyLXzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjEzp7x8ysGRasvX3c+WvOHmF1nWUasXH5zMo1phrv6ZuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhmpG/qSTpL0oKRHJO2S9Pk0faOkpyXtSJfFabokfVXSoKRHJZ3T6jthZmaNaeRbNl8Bzo+IYUnHA/dJujPN+72IuHnU8hcAi9Ll7cB16drMzI6xunv6URhOo8enS4yzykrgG2m9+4HZkuZWb9XMzKpq6Ji+pGmSdgAHgLsj4oE06+p0COdaSSemaacDz9asvjdNMzOzY0wR4+20j1pYmg3cCnwSeB54DjgBWA88FRH/U9IW4JqIuC+tsxX4TEQ8NKpWL9AL0NnZuaSvr68JdweGh4fp6OhomzrtWss9TX4t93TEwNChcefPmQH7X67e08JZ06b0Y97T07M9IpZOZJ0J/XJWRLwgaRuwPCK+nCa/IukvgN9N40PA/JrV5qVpo2utp3iyoKurK7q7uyfSypj6+/tpRq1m1WnXWu5p8mu5pyPq/SrWmrNHWDdQ/Yf9Ni6fOaUf8zIaOXunM+3hI2kG8G7g8cPH6SUJuBDYmVbZDHwsncVzHnAoIva1pHszM5uQRp5K5wKbJE2jeJLoi4gtku6R1AkI2AH8Tlr+DmAFMAi8BHy8+W2bmVkZdUM/Ih4F3naU6eePsXwAl1VvzczMms2fyDUzy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OM1A19SSdJelDSI5J2Sfp8mr5Q0gOSBiXdJOmENP3END6Y5i9o7V0wM7NGNbKn/wpwfkS8FVgMLJd0HvBF4NqIeAtwELg0LX8pcDBNvzYtZ2ZmbaBu6EdhOI0eny4BnA/cnKZvAi5MwyvTOGn+MklqWsdmZlaaIqL+QtI0YDvwFuBPgS8B96e9eSTNB+6MiLMk7QSWR8TeNO8p4O0R8eNRNXuBXoDOzs4lfX19TblDw8PDdHR0tE2ddq3lnia/lns6YmDo0Ljz58yA/S9X72nhrGlT+jHv6enZHhFLJ7LO9EYWiohXgcWSZgO3Av++RH+ja64H1gN0dXVFd3d31ZIA9Pf304xazarTrrXc0+TXck9HrF57+7jz15w9wrqBhuJpXBuXz5zSj3kZEzp7JyJeALYBvwzMlnT4rzIPGErDQ8B8gDR/FvB8U7o1M7NKGjl7pzPt4SNpBvBuYDdF+H8wLbYKuC0Nb07jpPn3RCPHkMzMrOUaef00F9iUjusfB/RFxBZJjwE3SvpfwA+ADWn5DcA3JQ0CPwEubkHfZmZWQt3Qj4hHgbcdZfqPgHOPMv2fgA81pTszM2sqfyLXzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w08sPo8yVtk/SYpF2SLk/Tr5I0JGlHuqyoWedKSYOSnpD06628A2Zm1rhGfhh9BFgTEQ9LOhnYLunuNO/aiPhy7cKSzqT4MfRfAt4EfE/SGRHxajMbNzOziau7px8R+yLi4TT8U2A3cPo4q6wEboyIVyLiaWCQo/yAupmZTT5FROMLSwuAe4GzgE8Dq4EXgYcoXg0clPQnwP0R8a20zgbgzoi4eVStXqAXoLOzc0lfX1/V+wLA8PAwHR0dbVOnXWu5p8mv5Z6OGBg6NO78OTNg/8vVe1o4a9qUfsx7enq2R8TSiazTyOEdACR1AN8FroiIFyVdB3wBiHS9Drik0XoRsR5YD9DV1RXd3d0TaHts/f39NKNWs+q0ay33NPm13NMRq9fePu78NWePsG6g4Xga08blM6f0Y15GQ2fvSDqeIvBviIhbACJif0S8GhGvAV/jyCGcIWB+zerz0jQzMzvGGjl7R8AGYHdEfKVm+tyaxT4A7EzDm4GLJZ0oaSGwCHiweS2bmVlZjbx+egfwUWBA0o407bPAhyUtpji8swf4bYCI2CWpD3iM4syfy3zmjplZe6gb+hFxH6CjzLpjnHWuBq6u0JeZmbWAP5FrZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYa+WH0+ZK2SXpM0i5Jl6fpp0q6W9IP0/UpabokfVXSoKRHJZ3T6jthZmaNaWRPfwRYExFnAucBl0k6E1gLbI2IRcDWNA5wAbAoXXqB65retZmZlVI39CNiX0Q8nIZ/CuwGTgdWApvSYpuAC9PwSuAbUbgfmC1pbtM7NzOzCVNENL6wtAC4FzgL+PuImJ2mCzgYEbMlbQGuiYj70rytwGci4qFRtXopXgnQ2dm5pK+vr/q9AYaHh+no6GibOu1ayz1Nfi33dMTA0KFx58+ZAftfrt7TwlnTpvRj3tPTsz0ilk5knemNLiipA/gucEVEvFjkfCEiQlLjzx7FOuuB9QBdXV3R3d09kdXH1N/fTzNqNatOu9ZyT5Nfyz0dsXrt7ePOX3P2COsGGo6nMW1cPnNKP+ZlNHT2jqTjKQL/hoi4JU3ef/iwTbo+kKYPAfNrVp+XppmZ2THWyNk7AjYAuyPiKzWzNgOr0vAq4Laa6R9LZ/GcBxyKiH1N7NnMzEpq5PXTO4CPAgOSdqRpnwWuAfokXQo8A1yU5t0BrAAGgZeAjze1YzMzK61u6Kc3ZDXG7GVHWT6Ayyr2ZWZmLeBP5JqZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWkUZ+GP16SQck7ayZdpWkIUk70mVFzbwrJQ1KekLSr7eqcTMzm7hG9vQ3AsuPMv3aiFicLncASDoTuBj4pbTOn0ma1qxmzcysmrqhHxH3Aj9psN5K4MaIeCUingYGgXMr9GdmZk2kiKi/kLQA2BIRZ6Xxq4DVwIvAQ8CaiDgo6U+A+yPiW2m5DcCdEXHzUWr2Ar0AnZ2dS/r6+ppwd2B4eJiOjo62qdOutdzT5NdyT0cMDB0ad/6cGbD/5eo9LZw1bUo/5j09PdsjYulE1ple8rauA74ARLpeB1wykQIRsR5YD9DV1RXd3d0lW/lZ/f39NKNWs+q0ay33NPm13NMRq9fePu78NWePsG6gbDwdsXH5zCn9mJdR6uydiNgfEa9GxGvA1zhyCGcImF+z6Lw0zczM2kCp0Jc0t2b0A8DhM3s2AxdLOlHSQmAR8GC1Fs3MrFnqvn6S9B2gGzhN0l7gD4FuSYspDu/sAX4bICJ2SeoDHgNGgMsi4tXWtG5mZhNVN/Qj4sNHmbxhnOWvBq6u0pSZmbWGP5FrZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUbqhr6k6yUdkLSzZtqpku6W9MN0fUqaLklflTQo6VFJ57SyeTMzm5hG9vQ3AstHTVsLbI2IRcDWNA5wAbAoXXqB65rTppmZNUPd0I+Ie4GfjJq8EtiUhjcBF9ZM/0YU7gdmS5rbrGbNzKwaRUT9haQFwJaIOCuNvxARs9OwgIMRMVvSFuCaiLgvzdsKfCYiHjpKzV6KVwN0dnYu6evra8odGh4epqOjo23qtGst9zT5tdzTEQNDh8adP2cG7H+5ek8LZ02b0o95T0/P9ohYOpF1ple90YgISfWfOf71euuB9QBdXV3R3d1dtRUA+vv7aUatZtVp11ruafJruacjVq+9fdz5a84eYd1A5Xhi4/KZU/oxL6Ps2Tv7Dx+2SdcH0vQhYH7NcvPSNDMzawNlQ38zsCoNrwJuq5n+sXQWz3nAoYjYV7FHMzNrkrqvnyR9B+gGTpO0F/hD4BqgT9KlwDPARWnxO4AVwCDwEvDxFvRsZmYl1Q39iPjwGLOWHWXZAC6r2pSZmbWGP5FrZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUaqf87ZzKaMBXW+HmE8a84eqfv1CnbseU/fzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMlLpu3ck7QF+CrwKjETEUkmnAjcBC4A9wEURcbBam2Zm1gzN2NPviYjFEbE0ja8FtkbEImBrGjczszbQisM7K4FNaXgTcGELbsPMzEqoGvoB3CVpu6TeNG1OROxLw88BcyrehpmZNYkiovzK0ukRMSTpjcDdwCeBzRExu2aZgxFxylHW7QV6ATo7O5f09fWV7qPW8PAwHR0dbVOnXWu5p8mv9fPQ08DQodK15syA/S9XbqmptRbOmtb2j3kVPT0922sOrTekUuj/TCHpKmAY+C9Ad0TskzQX6I+IrvHW7erqiieeeKIpffT399Pd3d02ddq1lnua/Fo/Dz1V/RGVdQPN+V2mZtXauHxm2z/mVUiacOiXPrwjaaakkw8PA+8BdgKbgVVpsVXAbWVvw8zMmqvKU+kc4FZJh+t8OyL+RtL3gT5JlwLPABdVb9PMzJqhdOhHxI+Atx5l+vPAsipNmZlZa/gTuWZmGXHom5llxKFvZpYRh76ZWUYc+mZmGWnOJynMrKVGf2hqzdkjrK7wQapm17GfH97TNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLSMtCX9JySU9IGpS0tlW3Y2ZmjWvJVytLmgb8KfBuYC/wfUmbI+KxVtzeVDZZX6m755r3Vq6Zo9F/n/H4a4ytHbTq+/TPBQYj4kcAkm4EVgItD/2BoUOT8j3jDslyxgvJZoZiu9YyO9YUEc0vKn0QWB4Rv5XGPwq8PSI+UbNML9CbRs8Cdjbp5k8DftxGddq1lnua/FruafJrTfWeuiLi5ImscMx+OSsi1gPrASQ9FBFLm1G3WbXasadm1nJPk1/LPU1+rRx6mug6rXojdwiYXzM+L00zM7NjqFWh/31gkaSFkk4ALgY2t+i2zMysQS05vBMRI5I+AfwtMA24PiJ2jbPK+ibefLNqtWNPzazlnia/lnua/FruaZSWvJFrZmbtyZ/INTPLiEPfzCwjxzT0JV0v6YCkSufoS5ovaZukxyTtknR5hVonSXpQ0iOp1ucr9jZN0g8kbalYZ4+kAUk7ypymNarWbEk3S3pc0m5Jv1yiRlfq5fDlRUlXVOjpU+nx3inpO5JOKlnn8lRj10T7Odr2KOlUSXdL+mG6PqVCrQ+lvl6T1PApe2PU+lL6+z0q6VZJs0vW+UKqsUPSXZLeVLanmnlrJIWk00r2dJWkoZpta0WVniR9Mj1WuyT9Udlakm6q6WmPpB0l6yyWdP/h/2VJ51bo6a2S/m/Khr+W9Pq6hSLimF2AdwHnADsr1pkLnJOGTwaeBM4sWUtARxo+HngAOK9Cb58Gvg1sqXgf9wCnNelx3wT8Vho+AZhdsd404Dng35Zc/3TgaWBGGu8DVpeoc/hDfq+jOEnhe8BbJrD+v9oegT8C1qbhtcAXK9T6RaAL6AeWVuzrPcD0NPzFRvoao87ra4b/O/DnZXtK0+dTnMDxTCPb6xg9XQX8bom//9Fq9aTt4MQ0/sYq969m/jrgD0r2dBdwQRpeAfRXuH/fB341DV8CfKFenWO6px8R9wI/aUKdfRHxcBr+KbCbIkjK1IqIGE6jx6dLqXe7Jc0D3gt8vcz6rSBpFsXGswEgIv45Il6oWHYZ8FREPFOhxnRghqTpFKH9DyVq/CLwQES8FBEjwN8Bv9HoymNsjyspniRJ1xeWrRURuyPiiUb7qVPrrnQfAe6n+CxMmTov1ozOpMFtfZz/3WuB329CnQkbo9Z/Ba6JiFfSMgeq9iVJwEXAd0rWCeDwHvksGtzWx6h1BnBvGr4b+M16dabcMX1JC4C3Ueyhl60xLb10OwDcHRFla/0xxT/Aa2V7qRHAXZK2q/gKi7IWAv8I/EU67PR1STMr9nYxDfwDjCUihoAvA38P7AMORcRdJUrtBH5F0hskvY5iL2p+nXXqmRMR+9Lwc8CcivVa4RLgzrIrS7pa0rPAR4A/qFBnJTAUEY+UrVHjE+mw0/WNHlIbwxkU28QDkv5O0n9sQm+/AuyPiB+WXP8K4EvpMf8ycGWFXnZR7JgAfIgGtvcpFfqSOoDvAleM2oOZkIh4NSIWU+w9nSvprBK9vA84EBHby/Yxyjsj4hzgAuAySe8qWWc6xUvE6yLibcD/ozhsUYqKD9+9H/jLCjVOodhwFwJvAmZK+s8TrRMRuykOddwF/A2wA3i1bF9HqR+UfNXXKpI+B4wAN5StERGfi4j5qcYn6i0/Rh+vAz5LhSeNGtcBvwAsptgJWFeh1nTgVOA84PeAvrSnXsWHqbCTQ/Hq41PpMf8U6VV3SZcA/03SdopD2/9cb4UpE/qSjqcI/Bsi4pZm1EyHPbYBy0us/g7g/ZL2ADcC50v6VoVehtL1AeBWim8yLWMvsLfm1cvNFE8CZV0APBwR+yvU+DXg6Yj4x4j4F+AW4D+VKRQRGyJiSUS8CzhI8f5OFfslzQVI1w0dHpgMklYD7wM+kp6QqrqBBg4PjOEXKJ60H0nb/DzgYUn/ZqKFImJ/2vF6Dfga5bd1KLb3W9Jh2wcpXnXXfYN5LOnw428AN1XoaRXFNg7FzlLp+xcRj0fEeyJiCcUT0VP11pkSoZ+euTcAuyPiKxVrdR4+E0LSDIrfBHh8onUi4sqImBcRCygOf9wTERPee019zJR08uFhijfxSp3xFBHPAc9K6kqTllHtK6+r7vVAcVjnPEmvS3/LZRTvy0yYpDem6zdT/HN+u2Jvmyn+SUnXt1Ws1xSSllMcOnx/RLxUoc6imtGVlNjWASJiICLeGBEL0ja/l+LkiudK9DS3ZvQDVPsG3r+ieDMXSWdQnLhQ5Rsufw14PCL2VqjxD8CvpuHzgbKHiWq39+OA/wH8ed2VGnnXuFUXirDYB/wLxUZyack676R42f0oxUv6HcCKkrX+A/CDVGsnDbxD30DNbiqcvQP8O+CRdNkFfK5iP4uBh9J9/CvglJJ1ZgLPA7Oa8Bh9niJwdgLfJJ1tUaLO/6F4EnsEWFZ1ewTeAGyl+Mf8HnBqhVofSMOvAPuBv61QaxB4tmZ7r3vWzRh1vpse80eBvwZOL9vTqPl7aOzsnaP19E1gIPW0GZhb4XE6AfhWuo8PA+dXuX/ARuB3Km5T7wS2p230AWBJhVqXU7yafRK4hvQtC+Nd/DUMZmYZmRKHd8zMrDEOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy8v8B302ywLn8rdQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6744a7198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tweets_df.groupby(by=\"Username\").count()[\"Tweet\"].tolist())\n",
    "plt.xticks(range(1, 20))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6747523c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = tweets_df.groupby(by=\"Username\").count()[\"Tweet\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.get_sketch_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>AverageAnnotation</th>\n",
       "      <th>ProfileInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>threelilbirdsss</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>['description: Mom. Wife. Career Lady. TV Junk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caitlynsalalala</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>[\"description: Hi. I'm addicted to video games...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Galafani1</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_takeachantz</td>\n",
       "      <td>-0.364865</td>\n",
       "      <td>[\"description: 412 | IUP'17 | Live Life | Don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sizzurp_713</td>\n",
       "      <td>-0.367647</td>\n",
       "      <td>['description: knowledge Is Power.\\n', 'follow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Username  AverageAnnotation  \\\n",
       "0  threelilbirdsss           0.053333   \n",
       "1  caitlynsalalala          -0.142857   \n",
       "2        Galafani1           0.014493   \n",
       "3     _takeachantz          -0.364865   \n",
       "4      Sizzurp_713          -0.367647   \n",
       "\n",
       "                                         ProfileInfo  \n",
       "0  ['description: Mom. Wife. Career Lady. TV Junk...  \n",
       "1  [\"description: Hi. I'm addicted to video games...  \n",
       "2                                                NaN  \n",
       "3  [\"description: 412 | IUP'17 | Live Life | Don'...  \n",
       "4  ['description: knowledge Is Power.\\n', 'follow...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/optimism-twitter-data/user_information.csv\"\\\n",
    "           ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['description: Dad of 2. WATP Glasgow\\\\n', 'followers: 323\\\\n', 'following: 315\\\\n', 'total tweet number: 257\\\\n', 'created_at: Mon Sep 16 13:58:10 +0000 2013\\\\n', 'favorites_count: 741\\\\n', 'listed_count: 2\\\\n']\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/optimism-twitter-data/user_information.csv\"\\\n",
    "           ).iloc[332][\"ProfileInfo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drafts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>788435</td>\n",
       "      <td>788435</td>\n",
       "      <td>788435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>790177</td>\n",
       "      <td>790177</td>\n",
       "      <td>790177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ItemID  SentimentSource  SentimentText\n",
       "Sentiment                                        \n",
       "0          788435           788435         788435\n",
       "1          790177           790177         790177"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv\"\\\n",
    "           , error_bad_lines=False).groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_index                                           sentence\n",
       "0               1  The Rock is destined to be the 21st Century 's...\n",
       "1               2  The gorgeously elaborate continuation of `` Th...\n",
       "2               3                     Effective but too-tepid biopic\n",
       "3               4  If you sometimes like to go to the movies to h...\n",
       "4               5  Emerges as something rare , an issue movie tha..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table(\"data/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSentences.txt\"\\\n",
    "             ).head()\n",
    "#            , error_bad_lines=False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
